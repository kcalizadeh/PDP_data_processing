{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_text_introduction_notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOW3OwbsMzKHXeIpn28MlSs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/PDP_data_processing/blob/master/new_text_introduction_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cw_rJlXCob_"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN4DvDsxCdio",
        "outputId": "26767b6c-ee09-4db4-bf38-2fc77d13a052"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\n",
        "# and relevant libraries via the functions.py file\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/philosophy_data_project'\n",
        "\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAk2WGLbCn3t"
      },
      "source": [
        "from import_functions import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV19sbpUC2PF",
        "outputId": "ef7d0744-8feb-4576-ba5c-ab89d7863651"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbT8yZ0pC30A"
      },
      "source": [
        "###Load the Text and Clip Front and End Matter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-MzN2T2DUYm"
      },
      "source": [
        "# if you are deleting an old text that was added here, make sure it is in the \n",
        "# primary database construction notebook\n",
        "seneca_all_texts = get_guten('http://www.gutenberg.org/files/56075/56075-0.txt')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuWrhYwOUbck"
      },
      "source": [
        "seneca_on_benefits = seneca_all_texts.split('SENECA OF BENEFITS')[1][54:].split('SENECA OF ANGER')[0]\n",
        "seneca_on_anger = seneca_all_texts.split('SENECA OF ANGER')[1][95:].split('SENECA OF CLEMENCY')[0]\n",
        "seneca_on_clemency = seneca_all_texts.split('SENECA OF CLEMENCY')[1][7:].split('Obvious typographical errors have been corre')[0][:-80]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suHuy6isDUiC"
      },
      "source": [
        "### Clean the Text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfFHzvnDUpf"
      },
      "source": [
        "def baseline_clean(to_correct, \n",
        "                   capitals=True, \n",
        "                   bracketed_fn=False, \n",
        "                   odd_words_dict={}):\n",
        "  # remove utf8 encoding characters and some punctuations\n",
        "  result = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6§\\\\\\£\\Â*_<>\"\"⎫•{}Γ~]', ' ', to_correct)\n",
        "  result = re.sub(r'[\\u2014\\u2013\\u2012-]', ' ', result)\n",
        "\n",
        "  # replace whitespace characters with actual whitespace\n",
        "  result = re.sub(r'\\s', ' ', result)\n",
        "\n",
        "  # replace odd quotation marks with a standard\n",
        "  result = re.sub(r'[‘’“”]', \"'\", result)\n",
        "\n",
        "  # replace the ﬀ, ﬃ and ﬁ with the appropriate counterparts\n",
        "  result = re.sub(r'ﬀ', 'ff', result)\n",
        "  result = re.sub(r'ﬁ', 'fi', result)\n",
        "  result = re.sub(r'ﬃ', 'ffi', result)\n",
        "\n",
        "  # replace some accented characters for ease of searching\n",
        "  result = re.sub(r'é', 'e', result)\n",
        "\n",
        "  # remove or standardize some recurring common and meaninless words/phrases\n",
        "  result = re.sub(r'\\s*This\\s*page\\s*intentionally\\s*left\\s*blank\\s*', ' ', result)\n",
        "  result = re.sub(r'(?i)Aufgabe\\s+', ' ', result)\n",
        "  result = re.sub(r',*\\s+cf\\.', ' ', result)\n",
        "\n",
        "  # some texts have footnotes conveniently in brackets - this removes them all, \n",
        "  # with a safety measure for unpaired brackets, and deletes all brackets afterwards\n",
        "  if bracketed_fn:\n",
        "    result = re.sub(r'\\[.{0,300}\\]|{.{0,300}}|{.{0,300}\\]|\\[.{0,300}}', ' ', result)\n",
        "  result = re.sub(r'[\\[\\]{}]', ' ', result)\n",
        "\n",
        "  # unify some abbreviations\n",
        "  result = re.sub(r'&', 'and', result)\n",
        "  result = re.sub(r'\\se\\.g\\.\\s', ' eg ', result)\n",
        "  result = re.sub(r'\\si\\.e\\.\\s', ' ie ', result)\n",
        "  result = re.sub('coroll\\.', 'coroll', result)\n",
        "  result = re.sub('pt\\.', 'pt', result)\n",
        "\n",
        "  # remove roman numerals, first capitalized ones\n",
        "  result = re.sub(r'\\s((I{2,}V*X*\\.*)|(IV\\.*)|(IX\\.*)|(V\\.*)|(V+I*\\.*)|(X+L*V*I*]\\.*))\\s', ' ', result)\n",
        "  # then lowercase\n",
        "  result = re.sub(r'\\s((i{2,}v*x*\\.*)|(iv\\.*)|(ix\\.*)|(v\\.*)|(v+i*\\.*)|(x+l*v*i*\\.*))\\s', ' ', result)\n",
        "\n",
        "  # remove periods and commas flanked by numbers\n",
        "  result = re.sub(r'\\d\\.\\d', ' ', result)\n",
        "  result = re.sub(r'\\d,\\d', ' ', result)\n",
        "\n",
        "  # remove the number-letter-number pattern used for many citations\n",
        "  result = re.sub(r'\\d*\\w{,2}\\d', ' ', result)\n",
        "\n",
        "  # remove numerical characters\n",
        "  result = re.sub(r'\\d+', ' ', result)\n",
        "\n",
        "  # remove words of 2+ characters that are entirely capitalized \n",
        "  # (these are almost always titles, headings, or speakers in a dialogue)\n",
        "  # remove capital I's that follow capital words - these almost always roman numerals\n",
        "  # some texts do use these capitalizations meaningfully, so we make this optional\n",
        "  if capitals:\n",
        "    result = re.sub(r'[A-Z]{2,}\\s+I', ' ', result)\n",
        "    result = re.sub(r'[A-Z]{2,}', ' ', result)\n",
        "\n",
        "  # remove isolated colons and semicolons that result from removal of titles\n",
        "  result = re.sub(r'\\s+:\\s*', ' ', result)\n",
        "  result = re.sub(r'\\s+;\\s*', ' ', result)\n",
        "\n",
        "  # remove isolated letters (do it several times because strings of isolated letters do not get captured properly)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "\n",
        "  # remove isolated letters at the end of sentences or before commas\n",
        "  result = re.sub(r'\\s[^aI]\\.', '.', result)\n",
        "  result = re.sub(r'\\s[^aI],', ',', result)\n",
        "\n",
        "  # deal with spaces around periods and commas\n",
        "  result = re.sub(r'\\s+,\\s+', ', ', result)\n",
        "  result = re.sub(r'\\s+\\.\\s+', '. ', result)\n",
        "\n",
        "  # remove empty parantheses\n",
        "  result = re.sub(r'(\\(\\s*\\.*\\s*\\))|(\\(\\s*,*\\s*)\\)', ' ', result)\n",
        "  result = re.sub(r'\\.\\)\\.', '.', result)\n",
        "  result = re.sub(r'\\.\\(\\.', '.', result)\n",
        "\n",
        "  # reduce multiple periods, commas, or whitespaces into a single one\n",
        "  result = re.sub(r'\\.+', '.', result)\n",
        "  result = re.sub(r',+', ',', result)\n",
        "  result = re.sub(r'\\s+', ' ', result)\n",
        "\n",
        "  # deal with isolated problem cases discovered in the data:\n",
        "  for key in odd_words_dict.keys():\n",
        "    result = re.sub(r''+key+'', odd_words_dict[key], result)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OjRlTV_EEHM"
      },
      "source": [
        "# note extras like bracketed footnotes or specific words to remove\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y9RIRBED-F"
      },
      "source": [
        "# build a dictionary for the book\n",
        "seneca_on_benefits_dict = {\n",
        "    'author': 'Seneca',\n",
        "    'title': 'On Benefits',\n",
        "    'text': seneca_on_benefits,\n",
        "    'school': 'Stoicism',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 59,\n",
        "    'corpus date': 2017\n",
        "}\n",
        "\n",
        "seneca_on_anger_dict = {\n",
        "    'author': 'Seneca',\n",
        "    'title': 'On Anger',\n",
        "    'text': seneca_on_anger,\n",
        "    'school': 'Stoicism',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 45,\n",
        "    'corpus date': 2017\n",
        "}\n",
        "\n",
        "seneca_on_clemency_dict = {\n",
        "    'author': 'Seneca',\n",
        "    'title': 'On Clemency',\n",
        "    'text': seneca_on_clemency,\n",
        "    'school': 'Stoicism',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 55,\n",
        "    'corpus date': 2017\n",
        "}"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fkWlxhoIOjA",
        "cellView": "form"
      },
      "source": [
        "#@title Oddities Dictionary for Cleaning\n",
        "# a dictionary of oddities to clean up\n",
        "odd_words_dict = {'\\sderstanding': 'derstanding',\n",
        "                  '\\sditference\\s': ' difference ',\n",
        "                  '\\sforthe\\s': ' for the ',\n",
        "                  '\\sject': 'ject',\n",
        "                  '\\sSure ly\\s': ' Surely ',\n",
        "                  '\\spiness': 'piness',\n",
        "                  '\\sjects': 'jects', \n",
        "                  '\\sness': 'ness',\n",
        "                  '\\schil dren\\s': ' children ',\n",
        "                  '\\sper\\scent\\s': ' percent ',\n",
        "                  '\\sper\\scent\\.': ' percent.',\n",
        "                  '\\sper\\scent,': ' percent,',\n",
        "                  '\\wi\\son': 'ion',\n",
        "                  '\\spri\\sori': ' priori',\n",
        "                  '\\stences\\s': 'tences ',\n",
        "                  '\\sprincipleb': ' principle',\n",
        "                  '\\ssciousness': 'sciousness',\n",
        "                  '\\stion': 'tion',\n",
        "                  '\\spri\\s': ' pri',\n",
        "                  '\\scluding': 'cluding',\n",
        "                  '\\sdom': 'dom',\n",
        "                  '\\sers': 'ers',\n",
        "                  '\\scritiq\\s': ' critique ',\n",
        "                  '\\ssensati\\s': ' sensation ',\n",
        "                  '(?i)\\syou\\sll': \" you'll\",\n",
        "                  '\\sI\\sll': \" I'll\",\n",
        "                  '(?i)\\swe\\sll': \" we'll\",\n",
        "                  '(?i)he\\sll': \" he'll\",\n",
        "                  '(?i)who\\sll': \"who'll\",\n",
        "                  '(?i)\\sthere\\sll\\s': \" there'll \",\n",
        "                  '\\seduca\\s': ' education ',\n",
        "                  '\\slity\\s': 'lity ',\n",
        "                  '\\smultaneously\\s': 'multaneously ',\n",
        "                  '\\stically\\s': 'tically ',\n",
        "                  '\\sDa\\ssein\\s': ' Dasein ',\n",
        "                  '(?i)\\sthey\\sll\\s': \" they'll \",\n",
        "                  '(?i)\\sin\\tum\\s': ' in turn ',\n",
        "                  '\\scon~\\s': ' con',\n",
        "                  '\\sà\\s': ' a ',\n",
        "                  '\\sjor\\s': ' for ',\n",
        "                  '\\sluminating\\s': 'luminating ',\n",
        "                  '\\sselj\\s': ' self ',\n",
        "                  '\\stial\\s': 'tial ',\n",
        "                  '\\sversal\\s': 'versal ',\n",
        "                  '\\sexis\\st': ' exist',\n",
        "                  '\\splauded\\s': 'plauded ',\n",
        "                  '\\suiry\\s': 'uiry ',\n",
        "                  '\\svithin\\s': ' within ',\n",
        "                  '\\soj\\s': ' of ',\n",
        "                  '\\sposi\\st': ' posit',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '(?i)\\sthat\\sll\\s': \" that'll \",\n",
        "                  '(?i)\\sa\\sll\\s': ' all ',\n",
        "                  '\\so\\sther\\s': ' other ',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '\\snei\\sther\\s': ' neither ',\n",
        "                  '\\sei\\sther\\s': ' either ',\n",
        "                  '\\sfur\\sther\\s': ' further ',\n",
        "                  '\\sano\\sther': ' another ',\n",
        "                  '\\sneces\\s': ' neces',\n",
        "                  'u\\slar\\s': 'ular ',\n",
        "                  '\\sference\\s': 'ference ',\n",
        "                  '(?i)it\\sll\\s': \"it'll \",\n",
        "                  '\\stoge\\sther': ' together ',\n",
        "                  '\\sknowledgeb\\s': ' knowledge ',\n",
        "                  'r\\stain\\s': 'rtain ',\n",
        "                  'on\\stain\\s': 'ontain',\n",
        "                  '(?i)j\\sect\\s': 'ject',\n",
        "                  '\\sob\\sect\\s': ' object ',\n",
        "                  '\\sbtle\\s': 'btle ',\n",
        "                  '\\snition\\s': 'nition ',\n",
        "                  '\\sdering\\s': 'dering ', \n",
        "                  '\\sized\\s': 'ized ',\n",
        "                  '\\sther\\shand': ' other hand',\n",
        "                  '\\ture\\s': 'ture ',\n",
        "                  '\\sabso\\sl': ' absol',\n",
        "                  '\\stly\\s': 'tly ',\n",
        "                  '\\serty\\s': 'erty ',\n",
        "                  '\\sobj\\se': ' obj',\n",
        "                  '\\sffiir\\s': ' for ',\n",
        "                  '\\sndeed\\s': ' indeed ',\n",
        "                  '\\sfonn\\s': ' form ',\n",
        "                  '\\snally\\s': 'nally ',\n",
        "                  'ain\\sty\\s': 'ainty ',\n",
        "                  'ici\\sty\\s': 'icity ',\n",
        "                  '\\scog\\sni': ' cogni',\n",
        "                  '\\sacc\\s': ' acc',\n",
        "                  '\\sindi\\svid\\sual': ' individual', \n",
        "                  '\\sintu\\sit': ' intuit',\n",
        "                  'r\\sance\\s': 'rance ',\n",
        "                  '\\ssions\\s': 'sions ',\n",
        "                  '\\sances\\s': 'ances ',\n",
        "                  '\\sper\\sception\\s': ' perception ',\n",
        "                  '\\sse\\sries\\s': ' series ',\n",
        "                  '\\sque\\sries\\s': ' queries ',\n",
        "                  '\\sessary\\s': 'essary ',\n",
        "                  '\\sofa\\s': ' of a ',\n",
        "                  '\\scer\\stainty\\s': ' certainty ',\n",
        "                  'ec\\stivity\\s': 'ectivity ',\n",
        "                  '\\stivity\\s': 'tivity ',\n",
        "                  '\\slation\\s': 'lation ',\n",
        "                  '\\sir\\sr': ' irr',\n",
        "                  '\\ssub\\sstance\\s': ' substance ',\n",
        "                  'sec\\sond\\s': 'second ',\n",
        "                  '\\s\\.rv': '',\n",
        "                  '\\story\\s': 'tory ',\n",
        "                  '\\sture\\s': 'ture ',\n",
        "                  '\\sminate\\s': 'minate ',\n",
        "                  '\\sing\\s': 'ing ',\n",
        "                  '\\splicity\\s': 'plicity ',\n",
        "                  '\\ssimi\\slar\\s': ' similar ',\n",
        "                  '\\scom\\smunity\\s': ' community ',\n",
        "                  '\\sitselfa\\s': ' itself a ',\n",
        "                  '\\ssimp\\s': ' simply ',\n",
        "                  '\\scon\\stex': ' contex',\n",
        "                  '\\scon\\sseq': ' conseq',\n",
        "                  '\\scon\\stai': ' contai',\n",
        "                  '\\sofwhat\\s': ' of what ',\n",
        "                  '\\sui\\s': 'ui',\n",
        "                  '\\sofan\\s': ' of an ',\n",
        "                  '\\saccor\\sdance\\s': ' accordance ',\n",
        "                  '\\stranscen\\sdental\\s': ' transcendental ',\n",
        "                  '\\sap\\spearances\\s': ' appearances ',\n",
        "                  'e\\squences\\s': 'equences ',\n",
        "                  '\\sorits\\s': ' or its ',\n",
        "                  '\\simma\\sn': ' imman',\n",
        "                  '\\seq\\sua': ' equa',\n",
        "                  '\\simpl\\sied\\s': ' implied ',\n",
        "                  '\\sbuta\\s': ' but a ',\n",
        "                  '\\sa\\snd\\s': ' and ',\n",
        "                  '\\sence\\s': 'ence ',\n",
        "                  '\\stain\\s': 'tain ',\n",
        "                  '\\sunder\\sstanding\\s': ' understanding ',\n",
        "                  'i\\sence\\s': 'ience ',\n",
        "                  'r\\sence\\s': 'rence ',\n",
        "                  '\\stical\\s': 'tical ',\n",
        "                  '\\sobjectsb\\s': ' objects ',\n",
        "                  '\\stbe\\s': ' the ',\n",
        "                  '\\smul\\st': ' mult',\n",
        "                  '\\sgen\\seral\\s': ' general ',\n",
        "                  '\\suniver\\ssal\\s': ' universal ',\n",
        "                  '\\scon\\stent\\s': ' content ',\n",
        "                  '\\spar\\sticular\\s': ' particular ',\n",
        "                  'ver\\ssity\\s': 'versity ',\n",
        "                  '\\sCritiq\\s': ' Critique ',\n",
        "                  '\\sphilo\\ssophy\\s': ' philosophy ',\n",
        "                  '\\seq\\s': ' eq'}"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXDII00UED1c"
      },
      "source": [
        "# a function that takes the dictionary and returns a dataframe of sentences\n",
        "def from_raw_to_df(text_dict):\n",
        "  nlp.max_length = 9000000\n",
        "  text = text_dict['text']\n",
        "  text = remove_words(text, text_dict['words to remove'])\n",
        "  text = baseline_clean(text, capitals=text_dict['remove capitals'],\n",
        "                        bracketed_fn=text_dict['bracketed fn'],\n",
        "                        odd_words_dict=odd_words_dict)\n",
        "  text_nlp = nlp(text, disable=['ner'])\n",
        "  text_df = pd.DataFrame(columns=['title', 'author', 'school', 'sentence_spacy'])\n",
        "  text_df['sentence_spacy'] = list(text_nlp.sents)\n",
        "  text_df['author'] = text_dict['author']\n",
        "  text_df['title'] = text_dict['title']\n",
        "  text_df['school'] = text_dict['school']\n",
        "  text_df['original_publication_date'] = text_dict['original date']\n",
        "  text_df['corpus_edition_date'] = text_dict['corpus date']\n",
        "  text_df['sentence_str'] = text_df['sentence_spacy'].apply(lambda x: ''.join(list(str(x))))\n",
        "  return text_df"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w14qMlTrFM4s"
      },
      "source": [
        "# use the function\n",
        "on_benefits_df = from_raw_to_df(seneca_on_benefits_dict)\n",
        "on_anger_df = from_raw_to_df(seneca_on_anger_dict)\n",
        "on_clemency_df = from_raw_to_df(seneca_on_clemency_dict)\n",
        "\n",
        "df = on_benefits_df.append(on_anger_df, ignore_index=True).append(on_clemency_df, ignore_index=True)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IZ3JhAyNFept",
        "outputId": "223486eb-20ae-4aa9-8d07-5465f459d5f6"
      },
      "source": [
        "# checking the result\n",
        "pd.options.display.max_colwidth = 200\n",
        "df.sample(10)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2911</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(They, look, presently, about, them, from, one, to, another, ,, as, who, should, say, ;, ', Do, but, see, ,, my, masters, ,, how, these, rogues, abuse, us, ., ')</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>They look presently about them from one to another, as who should say; 'Do but see, my masters, how these rogues abuse us.'</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Two, persons, may, part, with, the, same, sum, of, money, ,, and, yet, not, the, same, benefit, :, the, one, had, it, of, his, own, and, it, was, but, a, little, out, of, a, great, deal, the, oth...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>Two persons may part with the same sum of money, and yet not the same benefit: the one had it of his own and it was but a little out of a great deal the other borrowed it, and bestowed upon me tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(He, that, is, not, illustrious, in, himself, ,, may, yet, be, reputed, so, in, the, right, of, his, ancestors, :, and, there, is, a, gratitude, to, be, entailed, upon, the, offspring, of, famous,...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>He that is not illustrious in himself, may yet be reputed so in the right of his ancestors: and there is a gratitude to be entailed upon the offspring of famous progenitors.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2858</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(How, happy, is, he, that, owes, nothing, but, to, himself, ,, and, only, that, which, he, can, easily, refuse, or, easily, pay, !)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>How happy is he that owes nothing but to himself, and only that which he can easily refuse or easily pay!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3314</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Neither, are, we, moved, at, the, impudence, and, bitterness, of, a, buffoon, though, he, fall, upon, his, own, master, as, well, as, the, guests, ;, but, ,, on, the, contrary, ,, we, encourage, ...</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>Neither are we moved at the impudence and bitterness of a buffoon though he fall upon his own master as well as the guests; but, on the contrary, we encourage and entertain the freedom.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3706</th>\n",
              "      <td>On Clemency</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(It, would, tire, them, out, ,, if, either, they, were, to, execute, all, with, their, own, hands, ,, or, to, wound, others, at, the, peril, of, their, own, lives, .)</td>\n",
              "      <td>55</td>\n",
              "      <td>2017</td>\n",
              "      <td>It would tire them out, if either they were to execute all with their own hands, or to wound others at the peril of their own lives.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>604</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(The, counsels, of, a, wise, man, are, certain, ,, but, events, are, uncertain, :, and, yet, if, I, have, passed, a, rash, promise, ,, I, will, in, some, degree, punish, the, temerity, of, making,...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>The counsels of a wise man are certain, but events are uncertain: and yet if I have passed a rash promise, I will in some degree punish the temerity of making it with the damage of keeping it, unl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1150</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Socrates, looked, a, scandalous, death, in, the, face, with, the, same, constancy, that, he, had, before, practiced, towards, the, thirty, tyrants, :)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>Socrates looked a scandalous death in the face with the same constancy that he had before practiced towards the thirty tyrants:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2465</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(To, have, it, said, ', that, such, a, one, is, never, out, of, his, study, ,, and, sees, nobody, ,, ', etc, ., ;, this, furnishes, matter, for, discourse, .)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>To have it said 'that such a one is never out of his study, and sees nobody,' etc.; this furnishes matter for discourse.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3021</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(There, is, nothing, great, but, what, is, virtuous, ,, nor, indeed, truly, great, ,, but, what, is, also, composed, and, quiet, .)</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>There is nothing great but what is virtuous, nor indeed truly great, but what is also composed and quiet.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  ...                                                                                                                                                                                             sentence_str\n",
              "2911     On Anger  ...                                                                              They look presently about them from one to another, as who should say; 'Do but see, my masters, how these rogues abuse us.'\n",
              "239   On Benefits  ...  Two persons may part with the same sum of money, and yet not the same benefit: the one had it of his own and it was but a little out of a great deal the other borrowed it, and bestowed upon me tha...\n",
              "392   On Benefits  ...                            He that is not illustrious in himself, may yet be reputed so in the right of his ancestors: and there is a gratitude to be entailed upon the offspring of famous progenitors.\n",
              "2858  On Benefits  ...                                                                                                How happy is he that owes nothing but to himself, and only that which he can easily refuse or easily pay!\n",
              "3314     On Anger  ...                Neither are we moved at the impudence and bitterness of a buffoon though he fall upon his own master as well as the guests; but, on the contrary, we encourage and entertain the freedom.\n",
              "3706  On Clemency  ...                                                                     It would tire them out, if either they were to execute all with their own hands, or to wound others at the peril of their own lives.\n",
              "604   On Benefits  ...  The counsels of a wise man are certain, but events are uncertain: and yet if I have passed a rash promise, I will in some degree punish the temerity of making it with the damage of keeping it, unl...\n",
              "1150  On Benefits  ...                                                                          Socrates looked a scandalous death in the face with the same constancy that he had before practiced towards the thirty tyrants:\n",
              "2465  On Benefits  ...                                                                                 To have it said 'that such a one is never out of his study, and sees nobody,' etc.; this furnishes matter for discourse.\n",
              "3021     On Anger  ...                                                                                                There is nothing great but what is virtuous, nor indeed truly great, but what is also composed and quiet.\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZMqd8G0Ra-1",
        "outputId": "78658db6-9459-41c9-ba9f-78fdd74a9c2a"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3810"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-mqOl9pFgwH"
      },
      "source": [
        "#### Remove Short Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "EfYhrwWuFzOl",
        "outputId": "5ff8e979-5582-481e-e681-aaa23b85cd1c"
      },
      "source": [
        "df['sentence_length'] = df['sentence_str'].map(lambda x: len(x))\n",
        "num_of_short_entries = len(df[df['sentence_length'] < 20])\n",
        "print(f\"there are {num_of_short_entries} so-called sentences with fewer than 20 characters\")\n",
        "df[df['sentence_length'] < 20].sample(5)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 72 so-called sentences with fewer than 20 characters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(the, brother, ?)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>the brother?</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2592</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(how, well, .)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>how well.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2396</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Alas, !)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>Alas!</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(And, it, is, but)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>And it is but</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(the, mother, ?)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>the mother?</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  author  ...   sentence_str sentence_length\n",
              "366   On Benefits  Seneca  ...   the brother?              12\n",
              "2592  On Benefits  Seneca  ...      how well.               9\n",
              "2396  On Benefits  Seneca  ...          Alas!               5\n",
              "403   On Benefits  Seneca  ...  And it is but              13\n",
              "369   On Benefits  Seneca  ...    the mother?              11\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW0AZpVyF1Qk",
        "outputId": "f7555dd1-21eb-43c4-86c1-3d0cb14ae46f"
      },
      "source": [
        "df = df.drop(df[df['sentence_length'] < 20].index)\n",
        "len(df)"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX9UfoDtF3Lz"
      },
      "source": [
        "#### Remove Cases of Self-Mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "LJnDfK9IF8hU",
        "outputId": "874127a2-0945-47df-cc36-1c8c16011bb1"
      },
      "source": [
        "# change the author name in this cell \n",
        "\n",
        "self_mentions = df[df['sentence_str'].str.contains('\\s'+'Anselm'.lower())]\n",
        "print(len(self_mentions))\n",
        "self_mentions"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, author, school, sentence_spacy, original_publication_date, corpus_edition_date, sentence_str, sentence_length]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt86zZ3RF8q8",
        "outputId": "80981f34-c2b1-46f8-86d6-529d85adf6ac"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].str.contains('\\s'+'Augustine'.lower())].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vglbGXSFF8y4"
      },
      "source": [
        "#### Deal with Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRXjQSIQHpa-",
        "outputId": "8cf5303c-b234-4a25-a5e7-86cc5feaaa3f"
      },
      "source": [
        "# find the total number of duplicates\n",
        "len(df['sentence_str'])-len(df['sentence_str'].drop_duplicates())"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "sHn4mTy2TR3P",
        "outputId": "0ed1e806-33e5-4db2-9a09-e598a7f9c775"
      },
      "source": [
        "doubles_df = pd.concat(g for _, g in df.groupby(\"sentence_str\") if len(g) > 1)\n",
        "doubles_df"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c58ecf086ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoubles_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentence_str\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoubles_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-7vXDjTh0s"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].duplicated(keep='first')].index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFT73wJCThrT"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HnVnn1WHrTW"
      },
      "source": [
        "#### Check for Foreign Languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVcwhudjH5jY"
      },
      "source": [
        "# checking for 'der', a common article in German\n",
        "len((df[df['sentence_str'].str.contains('\\sder\\s')]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBzPHm8PH4XB"
      },
      "source": [
        "# checking for 'il', a common article in French\n",
        "len(df[df['sentence_str'].str.contains('\\sil\\s')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxWbjI0IiAzE"
      },
      "source": [
        "#### Some Ad Hoc Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8YsiZc_h-iu"
      },
      "source": [
        "# miscellaneous nonsense sentences\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\spp\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\stotam\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\srree\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sflir\\s')].index)\n",
        "df = df.drop(df[(df['sentence_str'].str.contains('\\smodis\\s')) & (df['author'] != 'Kant')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwQzpQ2_iJEU"
      },
      "source": [
        "# markers of french and notes\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\schapitre')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\salisme')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sHahn')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcQoVnariNWg"
      },
      "source": [
        "# some notes in Kant\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sVorl\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sberschwenglich')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI3dJy_dibCA"
      },
      "source": [
        "# a common phrase in Plato / Aristotle footnotes\n",
        "df = df.drop(df[(df['author']=='Plato') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "df = df.drop(df[(df['author']=='Aristotle') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DUt3mAjtigKB"
      },
      "source": [
        "# mentions of Aristotle in Plato\n",
        "df = df.drop(df[(df['author']=='Plato') & df['sentence_str'].str.contains('Aristotle')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sd2rbDJHraR"
      },
      "source": [
        "### Lemmatize and Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLKswX_Hrhd"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# use gensim to tokenize sentences\n",
        "df['tokenized_txt'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
        "                                                        max_len=200))\n",
        "\n",
        "# use spacey to get intelligent lemmatization\n",
        "def lemmatize_sentence(sentence):\n",
        "  lemmatized_txt = ''\n",
        "  for word in sentence:\n",
        "    lemmatized_txt += ' ' + str(word.lemma_)\n",
        "  return lemmatized_txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sg_V1rxIdzJ"
      },
      "source": [
        "df['lemmatized_str'] = df['sentence_spacy'].apply(lemmatize_sentence)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pyznlhXId8n"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOxPwDpIeDT"
      },
      "source": [
        "### Combine with the Old Dataframe & Export to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU8QqgIXInkp"
      },
      "source": [
        "# load the old version and check it out\n",
        "og_df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/philosophy_data.csv')\n",
        "og_df.sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfwEX5vzInx0"
      },
      "source": [
        "og_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1wqPSYwsrBN"
      },
      "source": [
        "len(og_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQcxBh37IoDJ"
      },
      "source": [
        "# append the new data\n",
        "new_df = og_df.append(df)\n",
        "new_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwgCHszFf6_p"
      },
      "source": [
        "new_df[new_df['author']=='Seneca'].sample(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncmXLdXuIoMl"
      },
      "source": [
        "# export as csv\n",
        "from google.colab import files\n",
        "new_df.to_csv('phil_nlp.csv', index=False) \n",
        "files.download('phil_nlp.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz0aj3NrECm3"
      },
      "source": [
        "###Upload Data to the SQL Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "bW76POWkJL-b",
        "outputId": "71bab1dc-6010-408c-cfab-94024b39f954"
      },
      "source": [
        "# prepare to upload to the PostgreSQL database\n",
        "\n",
        "# note which dataframe you set this to - new_df for the whole dataset, df for \n",
        "# just the new text\n",
        "\n",
        "for_db = new_df\n",
        "for_db['date'] = for_db['original_publication_date']\n",
        "for_db['date'] = for_db['date'].apply(lambda x: str(x)[1:]+' BC' if x < 0 else str(x))\n",
        "for_db['sentence'] = for_db['sentence_str']\n",
        "for_db['school'] = for_db['school'].apply(lambda x: x.replace('_', ' ').title())\n",
        "for_db = for_db.drop(['sentence_spacy', \n",
        "                      'sentence_length',\n",
        "                      'sentence_lowered', \n",
        "                      'sentence_str', \n",
        "                      'tokenized_txt', \n",
        "                      'lemmatized_str',\n",
        "                      'corpus_edition_date',\n",
        "                      'original_publication_date'], axis=1)\n",
        "for_db.columns = [i.upper() for i in for_db.columns]\n",
        "\n",
        "for_db.sample(5)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>SCHOOL</th>\n",
              "      <th>DATE</th>\n",
              "      <th>SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>51317</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>320 BC</td>\n",
              "      <td>Indeed those animals which are hottest in the belly have the hottest excreta.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16994</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>Plato</td>\n",
              "      <td>350 BC</td>\n",
              "      <td>And has been for two days.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215256</th>\n",
              "      <td>Anti-Oedipus</td>\n",
              "      <td>Deleuze</td>\n",
              "      <td>Continental</td>\n",
              "      <td>1972</td>\n",
              "      <td>Such neurosis, the displacement of the limit, in order to create a little colon al world of one's own.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170976</th>\n",
              "      <td>The Logic Of Scientific Discovery</td>\n",
              "      <td>Popper</td>\n",
              "      <td>Analytic</td>\n",
              "      <td>1959</td>\n",
              "      <td>The Theory of Groups and Quantum Mechanics,.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328316</th>\n",
              "      <td>Meditations</td>\n",
              "      <td>Marcus Aurelius</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>170</td>\n",
              "      <td>(if he have any wit at all) can in a manner (for that they are all of one kind)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    TITLE  ...                                                                                                SENTENCE\n",
              "51317          Aristotle - Complete Works  ...                           Indeed those animals which are hottest in the belly have the hottest excreta.\n",
              "16994              Plato - Complete Works  ...                                                                              And has been for two days.\n",
              "215256                       Anti-Oedipus  ...  Such neurosis, the displacement of the limit, in order to create a little colon al world of one's own.\n",
              "170976  The Logic Of Scientific Discovery  ...                                                            The Theory of Groups and Quantum Mechanics,.\n",
              "328316                        Meditations  ...                         (if he have any wit at all) can in a manner (for that they are all of one kind)\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWSVKbmoVaAW",
        "outputId": "1cc1c8cf-4ef3-44fe-a307-9f69d5149200"
      },
      "source": [
        "len(for_db)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "369599"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mni3N-fyK-jZ",
        "outputId": "f9927aaf-2b85-4439-cac9-f807c95dbef4"
      },
      "source": [
        "#importing sql library \n",
        "from sqlalchemy import create_engine \n",
        "  \n",
        "# create a reference  \n",
        "# for sql library \n",
        "engine = create_engine('post',\n",
        "                       echo=False)\n",
        "  \n",
        "# attach the data frame to the sql server \n",
        "for_db.to_sql('phil_nlp', \n",
        "               con = engine,\n",
        "              if_exists='replace',\n",
        "              index=False,\n",
        "              method='multi') \n",
        "  \n",
        "# show the completed data as a test\n",
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp WHERE \"AUTHOR\" = 'Seneca'\"\"\").fetchone()) "
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('On Benefits', 'Seneca', 'Stoicism', '59', 'and so in infinitum.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRYDdaLGW2"
      },
      "source": [
        "Remember to add to the clipping and other elements to the notebook that creates the database as a whole. Then you're done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK50YeA-LNtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd40c3c1-0018-4553-f18a-5cd643819b15"
      },
      "source": [
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp where \"AUTHOR\" = 'Anselm'\"\"\").fetchone()) "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Proslogion', 'Anselm', 'Scholasticism', '1077', 'How is it, then, Lord, that You are all these things?')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfaWbJkCid6W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}