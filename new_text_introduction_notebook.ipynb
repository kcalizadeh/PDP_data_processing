{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_text_introduction_notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMbm6Bvrvc79pz0LcdiBaJA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/PDP_data_processing/blob/master/new_text_introduction_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cw_rJlXCob_"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN4DvDsxCdio",
        "outputId": "26767b6c-ee09-4db4-bf38-2fc77d13a052"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\n",
        "# and relevant libraries via the functions.py file\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/philosophy_data_project'\n",
        "\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAk2WGLbCn3t"
      },
      "source": [
        "from import_functions import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV19sbpUC2PF",
        "outputId": "ef7d0744-8feb-4576-ba5c-ab89d7863651"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbT8yZ0pC30A"
      },
      "source": [
        "###Load the Text and Clip Front and End Matter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-MzN2T2DUYm"
      },
      "source": [
        "# if you are deleting an old text that was added here, make sure it is in the \n",
        "# primary database construction notebook\n",
        "seneca_all_texts = get_guten('http://www.gutenberg.org/files/56075/56075-0.txt')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuWrhYwOUbck"
      },
      "source": [
        "seneca_on_benefits = seneca_all_texts.split('SENECA OF BENEFITS')[1][54:].split('SENECA OF ANGER')[0]\n",
        "seneca_on_anger = seneca_all_texts.split('SENECA OF ANGER')[1][95:].split('SENECA OF CLEMENCY')[0]\n",
        "seneca_on_clemency = seneca_all_texts.split('SENECA OF CLEMENCY')[1][7:].split('Obvious typographical errors have been corre')[0][:-80]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suHuy6isDUiC"
      },
      "source": [
        "### Clean the Text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfFHzvnDUpf"
      },
      "source": [
        "def baseline_clean(to_correct, \n",
        "                   capitals=True, \n",
        "                   bracketed_fn=False, \n",
        "                   odd_words_dict={}):\n",
        "  # remove utf8 encoding characters and some punctuations\n",
        "  result = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6§\\\\\\£\\Â*_<>\"\"⎫•{}Γ~]', ' ', to_correct)\n",
        "  result = re.sub(r'[\\u2014\\u2013\\u2012-]', ' ', result)\n",
        "\n",
        "  # replace whitespace characters with actual whitespace\n",
        "  result = re.sub(r'\\s', ' ', result)\n",
        "\n",
        "  # replace odd quotation marks with a standard\n",
        "  result = re.sub(r'[‘’“”]', \"'\", result)\n",
        "\n",
        "  # replace the ﬀ, ﬃ and ﬁ with the appropriate counterparts\n",
        "  result = re.sub(r'ﬀ', 'ff', result)\n",
        "  result = re.sub(r'ﬁ', 'fi', result)\n",
        "  result = re.sub(r'ﬃ', 'ffi', result)\n",
        "\n",
        "  # replace some accented characters for ease of searching\n",
        "  result = re.sub(r'é', 'e', result)\n",
        "\n",
        "  # remove or standardize some recurring common and meaninless words/phrases\n",
        "  result = re.sub(r'\\s*This\\s*page\\s*intentionally\\s*left\\s*blank\\s*', ' ', result)\n",
        "  result = re.sub(r'(?i)Aufgabe\\s+', ' ', result)\n",
        "  result = re.sub(r',*\\s+cf\\.', ' ', result)\n",
        "\n",
        "  # some texts have footnotes conveniently in brackets - this removes them all, \n",
        "  # with a safety measure for unpaired brackets, and deletes all brackets afterwards\n",
        "  if bracketed_fn:\n",
        "    result = re.sub(r'\\[.{0,300}\\]|{.{0,300}}|{.{0,300}\\]|\\[.{0,300}}', ' ', result)\n",
        "  result = re.sub(r'[\\[\\]{}]', ' ', result)\n",
        "\n",
        "  # unify some abbreviations\n",
        "  result = re.sub(r'&', 'and', result)\n",
        "  result = re.sub(r'\\se\\.g\\.\\s', ' eg ', result)\n",
        "  result = re.sub(r'\\si\\.e\\.\\s', ' ie ', result)\n",
        "  result = re.sub('coroll\\.', 'coroll', result)\n",
        "  result = re.sub('pt\\.', 'pt', result)\n",
        "\n",
        "  # remove roman numerals, first capitalized ones\n",
        "  result = re.sub(r'\\s((I{2,}V*X*\\.*)|(IV\\.*)|(IX\\.*)|(V\\.*)|(V+I*\\.*)|(X+L*V*I*]\\.*))\\s', ' ', result)\n",
        "  # then lowercase\n",
        "  result = re.sub(r'\\s((i{2,}v*x*\\.*)|(iv\\.*)|(ix\\.*)|(v\\.*)|(v+i*\\.*)|(x+l*v*i*\\.*))\\s', ' ', result)\n",
        "\n",
        "  # remove periods and commas flanked by numbers\n",
        "  result = re.sub(r'\\d\\.\\d', ' ', result)\n",
        "  result = re.sub(r'\\d,\\d', ' ', result)\n",
        "\n",
        "  # remove the number-letter-number pattern used for many citations\n",
        "  result = re.sub(r'\\d*\\w{,2}\\d', ' ', result)\n",
        "\n",
        "  # remove numerical characters\n",
        "  result = re.sub(r'\\d+', ' ', result)\n",
        "\n",
        "  # remove words of 2+ characters that are entirely capitalized \n",
        "  # (these are almost always titles, headings, or speakers in a dialogue)\n",
        "  # remove capital I's that follow capital words - these almost always roman numerals\n",
        "  # some texts do use these capitalizations meaningfully, so we make this optional\n",
        "  if capitals:\n",
        "    result = re.sub(r'[A-Z]{2,}\\s+I', ' ', result)\n",
        "    result = re.sub(r'[A-Z]{2,}', ' ', result)\n",
        "\n",
        "  # remove isolated colons and semicolons that result from removal of titles\n",
        "  result = re.sub(r'\\s+:\\s*', ' ', result)\n",
        "  result = re.sub(r'\\s+;\\s*', ' ', result)\n",
        "\n",
        "  # remove isolated letters (do it several times because strings of isolated letters do not get captured properly)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "\n",
        "  # remove isolated letters at the end of sentences or before commas\n",
        "  result = re.sub(r'\\s[^aI]\\.', '.', result)\n",
        "  result = re.sub(r'\\s[^aI],', ',', result)\n",
        "\n",
        "  # deal with spaces around periods and commas\n",
        "  result = re.sub(r'\\s+,\\s+', ', ', result)\n",
        "  result = re.sub(r'\\s+\\.\\s+', '. ', result)\n",
        "\n",
        "  # remove empty parantheses\n",
        "  result = re.sub(r'(\\(\\s*\\.*\\s*\\))|(\\(\\s*,*\\s*)\\)', ' ', result)\n",
        "  result = re.sub(r'\\.\\)\\.', '.', result)\n",
        "  result = re.sub(r'\\.\\(\\.', '.', result)\n",
        "\n",
        "  # reduce multiple periods, commas, or whitespaces into a single one\n",
        "  result = re.sub(r'\\.+', '.', result)\n",
        "  result = re.sub(r',+', ',', result)\n",
        "  result = re.sub(r'\\s+', ' ', result)\n",
        "\n",
        "  # deal with isolated problem cases discovered in the data:\n",
        "  for key in odd_words_dict.keys():\n",
        "    result = re.sub(r''+key+'', odd_words_dict[key], result)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OjRlTV_EEHM"
      },
      "source": [
        "# note extras like bracketed footnotes or specific words to remove\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y9RIRBED-F"
      },
      "source": [
        "# build a dictionary for the book\n",
        "seneca_on_benefits_dict = {\n",
        "    'author': 'Seneca',\n",
        "    'title': 'On Benefits',\n",
        "    'text': seneca_on_benefits,\n",
        "    'school': 'Stoicism',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 59,\n",
        "    'corpus date': 2017\n",
        "}\n",
        "\n",
        "seneca_on_anger_dict = {\n",
        "    'author': 'Seneca',\n",
        "    'title': 'On Anger',\n",
        "    'text': seneca_on_anger,\n",
        "    'school': 'Stoicism',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 45,\n",
        "    'corpus date': 2017\n",
        "}\n",
        "\n",
        "seneca_on_clemency_dict = {\n",
        "    'author': 'Seneca',\n",
        "    'title': 'On Clemency',\n",
        "    'text': seneca_on_clemency,\n",
        "    'school': 'Stoicism',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 55,\n",
        "    'corpus date': 2017\n",
        "}"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fkWlxhoIOjA",
        "cellView": "form"
      },
      "source": [
        "#@title Oddities Dictionary for Cleaning\n",
        "# a dictionary of oddities to clean up\n",
        "odd_words_dict = {'\\sderstanding': 'derstanding',\n",
        "                  '\\sditference\\s': ' difference ',\n",
        "                  '\\sforthe\\s': ' for the ',\n",
        "                  '\\sject': 'ject',\n",
        "                  '\\sSure ly\\s': ' Surely ',\n",
        "                  '\\spiness': 'piness',\n",
        "                  '\\sjects': 'jects', \n",
        "                  '\\sness': 'ness',\n",
        "                  '\\schil dren\\s': ' children ',\n",
        "                  '\\sper\\scent\\s': ' percent ',\n",
        "                  '\\sper\\scent\\.': ' percent.',\n",
        "                  '\\sper\\scent,': ' percent,',\n",
        "                  '\\wi\\son': 'ion',\n",
        "                  '\\spri\\sori': ' priori',\n",
        "                  '\\stences\\s': 'tences ',\n",
        "                  '\\sprincipleb': ' principle',\n",
        "                  '\\ssciousness': 'sciousness',\n",
        "                  '\\stion': 'tion',\n",
        "                  '\\spri\\s': ' pri',\n",
        "                  '\\scluding': 'cluding',\n",
        "                  '\\sdom': 'dom',\n",
        "                  '\\sers': 'ers',\n",
        "                  '\\scritiq\\s': ' critique ',\n",
        "                  '\\ssensati\\s': ' sensation ',\n",
        "                  '(?i)\\syou\\sll': \" you'll\",\n",
        "                  '\\sI\\sll': \" I'll\",\n",
        "                  '(?i)\\swe\\sll': \" we'll\",\n",
        "                  '(?i)he\\sll': \" he'll\",\n",
        "                  '(?i)who\\sll': \"who'll\",\n",
        "                  '(?i)\\sthere\\sll\\s': \" there'll \",\n",
        "                  '\\seduca\\s': ' education ',\n",
        "                  '\\slity\\s': 'lity ',\n",
        "                  '\\smultaneously\\s': 'multaneously ',\n",
        "                  '\\stically\\s': 'tically ',\n",
        "                  '\\sDa\\ssein\\s': ' Dasein ',\n",
        "                  '(?i)\\sthey\\sll\\s': \" they'll \",\n",
        "                  '(?i)\\sin\\tum\\s': ' in turn ',\n",
        "                  '\\scon~\\s': ' con',\n",
        "                  '\\sà\\s': ' a ',\n",
        "                  '\\sjor\\s': ' for ',\n",
        "                  '\\sluminating\\s': 'luminating ',\n",
        "                  '\\sselj\\s': ' self ',\n",
        "                  '\\stial\\s': 'tial ',\n",
        "                  '\\sversal\\s': 'versal ',\n",
        "                  '\\sexis\\st': ' exist',\n",
        "                  '\\splauded\\s': 'plauded ',\n",
        "                  '\\suiry\\s': 'uiry ',\n",
        "                  '\\svithin\\s': ' within ',\n",
        "                  '\\soj\\s': ' of ',\n",
        "                  '\\sposi\\st': ' posit',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '(?i)\\sthat\\sll\\s': \" that'll \",\n",
        "                  '(?i)\\sa\\sll\\s': ' all ',\n",
        "                  '\\so\\sther\\s': ' other ',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '\\snei\\sther\\s': ' neither ',\n",
        "                  '\\sei\\sther\\s': ' either ',\n",
        "                  '\\sfur\\sther\\s': ' further ',\n",
        "                  '\\sano\\sther': ' another ',\n",
        "                  '\\sneces\\s': ' neces',\n",
        "                  'u\\slar\\s': 'ular ',\n",
        "                  '\\sference\\s': 'ference ',\n",
        "                  '(?i)it\\sll\\s': \"it'll \",\n",
        "                  '\\stoge\\sther': ' together ',\n",
        "                  '\\sknowledgeb\\s': ' knowledge ',\n",
        "                  'r\\stain\\s': 'rtain ',\n",
        "                  'on\\stain\\s': 'ontain',\n",
        "                  '(?i)j\\sect\\s': 'ject',\n",
        "                  '\\sob\\sect\\s': ' object ',\n",
        "                  '\\sbtle\\s': 'btle ',\n",
        "                  '\\snition\\s': 'nition ',\n",
        "                  '\\sdering\\s': 'dering ', \n",
        "                  '\\sized\\s': 'ized ',\n",
        "                  '\\sther\\shand': ' other hand',\n",
        "                  '\\ture\\s': 'ture ',\n",
        "                  '\\sabso\\sl': ' absol',\n",
        "                  '\\stly\\s': 'tly ',\n",
        "                  '\\serty\\s': 'erty ',\n",
        "                  '\\sobj\\se': ' obj',\n",
        "                  '\\sffiir\\s': ' for ',\n",
        "                  '\\sndeed\\s': ' indeed ',\n",
        "                  '\\sfonn\\s': ' form ',\n",
        "                  '\\snally\\s': 'nally ',\n",
        "                  'ain\\sty\\s': 'ainty ',\n",
        "                  'ici\\sty\\s': 'icity ',\n",
        "                  '\\scog\\sni': ' cogni',\n",
        "                  '\\sacc\\s': ' acc',\n",
        "                  '\\sindi\\svid\\sual': ' individual', \n",
        "                  '\\sintu\\sit': ' intuit',\n",
        "                  'r\\sance\\s': 'rance ',\n",
        "                  '\\ssions\\s': 'sions ',\n",
        "                  '\\sances\\s': 'ances ',\n",
        "                  '\\sper\\sception\\s': ' perception ',\n",
        "                  '\\sse\\sries\\s': ' series ',\n",
        "                  '\\sque\\sries\\s': ' queries ',\n",
        "                  '\\sessary\\s': 'essary ',\n",
        "                  '\\sofa\\s': ' of a ',\n",
        "                  '\\scer\\stainty\\s': ' certainty ',\n",
        "                  'ec\\stivity\\s': 'ectivity ',\n",
        "                  '\\stivity\\s': 'tivity ',\n",
        "                  '\\slation\\s': 'lation ',\n",
        "                  '\\sir\\sr': ' irr',\n",
        "                  '\\ssub\\sstance\\s': ' substance ',\n",
        "                  'sec\\sond\\s': 'second ',\n",
        "                  '\\s\\.rv': '',\n",
        "                  '\\story\\s': 'tory ',\n",
        "                  '\\sture\\s': 'ture ',\n",
        "                  '\\sminate\\s': 'minate ',\n",
        "                  '\\sing\\s': 'ing ',\n",
        "                  '\\splicity\\s': 'plicity ',\n",
        "                  '\\ssimi\\slar\\s': ' similar ',\n",
        "                  '\\scom\\smunity\\s': ' community ',\n",
        "                  '\\sitselfa\\s': ' itself a ',\n",
        "                  '\\ssimp\\s': ' simply ',\n",
        "                  '\\scon\\stex': ' contex',\n",
        "                  '\\scon\\sseq': ' conseq',\n",
        "                  '\\scon\\stai': ' contai',\n",
        "                  '\\sofwhat\\s': ' of what ',\n",
        "                  '\\sui\\s': 'ui',\n",
        "                  '\\sofan\\s': ' of an ',\n",
        "                  '\\saccor\\sdance\\s': ' accordance ',\n",
        "                  '\\stranscen\\sdental\\s': ' transcendental ',\n",
        "                  '\\sap\\spearances\\s': ' appearances ',\n",
        "                  'e\\squences\\s': 'equences ',\n",
        "                  '\\sorits\\s': ' or its ',\n",
        "                  '\\simma\\sn': ' imman',\n",
        "                  '\\seq\\sua': ' equa',\n",
        "                  '\\simpl\\sied\\s': ' implied ',\n",
        "                  '\\sbuta\\s': ' but a ',\n",
        "                  '\\sa\\snd\\s': ' and ',\n",
        "                  '\\sence\\s': 'ence ',\n",
        "                  '\\stain\\s': 'tain ',\n",
        "                  '\\sunder\\sstanding\\s': ' understanding ',\n",
        "                  'i\\sence\\s': 'ience ',\n",
        "                  'r\\sence\\s': 'rence ',\n",
        "                  '\\stical\\s': 'tical ',\n",
        "                  '\\sobjectsb\\s': ' objects ',\n",
        "                  '\\stbe\\s': ' the ',\n",
        "                  '\\smul\\st': ' mult',\n",
        "                  '\\sgen\\seral\\s': ' general ',\n",
        "                  '\\suniver\\ssal\\s': ' universal ',\n",
        "                  '\\scon\\stent\\s': ' content ',\n",
        "                  '\\spar\\sticular\\s': ' particular ',\n",
        "                  'ver\\ssity\\s': 'versity ',\n",
        "                  '\\sCritiq\\s': ' Critique ',\n",
        "                  '\\sphilo\\ssophy\\s': ' philosophy ',\n",
        "                  '\\seq\\s': ' eq'}"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXDII00UED1c"
      },
      "source": [
        "# a function that takes the dictionary and returns a dataframe of sentences\n",
        "def from_raw_to_df(text_dict):\n",
        "  nlp.max_length = 9000000\n",
        "  text = text_dict['text']\n",
        "  text = remove_words(text, text_dict['words to remove'])\n",
        "  text = baseline_clean(text, capitals=text_dict['remove capitals'],\n",
        "                        bracketed_fn=text_dict['bracketed fn'],\n",
        "                        odd_words_dict=odd_words_dict)\n",
        "  text_nlp = nlp(text, disable=['ner'])\n",
        "  text_df = pd.DataFrame(columns=['title', 'author', 'school', 'sentence_spacy'])\n",
        "  text_df['sentence_spacy'] = list(text_nlp.sents)\n",
        "  text_df['author'] = text_dict['author']\n",
        "  text_df['title'] = text_dict['title']\n",
        "  text_df['school'] = text_dict['school']\n",
        "  text_df['original_publication_date'] = text_dict['original date']\n",
        "  text_df['corpus_edition_date'] = text_dict['corpus date']\n",
        "  text_df['sentence_str'] = text_df['sentence_spacy'].apply(lambda x: ''.join(list(str(x))))\n",
        "  return text_df"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w14qMlTrFM4s"
      },
      "source": [
        "# use the function\n",
        "on_benefits_df = from_raw_to_df(seneca_on_benefits_dict)\n",
        "on_anger_df = from_raw_to_df(seneca_on_anger_dict)\n",
        "on_clemency_df = from_raw_to_df(seneca_on_clemency_dict)\n",
        "\n",
        "df = on_benefits_df.append(on_anger_df, ignore_index=True).append(on_clemency_df, ignore_index=True)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IZ3JhAyNFept",
        "outputId": "117aae8a-9c04-4c22-af77-1f98181feebf"
      },
      "source": [
        "# checking the result\n",
        "pd.options.display.max_colwidth = 200\n",
        "df.sample(10)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(they, couch, their, meaning)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>they couch their meaning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1158</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(I, speak, of, those, that, fortune, has, made, famous, for, their, persecutions, :, and, there, are, others, also, that, the, world, never, took, notice, of, until, they, were, dead, ;, as, Epicu...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>I speak of those that fortune has made famous for their persecutions: and there are others also that the world never took notice of until they were dead; as Epicurus and Metrodorus, that were almo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1988</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(And, the, business, is, ,, we, do, not, understand, the, true, state, of, things, :, we, are, deceived, by, rumors, ;, when, we, have, gained, the, thing, we, aimed, at, ,, we, find, it, to, be, ...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>And the business is, we do not understand the true state of things: we are deceived by rumors; when we have gained the thing we aimed at, we find it to be either ill or empty; or perchance less th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2872</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(All, I, desire, is, that, my, property, may, not, be, a, burden, to, myself, ,, or, make, me, so, to, others, ;, and, that, is, the, best, state, of, fortune, that, is, neither, directly, necessi...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>All I desire is that my property may not be a burden to myself, or make me so to others; and that is the best state of fortune that is neither directly necessitous, nor far from it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1400</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(It, is, dangerous, for, a, man, too, suddenly, ,, or, too, easily, ,, to, believe, himself, .)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>It is dangerous for a man too suddenly, or too easily, to believe himself.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1796</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(How, long, shall, we, covet, and, oppress, ,, enlarge, our, possessions, ,, and, account, that, too, little, for, one, man, which, was, formerly, enough, for, a, nation, ?)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>How long shall we covet and oppress, enlarge our possessions, and account that too little for one man which was formerly enough for a nation?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>570</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(The, benefits, that, we, receive, from, our, superiors, are, then, welcome, when, they, come, with, an, open, hand, ,, and, a, clear, brow, ;, without, either, contumely, or, state, ;, and, so, a...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>The benefits that we receive from our superiors are then welcome when they come with an open hand, and a clear brow; without either contumely or state; and so as to prevent our necessities.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1922</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(As, in, the, symptoms, of, an, approaching, disease, ,, a, man, shall, find, himself, lazy, and, listless, :, a, weariness, in, his, limbs, ,, with, a, yawning, and, shuddering, all, over, him, ;...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>As in the symptoms of an approaching disease, a man shall find himself lazy and listless: a weariness in his limbs, with a yawning and shuddering all over him; so it is in the case of a weak mind,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(A.)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>A.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3021</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(There, is, nothing, great, but, what, is, virtuous, ,, nor, indeed, truly, great, ,, but, what, is, also, composed, and, quiet, .)</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>There is nothing great but what is virtuous, nor indeed truly great, but what is also composed and quiet.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  ...                                                                                                                                                                                             sentence_str\n",
              "463   On Benefits  ...                                                                                                                                                                                 they couch their meaning\n",
              "1158  On Benefits  ...  I speak of those that fortune has made famous for their persecutions: and there are others also that the world never took notice of until they were dead; as Epicurus and Metrodorus, that were almo...\n",
              "1988  On Benefits  ...  And the business is, we do not understand the true state of things: we are deceived by rumors; when we have gained the thing we aimed at, we find it to be either ill or empty; or perchance less th...\n",
              "2872  On Benefits  ...                    All I desire is that my property may not be a burden to myself, or make me so to others; and that is the best state of fortune that is neither directly necessitous, nor far from it.\n",
              "1400  On Benefits  ...                                                                                                                               It is dangerous for a man too suddenly, or too easily, to believe himself.\n",
              "1796  On Benefits  ...                                                            How long shall we covet and oppress, enlarge our possessions, and account that too little for one man which was formerly enough for a nation?\n",
              "570   On Benefits  ...            The benefits that we receive from our superiors are then welcome when they come with an open hand, and a clear brow; without either contumely or state; and so as to prevent our necessities.\n",
              "1922  On Benefits  ...  As in the symptoms of an approaching disease, a man shall find himself lazy and listless: a weariness in his limbs, with a yawning and shuddering all over him; so it is in the case of a weak mind,...\n",
              "359   On Benefits  ...                                                                                                                                                                                                       A.\n",
              "3021     On Anger  ...                                                                                                There is nothing great but what is virtuous, nor indeed truly great, but what is also composed and quiet.\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZMqd8G0Ra-1",
        "outputId": "f091718c-390c-421a-cbc5-56b5b50909c9"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3810"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-mqOl9pFgwH"
      },
      "source": [
        "#### Remove Short Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "EfYhrwWuFzOl",
        "outputId": "c18fc1eb-828e-4554-bab9-845b835b56fb"
      },
      "source": [
        "df['sentence_length'] = df['sentence_str'].map(lambda x: len(x))\n",
        "num_of_short_entries = len(df[df['sentence_length'] < 20])\n",
        "print(f\"there are {num_of_short_entries} so-called sentences with fewer than 20 characters\")\n",
        "df[df['sentence_length'] < 20].sample(5)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 72 so-called sentences with fewer than 20 characters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3022</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Anger, ,, alas, !)</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>Anger, alas!</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2592</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(how, well, .)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>how well.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1654</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(I, know, :)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>I know:</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(the, brother, ?)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>the brother?</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1773</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Is, it, day, ?, ')</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>Is it day? '</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  author  ...  sentence_str sentence_length\n",
              "3022     On Anger  Seneca  ...  Anger, alas!              12\n",
              "2592  On Benefits  Seneca  ...     how well.               9\n",
              "1654  On Benefits  Seneca  ...       I know:               7\n",
              "366   On Benefits  Seneca  ...  the brother?              12\n",
              "1773  On Benefits  Seneca  ...  Is it day? '              12\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW0AZpVyF1Qk",
        "outputId": "29268e4a-1eed-4427-da55-af481a6723d4"
      },
      "source": [
        "df = df.drop(df[df['sentence_length'] < 20].index)\n",
        "len(df)"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX9UfoDtF3Lz"
      },
      "source": [
        "#### Remove Cases of Self-Mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "LJnDfK9IF8hU",
        "outputId": "c446ea8f-c125-4c26-b373-5ba820a12422"
      },
      "source": [
        "# change the author name in this cell \n",
        "\n",
        "self_mentions = df[df['sentence_str'].str.contains('\\s'+'Anselm'.lower())]\n",
        "print(len(self_mentions))\n",
        "self_mentions"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, author, school, sentence_spacy, original_publication_date, corpus_edition_date, sentence_str, sentence_length]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt86zZ3RF8q8",
        "outputId": "3d60c0ce-aef5-48d2-b915-fbdd68a47425"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].str.contains('\\s'+'Augustine'.lower())].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vglbGXSFF8y4"
      },
      "source": [
        "#### Deal with Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRXjQSIQHpa-",
        "outputId": "6d816c6e-1b7a-4d28-8eb8-ed1b3ae55549"
      },
      "source": [
        "# find the total number of duplicates\n",
        "len(df['sentence_str'])-len(df['sentence_str'].drop_duplicates())"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "sHn4mTy2TR3P",
        "outputId": "9aa40c25-c127-4521-c21a-9a9cb47c5525"
      },
      "source": [
        "doubles_df = pd.concat(g for _, g in df.groupby(\"sentence_str\") if len(g) > 1)\n",
        "doubles_df"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-c58ecf086ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoubles_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentence_str\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoubles_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-7vXDjTh0s"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].duplicated(keep='first')].index)"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFT73wJCThrT",
        "outputId": "e1430d9e-0b27-42fa-ee46-c420be72b10d"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HnVnn1WHrTW"
      },
      "source": [
        "#### Check for Foreign Languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVcwhudjH5jY",
        "outputId": "2a827fb0-b753-44a2-cdaf-82582bf85619"
      },
      "source": [
        "# checking for 'der', a common article in German\n",
        "len((df[df['sentence_str'].str.contains('\\sder\\s')]))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBzPHm8PH4XB",
        "outputId": "116239b2-9a8a-4334-e814-b49571c9fddf"
      },
      "source": [
        "# checking for 'il', a common article in French\n",
        "len(df[df['sentence_str'].str.contains('\\sil\\s')])"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxWbjI0IiAzE"
      },
      "source": [
        "#### Some Ad Hoc Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8YsiZc_h-iu",
        "outputId": "f1c6b58a-51a7-4355-b13b-c80d77ad65bb"
      },
      "source": [
        "# miscellaneous nonsense sentences\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\spp\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\stotam\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\srree\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sflir\\s')].index)\n",
        "df = df.drop(df[(df['sentence_str'].str.contains('\\smodis\\s')) & (df['author'] != 'Kant')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwQzpQ2_iJEU",
        "outputId": "d4a6fd26-b3c7-493d-e50e-24203dcedeaa"
      },
      "source": [
        "# markers of french and notes\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\schapitre')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\salisme')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sHahn')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcQoVnariNWg",
        "outputId": "6db37fd2-a641-4670-9d86-c08e2f4ddb32"
      },
      "source": [
        "# some notes in Kant\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sVorl\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sberschwenglich')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI3dJy_dibCA",
        "outputId": "6361d695-4356-47ea-a77a-34b4dea913e8"
      },
      "source": [
        "# a common phrase in Plato / Aristotle footnotes\n",
        "df = df.drop(df[(df['author']=='Plato') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "df = df.drop(df[(df['author']=='Aristotle') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUt3mAjtigKB",
        "outputId": "ffb339b8-41f9-4c0d-ba4e-e9f4851e3cfc"
      },
      "source": [
        "# mentions of Aristotle in Plato\n",
        "df = df.drop(df[(df['author']=='Plato') & df['sentence_str'].str.contains('Aristotle')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3738"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sd2rbDJHraR"
      },
      "source": [
        "### Lemmatize and Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLKswX_Hrhd"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# use gensim to tokenize sentences\n",
        "df['tokenized_txt'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
        "                                                        max_len=200))\n",
        "\n",
        "# use spacey to get intelligent lemmatization\n",
        "def lemmatize_sentence(sentence):\n",
        "  lemmatized_txt = ''\n",
        "  for word in sentence:\n",
        "    lemmatized_txt += ' ' + str(word.lemma_)\n",
        "  return lemmatized_txt"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sg_V1rxIdzJ"
      },
      "source": [
        "df['lemmatized_str'] = df['sentence_spacy'].apply(lemmatize_sentence)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "0pyznlhXId8n",
        "outputId": "8a7df862-9703-4ea0-e202-264b80b5dca2"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2276</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(and, ,, in, effect, ,, a, friend, is, an, eye, ,, a, heart, ,, a, tongue, ,, a, hand, ,, at, all, distances, .)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>and, in effect, a friend is an eye, a heart, a tongue, a hand, at all distances.</td>\n",
              "      <td>80</td>\n",
              "      <td>[and, in, effect, friend, is, an, eye, heart, tongue, hand, at, all, distances]</td>\n",
              "      <td>and , in effect , a friend be an eye , a heart , a tongue , a hand , at all distance .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3406</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(The, one, ,, it, is, true, ,, is, wholly, void, of, reason, ,, but, it, is, also, an, equivalent, darkness, of, mind, that, possesses, the, other, .)</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>The one, it is true, is wholly void of reason, but it is also an equivalent darkness of mind that possesses the other.</td>\n",
              "      <td>118</td>\n",
              "      <td>[the, one, it, is, true, is, wholly, void, of, reason, but, it, is, also, an, equivalent, darkness, of, mind, that, possesses, the, other]</td>\n",
              "      <td>the one , -PRON- be true , be wholly void of reason , but -PRON- be also an equivalent darkness of mind that possess the other .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(He, is, restless, in, his, thoughts, ,, unsteady, in, his, counsels, ,, dissatisfied, with, the, present, ,, solicitous, for, the, future, ;, whereas, he, that, prudently, computes, his, hours, a...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>He is restless in his thoughts, unsteady in his counsels, dissatisfied with the present, solicitous for the future; whereas he that prudently computes his hours and his business, does not only for...</td>\n",
              "      <td>377</td>\n",
              "      <td>[he, is, restless, in, his, thoughts, unsteady, in, his, counsels, dissatisfied, with, the, present, solicitous, for, the, future, whereas, he, that, prudently, computes, his, hours, and, his, bus...</td>\n",
              "      <td>-PRON- be restless in -PRON- thought , unsteady in -PRON- counsel , dissatisfied with the present , solicitous for the future ; whereas -PRON- that prudently compute -PRON- hour and -PRON- busine...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Some, there, are, ,, I, know, ,, that, take, the, matter, for, the, benefit, ,, and, tax, the, obligation, by, weight, and, measure, .)</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>Some there are, I know, that take the matter for the benefit, and tax the obligation by weight and measure.</td>\n",
              "      <td>107</td>\n",
              "      <td>[some, there, are, know, that, take, the, matter, for, the, benefit, and, tax, the, obligation, by, weight, and, measure]</td>\n",
              "      <td>some there be , -PRON- know , that take the matter for the benefit , and tax the obligation by weight and measure .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3138</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(It, is, so, potent, a, passion, that, Socrates, durst, not, trust, himself, with, it, ., ')</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>It is so potent a passion that Socrates durst not trust himself with it. '</td>\n",
              "      <td>74</td>\n",
              "      <td>[it, is, so, potent, passion, that, socrates, durst, not, trust, himself, with, it]</td>\n",
              "      <td>-PRON- be so potent a passion that Socrates durst not trust -PRON- with -PRON- . '</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  ...                                                                                                                                                                                           lemmatized_str\n",
              "2276  On Benefits  ...                                                                                                                   and , in effect , a friend be an eye , a heart , a tongue , a hand , at all distance .\n",
              "3406     On Anger  ...                                                                         the one , -PRON- be true , be wholly void of reason , but -PRON- be also an equivalent darkness of mind that possess the other .\n",
              "2475  On Benefits  ...   -PRON- be restless in -PRON- thought , unsteady in -PRON- counsel , dissatisfied with the present , solicitous for the future ; whereas -PRON- that prudently compute -PRON- hour and -PRON- busine...\n",
              "83    On Benefits  ...                                                                                      some there be , -PRON- know , that take the matter for the benefit , and tax the obligation by weight and measure .\n",
              "3138     On Anger  ...                                                                                                                       -PRON- be so potent a passion that Socrates durst not trust -PRON- with -PRON- . '\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOxPwDpIeDT"
      },
      "source": [
        "### Combine with the Old Dataframe & Export to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 954
        },
        "id": "UU8QqgIXInkp",
        "outputId": "f8a0fd66-2669-4df2-e8e2-872e6f2df441"
      },
      "source": [
        "# load the old version and check it out\n",
        "og_df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/philosophy_data.csv')\n",
        "og_df.sample(5)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>77107</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>not but what some particular detail may perhaps be well looked after by an unscientific person, if he has studied accurately in the light of experience what happens in each case, just as some peop...</td>\n",
              "      <td>not but what some particular detail may perhaps be well looked after by an unscientific person, if he has studied accurately in the light of experience what happens in each case, just as some peop...</td>\n",
              "      <td>-320</td>\n",
              "      <td>1991</td>\n",
              "      <td>281</td>\n",
              "      <td>not but what some particular detail may perhaps be well looked after by an unscientific person, if he has studied accurately in the light of experience what happens in each case, just as some peop...</td>\n",
              "      <td>['not', 'but', 'what', 'some', 'particular', 'detail', 'may', 'perhaps', 'be', 'well', 'looked', 'after', 'by', 'an', 'unscientific', 'person', 'if', 'he', 'has', 'studied', 'accurately', 'in', 't...</td>\n",
              "      <td>not but what some particular detail may perhaps be well look after by an unscientific person , if -PRON- have study accurately in the light of experience what happen in each case , just as some p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76881</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>It is something of this sort that we are looking for.</td>\n",
              "      <td>It is something of this sort that we are looking for.</td>\n",
              "      <td>-320</td>\n",
              "      <td>1991</td>\n",
              "      <td>53</td>\n",
              "      <td>it is something of this sort that we are looking for.</td>\n",
              "      <td>['it', 'is', 'something', 'of', 'this', 'sort', 'that', 'we', 'are', 'looking', 'for']</td>\n",
              "      <td>-PRON- be something of this sort that -PRON- be look for .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350267</th>\n",
              "      <td>The Second Sex</td>\n",
              "      <td>Beauvoir</td>\n",
              "      <td>feminism</td>\n",
              "      <td>I detested him because of his ways.</td>\n",
              "      <td>I detested him because of his ways.</td>\n",
              "      <td>1949</td>\n",
              "      <td>2009</td>\n",
              "      <td>35</td>\n",
              "      <td>i detested him because of his ways.</td>\n",
              "      <td>['detested', 'him', 'because', 'of', 'his', 'ways']</td>\n",
              "      <td>-PRON- detest -PRON- because of -PRON- way .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191162</th>\n",
              "      <td>History Of Madness</td>\n",
              "      <td>Foucault</td>\n",
              "      <td>continental</td>\n",
              "      <td>Madness begins when a subject states as an affirmation that he is dead, and gives truth value to the still neutral content of the image 'I am dead.'</td>\n",
              "      <td>Madness begins when a subject states as an affirmation that he is dead, and gives truth value to the still neutral content of the image 'I am dead.'</td>\n",
              "      <td>1961</td>\n",
              "      <td>2006</td>\n",
              "      <td>148</td>\n",
              "      <td>madness begins when a subject states as an affirmation that he is dead, and gives truth value to the still neutral content of the image 'i am dead.'</td>\n",
              "      <td>['madness', 'begins', 'when', 'subject', 'states', 'as', 'an', 'affirmation', 'that', 'he', 'is', 'dead', 'and', 'gives', 'truth', 'value', 'to', 'the', 'still', 'neutral', 'content', 'of', 'the',...</td>\n",
              "      <td>madness begin when a subject state as an affirmation that -PRON- be dead , and give truth value to the still neutral content of the image ' -PRON- be dead . '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83537</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>For what is often useful surpasses what is seldom useful, whence the saying The best of things is water.</td>\n",
              "      <td>For what is often useful surpasses what is seldom useful, whence the saying The best of things is water.</td>\n",
              "      <td>-320</td>\n",
              "      <td>1991</td>\n",
              "      <td>104</td>\n",
              "      <td>for what is often useful surpasses what is seldom useful, whence the saying the best of things is water.</td>\n",
              "      <td>['for', 'what', 'is', 'often', 'useful', 'surpasses', 'what', 'is', 'seldom', 'useful', 'whence', 'the', 'saying', 'the', 'best', 'of', 'things', 'is', 'water']</td>\n",
              "      <td>for what be often useful surpass what be seldom useful , whence the say the good of thing be water .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             title  ...                                                                                                                                                                                           lemmatized_str\n",
              "77107   Aristotle - Complete Works  ...   not but what some particular detail may perhaps be well look after by an unscientific person , if -PRON- have study accurately in the light of experience what happen in each case , just as some p...\n",
              "76881   Aristotle - Complete Works  ...                                                                                                                                               -PRON- be something of this sort that -PRON- be look for .\n",
              "350267              The Second Sex  ...                                                                                                                                                             -PRON- detest -PRON- because of -PRON- way .\n",
              "191162          History Of Madness  ...                                           madness begin when a subject state as an affirmation that -PRON- be dead , and give truth value to the still neutral content of the image ' -PRON- be dead . '\n",
              "83537   Aristotle - Complete Works  ...                                                                                                     for what be often useful surpass what be seldom useful , whence the say the good of thing be water .\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfwEX5vzInx0",
        "outputId": "3832fcc5-6007-4241-92c8-f657fa37245d"
      },
      "source": [
        "og_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Aristotle          0.131978\n",
              "Plato              0.103804\n",
              "Hegel              0.061418\n",
              "Foucault           0.041234\n",
              "Heidegger          0.041231\n",
              "Kant               0.038225\n",
              "Nietzsche          0.036656\n",
              "Marx               0.036496\n",
              "Lewis              0.035498\n",
              "Beauvoir           0.035219\n",
              "Malebranche        0.035165\n",
              "Deleuze            0.033929\n",
              "Kripke             0.033764\n",
              "Smith              0.031637\n",
              "Wittgenstein       0.024443\n",
              "Locke              0.024040\n",
              "Hume               0.022489\n",
              "Merleau-Ponty      0.020541\n",
              "Quine              0.019949\n",
              "Derrida            0.016231\n",
              "Husserl            0.015536\n",
              "Fichte             0.014362\n",
              "Russell            0.013726\n",
              "Leibniz            0.013601\n",
              "Popper             0.012657\n",
              "Lenin              0.012091\n",
              "Augustine          0.011007\n",
              "Spinoza            0.010262\n",
              "Seneca             0.010114\n",
              "Moore              0.009924\n",
              "Keynes             0.009229\n",
              "Ricardo            0.008360\n",
              "Davis              0.008277\n",
              "Berkeley           0.007397\n",
              "Wollstonecraft     0.006924\n",
              "Marcus Aurelius    0.005985\n",
              "Descartes          0.003063\n",
              "Anselm             0.002665\n",
              "Epictetus          0.000874\n",
              "Name: author, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1wqPSYwsrBN",
        "outputId": "c7be4910-605b-4b93-e0ab-c8c6c74149bb"
      },
      "source": [
        "len(og_df)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "369599"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQcxBh37IoDJ",
        "outputId": "f66d4d05-a7b9-4d5f-8379-923992d42a20"
      },
      "source": [
        "# append the new data\n",
        "new_df = og_df.append(df)\n",
        "new_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Aristotle          0.130657\n",
              "Plato              0.102765\n",
              "Hegel              0.060803\n",
              "Foucault           0.040821\n",
              "Heidegger          0.040818\n",
              "Kant               0.037842\n",
              "Nietzsche          0.036289\n",
              "Marx               0.036131\n",
              "Lewis              0.035143\n",
              "Beauvoir           0.034867\n",
              "Malebranche        0.034813\n",
              "Deleuze            0.033589\n",
              "Kripke             0.033426\n",
              "Smith              0.031320\n",
              "Wittgenstein       0.024198\n",
              "Locke              0.023799\n",
              "Hume               0.022264\n",
              "Merleau-Ponty      0.020336\n",
              "Seneca             0.020025\n",
              "Quine              0.019749\n",
              "Derrida            0.016069\n",
              "Husserl            0.015380\n",
              "Fichte             0.014218\n",
              "Russell            0.013588\n",
              "Leibniz            0.013465\n",
              "Popper             0.012530\n",
              "Lenin              0.011970\n",
              "Augustine          0.010896\n",
              "Spinoza            0.010160\n",
              "Moore              0.009825\n",
              "Keynes             0.009137\n",
              "Ricardo            0.008277\n",
              "Davis              0.008194\n",
              "Berkeley           0.007323\n",
              "Wollstonecraft     0.006854\n",
              "Marcus Aurelius    0.005925\n",
              "Descartes          0.003032\n",
              "Anselm             0.002638\n",
              "Epictetus          0.000865\n",
              "Name: author, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 988
        },
        "id": "bwgCHszFf6_p",
        "outputId": "3f9f4b0b-429b-414d-854f-57f5dc9312d2"
      },
      "source": [
        "new_df[new_df['author']=='Seneca'].sample(5)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>368381</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>for they are beset on all hands, and every minute in dread of a surprise.</td>\n",
              "      <td>for they are beset on all hands, and every minute in dread of a surprise.</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>73</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['for', 'they', 'are', 'beset', 'on', 'all', 'hands', 'and', 'every', 'minute', 'in', 'dread', 'of', 'surprise']</td>\n",
              "      <td>for -PRON- be beset on all hand , and every minute in dread of a surprise .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1277</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(There, are, some, dispositions, that, embrace, good, things, as, soon, as, they, hear, them, ;, but, they, will, still, need, quickening, by, admonition, and, precept)</td>\n",
              "      <td>There are some dispositions that embrace good things as soon as they hear them; but they will still need quickening by admonition and precept</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>141</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[there, are, some, dispositions, that, embrace, good, things, as, soon, as, they, hear, them, but, they, will, still, need, quickening, by, admonition, and, precept]</td>\n",
              "      <td>there be some disposition that embrace good thing as soon as -PRON- hear -PRON- ; but -PRON- will still need quicken by admonition and precept</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2422</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(I, speak, this, of, Cato, 's, last, part, ;, for, in, his, former, time, the, commonwealth, was, made, unfit, for, a, wise, man, 's, administration, .)</td>\n",
              "      <td>I speak this of Cato's last part; for in his former time the commonwealth was made unfit for a wise man's administration.</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[speak, this, of, cato, last, part, for, in, his, former, time, the, commonwealth, was, made, unfit, for, wise, man, administration]</td>\n",
              "      <td>-PRON- speak this of Cato 's last part ; for in -PRON- former time the commonwealth be make unfit for a wise man 's administration .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366049</th>\n",
              "      <td>On Benefits</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>It was well said of him that called a good office, that was done harshly, and with an ill will, a stony piece of bread it is necessary for him that is hungry to receive it, but it almost chokes a ...</td>\n",
              "      <td>It was well said of him that called a good office, that was done harshly, and with an ill will, a stony piece of bread it is necessary for him that is hungry to receive it, but it almost chokes a ...</td>\n",
              "      <td>59</td>\n",
              "      <td>2017</td>\n",
              "      <td>218</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['it', 'was', 'well', 'said', 'of', 'him', 'that', 'called', 'good', 'office', 'that', 'was', 'done', 'harshly', 'and', 'with', 'an', 'ill', 'will', 'stony', 'piece', 'of', 'bread', 'it', 'is', 'n...</td>\n",
              "      <td>-PRON- be well say of -PRON- that call a good office , that be do harshly , and with an ill will , a stony piece of bread -PRON- be necessary for -PRON- that be hungry to receive -PRON- , but -PR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2972</th>\n",
              "      <td>On Anger</td>\n",
              "      <td>Seneca</td>\n",
              "      <td>Stoicism</td>\n",
              "      <td>(Nothing, but, a, predominant, fear, could, ever, have, mastered, his, choleric, and, sanguinary, disposition, .)</td>\n",
              "      <td>Nothing but a predominant fear could ever have mastered his choleric and sanguinary disposition.</td>\n",
              "      <td>45</td>\n",
              "      <td>2017</td>\n",
              "      <td>96</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[nothing, but, predominant, fear, could, ever, have, mastered, his, choleric, and, sanguinary, disposition]</td>\n",
              "      <td>nothing but a predominant fear could ever have master -PRON- choleric and sanguinary disposition .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              title  ...                                                                                                                                                                                           lemmatized_str\n",
              "368381  On Benefits  ...                                                                                                                              for -PRON- be beset on all hand , and every minute in dread of a surprise .\n",
              "1277    On Benefits  ...                                                           there be some disposition that embrace good thing as soon as -PRON- hear -PRON- ; but -PRON- will still need quicken by admonition and precept\n",
              "2422    On Benefits  ...                                                                     -PRON- speak this of Cato 's last part ; for in -PRON- former time the commonwealth be make unfit for a wise man 's administration .\n",
              "366049  On Benefits  ...   -PRON- be well say of -PRON- that call a good office , that be do harshly , and with an ill will , a stony piece of bread -PRON- be necessary for -PRON- that be hungry to receive -PRON- , but -PR...\n",
              "2972       On Anger  ...                                                                                                       nothing but a predominant fear could ever have master -PRON- choleric and sanguinary disposition .\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ncmXLdXuIoMl",
        "outputId": "e5e13061-e2b1-4716-fa27-bf6056e9a8c1"
      },
      "source": [
        "# export as csv\n",
        "from google.colab import files\n",
        "new_df.to_csv('phil_nlp.csv', index=False) \n",
        "files.download('phil_nlp.csv')"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6575cb77-cd80-4569-a15a-76007e679793\", \"phil_nlp.csv\", 334218642)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz0aj3NrECm3"
      },
      "source": [
        "###Upload Data to the SQL Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "bW76POWkJL-b",
        "outputId": "7b13213a-d603-4704-e529-a98454d3b3c4"
      },
      "source": [
        "# prepare to upload to the PostgreSQL database\n",
        "\n",
        "# note which dataframe you set this to - new_df for the whole dataset, df for \n",
        "# just the new text\n",
        "\n",
        "for_db = new_df\n",
        "for_db['date'] = for_db['original_publication_date']\n",
        "for_db['date'] = for_db['date'].apply(lambda x: str(x)[1:]+' BC' if x < 0 else str(x))\n",
        "for_db['sentence'] = for_db['sentence_str']\n",
        "for_db['school'] = for_db['school'].apply(lambda x: x.replace('_', ' ').title())\n",
        "for_db = for_db.drop(['sentence_spacy', \n",
        "                      'sentence_length',\n",
        "                      'sentence_lowered', \n",
        "                      'sentence_str', \n",
        "                      'tokenized_txt', \n",
        "                      'lemmatized_str',\n",
        "                      'corpus_edition_date',\n",
        "                      'original_publication_date'], axis=1)\n",
        "for_db.columns = [i.upper() for i in for_db.columns]\n",
        "\n",
        "for_db.sample(5)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>SCHOOL</th>\n",
              "      <th>DATE</th>\n",
              "      <th>SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>96492</th>\n",
              "      <td>A Treatise Of Human Nature</td>\n",
              "      <td>Hume</td>\n",
              "      <td>Empiricism</td>\n",
              "      <td>1739</td>\n",
              "      <td>Now such as the parts are, such is the whole.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14892</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>Plato</td>\n",
              "      <td>350 BC</td>\n",
              "      <td>It is because of this that Nicias and Socrates agree (Laches is slow to accept the point, but it is clearly implied in what he has already said about courage's involving 'wisdom')</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263229</th>\n",
              "      <td>The System Of Ethics</td>\n",
              "      <td>Fichte</td>\n",
              "      <td>German Idealism</td>\n",
              "      <td>1798</td>\n",
              "      <td>General overview of the issue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49467</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>320 BC</td>\n",
              "      <td>The only difference is that in the last case, viz.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342640</th>\n",
              "      <td>Vindication Of The Rights Of Woman</td>\n",
              "      <td>Wollstonecraft</td>\n",
              "      <td>Feminism</td>\n",
              "      <td>1792</td>\n",
              "      <td>Yet thus to give a sex to mind was not very consistent with the principles of a man who argued so warmly, and so well, for the immortality of the soul.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     TITLE  ...                                                                                                                                                                             SENTENCE\n",
              "96492           A Treatise Of Human Nature  ...                                                                                                                                        Now such as the parts are, such is the whole.\n",
              "14892               Plato - Complete Works  ...  It is because of this that Nicias and Socrates agree (Laches is slow to accept the point, but it is clearly implied in what he has already said about courage's involving 'wisdom')\n",
              "263229                The System Of Ethics  ...                                                                                                                                                        General overview of the issue\n",
              "49467           Aristotle - Complete Works  ...                                                                                                                                   The only difference is that in the last case, viz.\n",
              "342640  Vindication Of The Rights Of Woman  ...                              Yet thus to give a sex to mind was not very consistent with the principles of a man who argued so warmly, and so well, for the immortality of the soul.\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWSVKbmoVaAW",
        "outputId": "669758af-f842-44b5-f8e8-c8e0ba4a1bf0"
      },
      "source": [
        "len(for_db)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "373337"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mni3N-fyK-jZ",
        "outputId": "43b5b82a-7af8-4f66-db79-8085678c534c"
      },
      "source": [
        "#importing sql library \n",
        "from sqlalchemy import create_engine \n",
        "  \n",
        "# create a reference  \n",
        "# for sql library \n",
        "engine = create_engine('pos',\n",
        "                       echo=False)\n",
        "  \n",
        "# attach the data frame to the sql server \n",
        "for_db.to_sql('phil_nlp', \n",
        "               con = engine,\n",
        "              if_exists='replace',\n",
        "              index=False,\n",
        "              method='multi') \n",
        "  \n",
        "# show the completed data as a test\n",
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp WHERE \"AUTHOR\" = 'Seneca'\"\"\").fetchone()) "
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('On Benefits', 'Seneca', 'Stoicism', '59', 'and so in infinitum.')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRYDdaLGW2"
      },
      "source": [
        "Remember to add to the clipping and other elements to the notebook that creates the database as a whole. Then you're done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK50YeA-LNtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd40c3c1-0018-4553-f18a-5cd643819b15"
      },
      "source": [
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp where \"AUTHOR\" = 'Anselm'\"\"\").fetchone()) "
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Proslogion', 'Anselm', 'Scholasticism', '1077', 'How is it, then, Lord, that You are all these things?')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfaWbJkCid6W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}