{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_text_introduction_notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyO3H0uAqqSxCYOxOwaEEtBP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/PDP_data_processing/blob/master/new_text_introduction_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cw_rJlXCob_"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN4DvDsxCdio",
        "outputId": "4a990f5a-915d-4114-bb5f-7a7bba9209dd"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\n",
        "# and relevant libraries via the functions.py file\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/philosophy_data_project'\n",
        "\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAk2WGLbCn3t"
      },
      "source": [
        "from import_functions import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fV19sbpUC2PF",
        "outputId": "5e7f18fc-6777-4669-bc3e-7e54db1d08f2"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbT8yZ0pC30A"
      },
      "source": [
        "###Load the Text and Clip Front and End Matter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-MzN2T2DUYm"
      },
      "source": [
        "# if you are deleting an old text that was added here, make sure it is in the \n",
        "# primary database construction notebook\n",
        "anselm_proslogion = get_text(drive_path + '/phil_txts/anselm_proslogion.txt')\n",
        "anselm_de_veritate = get_text(drive_path + '/phil_txts/anselm_de_veritate.txt')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuWrhYwOUbck"
      },
      "source": [
        "anselm_proslogion = anselm_proslogion.split('PREFACE 1')[1].split('John 16:24.   Isaiah 9:6.')[0][:-75]\n",
        "anselm_de_veritate = anselm_de_veritate.split('Preface [to the Three Dialogues')[1][45:]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suHuy6isDUiC"
      },
      "source": [
        "### Clean the Text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfFHzvnDUpf"
      },
      "source": [
        "def baseline_clean(to_correct, \n",
        "                   capitals=True, \n",
        "                   bracketed_fn=False, \n",
        "                   odd_words_dict={}):\n",
        "  # remove utf8 encoding characters and some punctuations\n",
        "  result = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6§\\\\\\£\\Â*_<>\"\"⎫•{}Γ~]', ' ', to_correct)\n",
        "  result = re.sub(r'[\\u2014\\u2013\\u2012-]', ' ', result)\n",
        "\n",
        "  # replace whitespace characters with actual whitespace\n",
        "  result = re.sub(r'\\s', ' ', result)\n",
        "\n",
        "  # replace odd quotation marks with a standard\n",
        "  result = re.sub(r'[‘’“”]', \"'\", result)\n",
        "\n",
        "  # replace the ﬀ, ﬃ and ﬁ with the appropriate counterparts\n",
        "  result = re.sub(r'ﬀ', 'ff', result)\n",
        "  result = re.sub(r'ﬁ', 'fi', result)\n",
        "  result = re.sub(r'ﬃ', 'ffi', result)\n",
        "\n",
        "  # replace some accented characters for ease of searching\n",
        "  result = re.sub(r'é', 'e', result)\n",
        "\n",
        "  # remove or standardize some recurring common and meaninless words/phrases\n",
        "  result = re.sub(r'\\s*This\\s*page\\s*intentionally\\s*left\\s*blank\\s*', ' ', result)\n",
        "  result = re.sub(r'(?i)Aufgabe\\s+', ' ', result)\n",
        "  result = re.sub(r',*\\s+cf\\.', ' ', result)\n",
        "\n",
        "  # some texts have footnotes conveniently in brackets - this removes them all, \n",
        "  # with a safety measure for unpaired brackets, and deletes all brackets afterwards\n",
        "  if bracketed_fn:\n",
        "    result = re.sub(r'\\[.{0,300}\\]|{.{0,300}}|{.{0,300}\\]|\\[.{0,300}}', ' ', result)\n",
        "  result = re.sub(r'[\\[\\]{}]', ' ', result)\n",
        "\n",
        "  # unify some abbreviations\n",
        "  result = re.sub(r'&', 'and', result)\n",
        "  result = re.sub(r'\\se\\.g\\.\\s', ' eg ', result)\n",
        "  result = re.sub(r'\\si\\.e\\.\\s', ' ie ', result)\n",
        "  result = re.sub('coroll\\.', 'coroll', result)\n",
        "  result = re.sub('pt\\.', 'pt', result)\n",
        "\n",
        "  # remove roman numerals, first capitalized ones\n",
        "  result = re.sub(r'\\s((I{2,}V*X*\\.*)|(IV\\.*)|(IX\\.*)|(V\\.*)|(V+I*\\.*)|(X+L*V*I*]\\.*))\\s', ' ', result)\n",
        "  # then lowercase\n",
        "  result = re.sub(r'\\s((i{2,}v*x*\\.*)|(iv\\.*)|(ix\\.*)|(v\\.*)|(v+i*\\.*)|(x+l*v*i*\\.*))\\s', ' ', result)\n",
        "\n",
        "  # remove periods and commas flanked by numbers\n",
        "  result = re.sub(r'\\d\\.\\d', ' ', result)\n",
        "  result = re.sub(r'\\d,\\d', ' ', result)\n",
        "\n",
        "  # remove the number-letter-number pattern used for many citations\n",
        "  result = re.sub(r'\\d*\\w{,2}\\d', ' ', result)\n",
        "\n",
        "  # remove numerical characters\n",
        "  result = re.sub(r'\\d+', ' ', result)\n",
        "\n",
        "  # remove words of 2+ characters that are entirely capitalized \n",
        "  # (these are almost always titles, headings, or speakers in a dialogue)\n",
        "  # remove capital I's that follow capital words - these almost always roman numerals\n",
        "  # some texts do use these capitalizations meaningfully, so we make this optional\n",
        "  if capitals:\n",
        "    result = re.sub(r'[A-Z]{2,}\\s+I', ' ', result)\n",
        "    result = re.sub(r'[A-Z]{2,}', ' ', result)\n",
        "\n",
        "  # remove isolated colons and semicolons that result from removal of titles\n",
        "  result = re.sub(r'\\s+:\\s*', ' ', result)\n",
        "  result = re.sub(r'\\s+;\\s*', ' ', result)\n",
        "\n",
        "  # remove isolated letters (do it several times because strings of isolated letters do not get captured properly)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "\n",
        "  # remove isolated letters at the end of sentences or before commas\n",
        "  result = re.sub(r'\\s[^aI]\\.', '.', result)\n",
        "  result = re.sub(r'\\s[^aI],', ',', result)\n",
        "\n",
        "  # deal with spaces around periods and commas\n",
        "  result = re.sub(r'\\s+,\\s+', ', ', result)\n",
        "  result = re.sub(r'\\s+\\.\\s+', '. ', result)\n",
        "\n",
        "  # remove empty parantheses\n",
        "  result = re.sub(r'(\\(\\s*\\.*\\s*\\))|(\\(\\s*,*\\s*)\\)', ' ', result)\n",
        "  result = re.sub(r'\\.\\)\\.', '.', result)\n",
        "  result = re.sub(r'\\.\\(\\.', '.', result)\n",
        "\n",
        "  # reduce multiple periods, commas, or whitespaces into a single one\n",
        "  result = re.sub(r'\\.+', '.', result)\n",
        "  result = re.sub(r',+', ',', result)\n",
        "  result = re.sub(r'\\s+', ' ', result)\n",
        "\n",
        "  # deal with isolated problem cases discovered in the data:\n",
        "  for key in odd_words_dict.keys():\n",
        "    result = re.sub(r''+key+'', odd_words_dict[key], result)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OjRlTV_EEHM"
      },
      "source": [
        "# note extras like bracketed footnotes or specific words to remove\n",
        "\n",
        "anselm_de_veritate_to_rm = ['On Truth', 'rectitudo', 'S\\.', 'T\\.']\n",
        "anselm_proslogion_to_rm = ['Proslogion', 'Preface', '&']\n"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y9RIRBED-F"
      },
      "source": [
        "# build a dictionary for the book\n",
        "anselm_proslogion_dict = {\n",
        "    'author': 'Anselm',\n",
        "    'title': 'Proslogion',\n",
        "    'text': anselm_proslogion,\n",
        "    'school': 'Scholasticism',\n",
        "    'words to remove': anselm_proslogion_to_rm,\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 1077,\n",
        "    'corpus date': 2000\n",
        "}\n",
        "\n",
        "anselm_de_veritate_dict = {\n",
        "    'author': 'Anselm',\n",
        "    'title': 'De Veritate',\n",
        "    'text': anselm_de_veritate,\n",
        "    'school': 'Scholasticism',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 1086,\n",
        "    'corpus date': 2000\n",
        "}"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fkWlxhoIOjA"
      },
      "source": [
        "#@title Oddities Dictionary for Cleaning\n",
        "# a dictionary of oddities to clean up\n",
        "odd_words_dict = {'\\sderstanding': 'derstanding',\n",
        "                  '\\sditference\\s': ' difference ',\n",
        "                  '\\sforthe\\s': ' for the ',\n",
        "                  '\\sject': 'ject',\n",
        "                  '\\sSure ly\\s': ' Surely ',\n",
        "                  '\\spiness': 'piness',\n",
        "                  '\\sjects': 'jects', \n",
        "                  '\\sness': 'ness',\n",
        "                  '\\schil dren\\s': ' children ',\n",
        "                  '\\sper\\scent\\s': ' percent ',\n",
        "                  '\\sper\\scent\\.': ' percent.',\n",
        "                  '\\sper\\scent,': ' percent,',\n",
        "                  '\\wi\\son': 'ion',\n",
        "                  '\\spri\\sori': ' priori',\n",
        "                  '\\stences\\s': 'tences ',\n",
        "                  '\\sprincipleb': ' principle',\n",
        "                  '\\ssciousness': 'sciousness',\n",
        "                  '\\stion': 'tion',\n",
        "                  '\\spri\\s': ' pri',\n",
        "                  '\\scluding': 'cluding',\n",
        "                  '\\sdom': 'dom',\n",
        "                  '\\sers': 'ers',\n",
        "                  '\\scritiq\\s': ' critique ',\n",
        "                  '\\ssensati\\s': ' sensation ',\n",
        "                  '(?i)\\syou\\sll': \" you'll\",\n",
        "                  '\\sI\\sll': \" I'll\",\n",
        "                  '(?i)\\swe\\sll': \" we'll\",\n",
        "                  '(?i)he\\sll': \" he'll\",\n",
        "                  '(?i)who\\sll': \"who'll\",\n",
        "                  '(?i)\\sthere\\sll\\s': \" there'll \",\n",
        "                  '\\seduca\\s': ' education ',\n",
        "                  '\\slity\\s': 'lity ',\n",
        "                  '\\smultaneously\\s': 'multaneously ',\n",
        "                  '\\stically\\s': 'tically ',\n",
        "                  '\\sDa\\ssein\\s': ' Dasein ',\n",
        "                  '(?i)\\sthey\\sll\\s': \" they'll \",\n",
        "                  '(?i)\\sin\\tum\\s': ' in turn ',\n",
        "                  '\\scon~\\s': ' con',\n",
        "                  '\\sà\\s': ' a ',\n",
        "                  '\\sjor\\s': ' for ',\n",
        "                  '\\sluminating\\s': 'luminating ',\n",
        "                  '\\sselj\\s': ' self ',\n",
        "                  '\\stial\\s': 'tial ',\n",
        "                  '\\sversal\\s': 'versal ',\n",
        "                  '\\sexis\\st': ' exist',\n",
        "                  '\\splauded\\s': 'plauded ',\n",
        "                  '\\suiry\\s': 'uiry ',\n",
        "                  '\\svithin\\s': ' within ',\n",
        "                  '\\soj\\s': ' of ',\n",
        "                  '\\sposi\\st': ' posit',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '(?i)\\sthat\\sll\\s': \" that'll \",\n",
        "                  '(?i)\\sa\\sll\\s': ' all ',\n",
        "                  '\\so\\sther\\s': ' other ',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '\\snei\\sther\\s': ' neither ',\n",
        "                  '\\sei\\sther\\s': ' either ',\n",
        "                  '\\sfur\\sther\\s': ' further ',\n",
        "                  '\\sano\\sther': ' another ',\n",
        "                  '\\sneces\\s': ' neces',\n",
        "                  'u\\slar\\s': 'ular ',\n",
        "                  '\\sference\\s': 'ference ',\n",
        "                  '(?i)it\\sll\\s': \"it'll \",\n",
        "                  '\\stoge\\sther': ' together ',\n",
        "                  '\\sknowledgeb\\s': ' knowledge ',\n",
        "                  'r\\stain\\s': 'rtain ',\n",
        "                  'on\\stain\\s': 'ontain',\n",
        "                  '(?i)j\\sect\\s': 'ject',\n",
        "                  '\\sob\\sect\\s': ' object ',\n",
        "                  '\\sbtle\\s': 'btle ',\n",
        "                  '\\snition\\s': 'nition ',\n",
        "                  '\\sdering\\s': 'dering ', \n",
        "                  '\\sized\\s': 'ized ',\n",
        "                  '\\sther\\shand': ' other hand',\n",
        "                  '\\ture\\s': 'ture ',\n",
        "                  '\\sabso\\sl': ' absol',\n",
        "                  '\\stly\\s': 'tly ',\n",
        "                  '\\serty\\s': 'erty ',\n",
        "                  '\\sobj\\se': ' obj',\n",
        "                  '\\sffiir\\s': ' for ',\n",
        "                  '\\sndeed\\s': ' indeed ',\n",
        "                  '\\sfonn\\s': ' form ',\n",
        "                  '\\snally\\s': 'nally ',\n",
        "                  'ain\\sty\\s': 'ainty ',\n",
        "                  'ici\\sty\\s': 'icity ',\n",
        "                  '\\scog\\sni': ' cogni',\n",
        "                  '\\sacc\\s': ' acc',\n",
        "                  '\\sindi\\svid\\sual': ' individual', \n",
        "                  '\\sintu\\sit': ' intuit',\n",
        "                  'r\\sance\\s': 'rance ',\n",
        "                  '\\ssions\\s': 'sions ',\n",
        "                  '\\sances\\s': 'ances ',\n",
        "                  '\\sper\\sception\\s': ' perception ',\n",
        "                  '\\sse\\sries\\s': ' series ',\n",
        "                  '\\sque\\sries\\s': ' queries ',\n",
        "                  '\\sessary\\s': 'essary ',\n",
        "                  '\\sofa\\s': ' of a ',\n",
        "                  '\\scer\\stainty\\s': ' certainty ',\n",
        "                  'ec\\stivity\\s': 'ectivity ',\n",
        "                  '\\stivity\\s': 'tivity ',\n",
        "                  '\\slation\\s': 'lation ',\n",
        "                  '\\sir\\sr': ' irr',\n",
        "                  '\\ssub\\sstance\\s': ' substance ',\n",
        "                  'sec\\sond\\s': 'second ',\n",
        "                  '\\s\\.rv': '',\n",
        "                  '\\story\\s': 'tory ',\n",
        "                  '\\sture\\s': 'ture ',\n",
        "                  '\\sminate\\s': 'minate ',\n",
        "                  '\\sing\\s': 'ing ',\n",
        "                  '\\splicity\\s': 'plicity ',\n",
        "                  '\\ssimi\\slar\\s': ' similar ',\n",
        "                  '\\scom\\smunity\\s': ' community ',\n",
        "                  '\\sitselfa\\s': ' itself a ',\n",
        "                  '\\ssimp\\s': ' simply ',\n",
        "                  '\\scon\\stex': ' contex',\n",
        "                  '\\scon\\sseq': ' conseq',\n",
        "                  '\\scon\\stai': ' contai',\n",
        "                  '\\sofwhat\\s': ' of what ',\n",
        "                  '\\sui\\s': 'ui',\n",
        "                  '\\sofan\\s': ' of an ',\n",
        "                  '\\saccor\\sdance\\s': ' accordance ',\n",
        "                  '\\stranscen\\sdental\\s': ' transcendental ',\n",
        "                  '\\sap\\spearances\\s': ' appearances ',\n",
        "                  'e\\squences\\s': 'equences ',\n",
        "                  '\\sorits\\s': ' or its ',\n",
        "                  '\\simma\\sn': ' imman',\n",
        "                  '\\seq\\sua': ' equa',\n",
        "                  '\\simpl\\sied\\s': ' implied ',\n",
        "                  '\\sbuta\\s': ' but a ',\n",
        "                  '\\sa\\snd\\s': ' and ',\n",
        "                  '\\sence\\s': 'ence ',\n",
        "                  '\\stain\\s': 'tain ',\n",
        "                  '\\sunder\\sstanding\\s': ' understanding ',\n",
        "                  'i\\sence\\s': 'ience ',\n",
        "                  'r\\sence\\s': 'rence ',\n",
        "                  '\\stical\\s': 'tical ',\n",
        "                  '\\sobjectsb\\s': ' objects ',\n",
        "                  '\\stbe\\s': ' the ',\n",
        "                  '\\smul\\st': ' mult',\n",
        "                  '\\sgen\\seral\\s': ' general ',\n",
        "                  '\\suniver\\ssal\\s': ' universal ',\n",
        "                  '\\scon\\stent\\s': ' content ',\n",
        "                  '\\spar\\sticular\\s': ' particular ',\n",
        "                  'ver\\ssity\\s': 'versity ',\n",
        "                  '\\sCritiq\\s': ' Critique ',\n",
        "                  '\\sphilo\\ssophy\\s': ' philosophy ',\n",
        "                  '\\seq\\s': ' eq'}"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXDII00UED1c"
      },
      "source": [
        "# a function that takes the dictionary and returns a dataframe of sentences\n",
        "def from_raw_to_df(text_dict):\n",
        "  nlp.max_length = 9000000\n",
        "  text = text_dict['text']\n",
        "  text = remove_words(text, text_dict['words to remove'])\n",
        "  text = baseline_clean(text, capitals=text_dict['remove capitals'],\n",
        "                        bracketed_fn=text_dict['bracketed fn'],\n",
        "                        odd_words_dict=odd_words_dict)\n",
        "  text_nlp = nlp(text, disable=['ner'])\n",
        "  text_df = pd.DataFrame(columns=['title', 'author', 'school', 'sentence_spacy'])\n",
        "  text_df['sentence_spacy'] = list(text_nlp.sents)\n",
        "  text_df['author'] = text_dict['author']\n",
        "  text_df['title'] = text_dict['title']\n",
        "  text_df['school'] = text_dict['school']\n",
        "  text_df['original_publication_date'] = text_dict['original date']\n",
        "  text_df['corpus_edition_date'] = text_dict['corpus date']\n",
        "  text_df['sentence_str'] = text_df['sentence_spacy'].apply(lambda x: ''.join(list(str(x))))\n",
        "  return text_df"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w14qMlTrFM4s"
      },
      "source": [
        "# use the function\n",
        "proslogion_df = from_raw_to_df(anselm_proslogion_dict)\n",
        "de_veritate_df = from_raw_to_df(anselm_de_veritate_dict)\n",
        "\n",
        "df = proslogion_df.append(de_veritate_df, ignore_index=True)"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IZ3JhAyNFept",
        "outputId": "3f165552-3427-4836-db1e-5d8950aa7357"
      },
      "source": [
        "# checking the result\n",
        "pd.options.display.max_colwidth = 200\n",
        "df.sample(10)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(My, soul, hoped, for, fullness, ;, and, ,, lo, ,, once, again, it, is, overwhelmed, with, need, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>My soul hoped for fullness; and, lo, once again it is overwhelmed with need.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(No, doubt, about, it, .)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>No doubt about it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>595</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(For, if, God, had, given, him, perseverance, ,, he, would, have, had, it, just, as, the, good, angels, had, it, because, God, gave, it, to, them, .)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>For if God had given him perseverance, he would have had it just as the good angels had it because God gave it to them.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(But, if, perceiving, is, only, knowing, or, only, for, the, sake, of, knowing, (, for, anyone, who, perceives, knows, in, accordance, with, the, characteristic, capabilities, of, the, respective,...</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>But if perceiving is only knowing or only for the sake of knowing (for anyone who perceives knows in accordance with the characteristic capabilities of the respective senses.g.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(How, He, who, is, completely, and, supremely, just, spares, those, who, are, evil, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>How He who is completely and supremely just spares those who are evil.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(For, since, there, can, be, thought, to, exist, something, of, this, kind, ,, if, You, were, not, this, Being, then, something, greater, than, You, could, be, thought, a, consequence, which, is, ...</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>For since there can be thought to exist something of this kind, if You were not this Being then something greater than You could be thought a consequence which is impossible.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Permit, me, ,, at, least, from, afar, or, from, the, deep, ,, to, look, upwards, toward, Your, light, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Permit me, at least from afar or from the deep, to look upwards toward Your light.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1028</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(See, whether, something, in, this, definition, ought, perhaps, to, be, amended, .)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>See whether something in this definition ought perhaps to be amended.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>758</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(So, unless, I, am, wrong, ,, we, can, also, number, among, right, actions)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>So unless I am wrong, we can also number among right actions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1105</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Clearly, not, .)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>Clearly not.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  ...                                                                                                                                                                      sentence_str\n",
              "396    Proslogion  ...                                                                                                      My soul hoped for fullness; and, lo, once again it is overwhelmed with need.\n",
              "664   De Veritate  ...                                                                                                                                                                No doubt about it.\n",
              "595   De Veritate  ...                                                           For if God had given him perseverance, he would have had it just as the good angels had it because God gave it to them.\n",
              "210    Proslogion  ...  But if perceiving is only knowing or only for the sake of knowing (for anyone who perceives knows in accordance with the characteristic capabilities of the respective senses.g.\n",
              "235    Proslogion  ...                                                                                                            How He who is completely and supremely just spares those who are evil.\n",
              "366    Proslogion  ...    For since there can be thought to exist something of this kind, if You were not this Being then something greater than You could be thought a consequence which is impossible.\n",
              "128    Proslogion  ...                                                                                                Permit me, at least from afar or from the deep, to look upwards toward Your light.\n",
              "1028  De Veritate  ...                                                                                                             See whether something in this definition ought perhaps to be amended.\n",
              "758   De Veritate  ...                                                                                                                      So unless I am wrong, we can also number among right actions\n",
              "1105  De Veritate  ...                                                                                                                                                                      Clearly not.\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZMqd8G0Ra-1",
        "outputId": "f54c7f9f-1285-46ac-f5a4-e2537f405e94"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1141"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-mqOl9pFgwH"
      },
      "source": [
        "#### Remove Short Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "id": "EfYhrwWuFzOl",
        "outputId": "eaa9b563-085f-4961-87af-0a7068531242"
      },
      "source": [
        "df['sentence_length'] = df['sentence_str'].map(lambda x: len(x))\n",
        "num_of_short_entries = len(df[df['sentence_length'] < 20])\n",
        "print(f\"there are {num_of_short_entries} so-called sentences with fewer than 20 characters\")\n",
        "df[df['sentence_length'] < 20].sample(5)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 120 so-called sentences with fewer than 20 characters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>815</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(No, .)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>No.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Why, is, this, ?)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Why is this?</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1105</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Clearly, not, .)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>Clearly not.</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Psalms, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Psalms.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Psalms, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Psalms.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  author  ...  sentence_str sentence_length\n",
              "815   De Veritate  Anselm  ...           No.               3\n",
              "355    Proslogion  Anselm  ...  Why is this?              12\n",
              "1105  De Veritate  Anselm  ...  Clearly not.              12\n",
              "525    Proslogion  Anselm  ...       Psalms.               7\n",
              "140    Proslogion  Anselm  ...       Psalms.               7\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW0AZpVyF1Qk",
        "outputId": "c9eee736-b89e-42f0-e868-78c474d43fa6"
      },
      "source": [
        "df = df.drop(df[df['sentence_length'] < 20].index)\n",
        "len(df)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX9UfoDtF3Lz"
      },
      "source": [
        "#### Remove Cases of Self-Mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        },
        "id": "LJnDfK9IF8hU",
        "outputId": "e18a9783-4e72-4c3a-9afb-b355612c66db"
      },
      "source": [
        "# change the author name in this cell \n",
        "\n",
        "self_mentions = df[df['sentence_str'].str.contains('\\s'+'Anselm'.lower())]\n",
        "print(len(self_mentions))\n",
        "self_mentions"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, author, school, sentence_spacy, original_publication_date, corpus_edition_date, sentence_str, sentence_length]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt86zZ3RF8q8",
        "outputId": "506a13e9-b402-40c7-b301-651fa91ac675"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].str.contains('\\s'+'Augustine'.lower())].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1021"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vglbGXSFF8y4"
      },
      "source": [
        "#### Deal with Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRXjQSIQHpa-",
        "outputId": "dca83632-921f-4d99-c84b-e32ed1c1a01c"
      },
      "source": [
        "# find the total number of duplicates\n",
        "len(df['sentence_str'])-len(df['sentence_str'].drop_duplicates())"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sHn4mTy2TR3P",
        "outputId": "21b3b842-af47-486d-fd2e-8ef9590047fb"
      },
      "source": [
        "doubles_df = pd.concat(g for _, g in df.groupby(\"sentence_str\") if len(g) > 1)\n",
        "doubles_df"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(A, conjecture, about, what, kind, of, good, this, is, and, about, how, great, it, is, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>A conjecture about what kind of good this is and about how great it is.</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(A, conjecture, about, what, kind, of, good, this, is, and, about, how, great, it, is, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>A conjecture about what kind of good this is and about how great it is.</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Alone, existing, through, Himself, ,, He, makes, all, other, things, from, nothing, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Alone existing through Himself, He makes all other things from nothing.</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Alone, existing, through, Himself, ,, He, makes, all, other, things, from, nothing, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Alone existing through Himself, He makes all other things from nothing.</td>\n",
              "      <td>71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Arousal, of, the, mind, for, contemplating, God, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Arousal of the mind for contemplating God.</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Whether, this, eternity, is, one, aeon, or, more, than, one, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Whether this eternity is one aeon or more than one.</td>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Whether, this, is, the, full, joy, which, the, Lord, promises, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Whether this is the full joy which the Lord promises.</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Whether, this, is, the, full, joy, which, the, Lord, promises, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Whether this is the full joy which the Lord promises.</td>\n",
              "      <td>53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(necessary, Being, which, is, every, good, ,, complete, good, ,, and, the, only, good, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>necessary Being which is every good, complete good, and the only good.</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(necessary, Being, which, is, every, good, ,, complete, good, ,, and, the, only, good, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>necessary Being which is every good, complete good, and the only good.</td>\n",
              "      <td>70</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          title  ... sentence_length\n",
              "47   Proslogion  ...              71\n",
              "490  Proslogion  ...              71\n",
              "25   Proslogion  ...              71\n",
              "198  Proslogion  ...              71\n",
              "19   Proslogion  ...              42\n",
              "..          ...  ...             ...\n",
              "460  Proslogion  ...              51\n",
              "49   Proslogion  ...              53\n",
              "559  Proslogion  ...              53\n",
              "46   Proslogion  ...              70\n",
              "477  Proslogion  ...              70\n",
              "\n",
              "[72 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-7vXDjTh0s"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].duplicated(keep='first')].index)"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFT73wJCThrT",
        "outputId": "bfedebdb-c775-4be0-e621-2e8f794fc4c7"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HnVnn1WHrTW"
      },
      "source": [
        "#### Check for Foreign Languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVcwhudjH5jY",
        "outputId": "04b50692-10cb-420a-886b-56a836dc8de5"
      },
      "source": [
        "# checking for 'der', a common article in German\n",
        "len((df[df['sentence_str'].str.contains('\\sder\\s')]))"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBzPHm8PH4XB",
        "outputId": "3fabe09f-ccd1-41df-c6a5-00fd0e8c1da5"
      },
      "source": [
        "# checking for 'il', a common article in French\n",
        "len(df[df['sentence_str'].str.contains('\\sil\\s')])"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxWbjI0IiAzE"
      },
      "source": [
        "#### Some Ad Hoc Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8YsiZc_h-iu",
        "outputId": "1c2ae3fa-494b-41ab-c958-f25aa45fe415"
      },
      "source": [
        "# miscellaneous nonsense sentences\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\spp\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\stotam\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\srree\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sflir\\s')].index)\n",
        "df = df.drop(df[(df['sentence_str'].str.contains('\\smodis\\s')) & (df['author'] != 'Kant')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwQzpQ2_iJEU",
        "outputId": "8d217609-845a-4505-d00d-794faa6d7659"
      },
      "source": [
        "# markers of french and notes\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\schapitre')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\salisme')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sHahn')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcQoVnariNWg",
        "outputId": "5f167f81-c0e5-4412-be0b-e2bbdfc82240"
      },
      "source": [
        "# some notes in Kant\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sVorl\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sberschwenglich')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI3dJy_dibCA",
        "outputId": "0c8c8424-eefa-4907-9272-eec7354ef45b"
      },
      "source": [
        "# a common phrase in Plato / Aristotle footnotes\n",
        "df = df.drop(df[(df['author']=='Plato') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "df = df.drop(df[(df['author']=='Aristotle') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUt3mAjtigKB",
        "outputId": "54290032-56b2-40ec-95ad-8df16524c607"
      },
      "source": [
        "# mentions of Aristotle in Plato\n",
        "df = df.drop(df[(df['author']=='Plato') & df['sentence_str'].str.contains('Aristotle')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "985"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sd2rbDJHraR"
      },
      "source": [
        "### Lemmatize and Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLKswX_Hrhd"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# use gensim to tokenize sentences\n",
        "df['tokenized_txt'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
        "                                                        max_len=200))\n",
        "\n",
        "# use spacey to get intelligent lemmatization\n",
        "def lemmatize_sentence(sentence):\n",
        "  lemmatized_txt = ''\n",
        "  for word in sentence:\n",
        "    lemmatized_txt += ' ' + str(word.lemma_)\n",
        "  return lemmatized_txt"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sg_V1rxIdzJ"
      },
      "source": [
        "df['lemmatized_str'] = df['sentence_spacy'].apply(lemmatize_sentence)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 921
        },
        "id": "0pyznlhXId8n",
        "outputId": "7031caba-eeed-44ee-e312-5a24c588a2f2"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(And, you, have, found, that, this, Being, is, life, itself, ,, light, ,, wisdom, ,, goodness, ,, eter, nal, blessedness, ,, and, blessed, eternity, and, that, this, Being, exists, everywhere, and...</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>And you have found that this Being is life itself, light, wisdom, goodness, eter nal blessedness, and blessed eternity and that this Being exists everywhere and always.</td>\n",
              "      <td>168</td>\n",
              "      <td>[and, you, have, found, that, this, being, is, life, itself, light, wisdom, goodness, eter, nal, blessedness, and, blessed, eternity, and, that, this, being, exists, everywhere, and, always]</td>\n",
              "      <td>and -PRON- have find that this being be life -PRON- , light , wisdom , goodness , eter nal blessedness , and bless eternity and that this be exist everywhere and always .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1135</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(For, truth, does, not, have, its, being, in, or, from, or, through, the, things, in, which, it, is, said, to, be, .)</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>For truth does not have its being in or from or through the things in which it is said to be.</td>\n",
              "      <td>93</td>\n",
              "      <td>[for, truth, does, not, have, its, being, in, or, from, or, through, the, things, in, which, it, is, said, to, be]</td>\n",
              "      <td>for truth do not have -PRON- being in or from or through the thing in which -PRON- be say to be .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(For, just, as, God, is, able, to, do, through, Himself, that, which, He, wills, ,, so, they, shall, be, able, to, do, through, Him, that, which, they, shall, will, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>For just as God is able to do through Himself that which He wills, so they shall be able to do through Him that which they shall will.</td>\n",
              "      <td>134</td>\n",
              "      <td>[for, just, as, god, is, able, to, do, through, himself, that, which, he, wills, so, they, shall, be, able, to, do, through, him, that, which, they, shall, will]</td>\n",
              "      <td>for just as God be able to do through -PRON- that which -PRON- will , so -PRON- shall be able to do through -PRON- that which -PRON- shall will .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Alas, ,, what, he, lost, and, what, he, found, ,, what, vanished, and, what, remained, !)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>Alas, what he lost and what he found, what vanished and what remained!</td>\n",
              "      <td>70</td>\n",
              "      <td>[alas, what, he, lost, and, what, he, found, what, vanished, and, what, remained]</td>\n",
              "      <td>alas , what -PRON- lose and what -PRON- find , what vanish and what remain !</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(But, surely, that, than, which, a, greater, can, not, be, thought, can, not, be, only, in, the, understanding, .)</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>But surely that than which a greater cannot be thought cannot be only in the understanding.</td>\n",
              "      <td>91</td>\n",
              "      <td>[but, surely, that, than, which, greater, cannot, be, thought, cannot, be, only, in, the, understanding]</td>\n",
              "      <td>but surely that than which a great can not be think can not be only in the understanding .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            title  ...                                                                                                                                                               lemmatized_str\n",
              "338    Proslogion  ...   and -PRON- have find that this being be life -PRON- , light , wisdom , goodness , eter nal blessedness , and bless eternity and that this be exist everywhere and always .\n",
              "1135  De Veritate  ...                                                                            for truth do not have -PRON- being in or from or through the thing in which -PRON- be say to be .\n",
              "534    Proslogion  ...                            for just as God be able to do through -PRON- that which -PRON- will , so -PRON- shall be able to do through -PRON- that which -PRON- shall will .\n",
              "81     Proslogion  ...                                                                                                 alas , what -PRON- lose and what -PRON- find , what vanish and what remain !\n",
              "165    Proslogion  ...                                                                                   but surely that than which a great can not be think can not be only in the understanding .\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOxPwDpIeDT"
      },
      "source": [
        "### Combine with the Old Dataframe & Export to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UU8QqgIXInkp",
        "outputId": "113d5c7c-f825-4089-97ac-25014210f465"
      },
      "source": [
        "# load the old version and check it out\n",
        "og_df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/philosophy_data.csv')\n",
        "og_df.sample(5)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>107115</th>\n",
              "      <td>Ethics</td>\n",
              "      <td>Spinoza</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>It is impossible that there should be in the universe two substances with an identical attribute, ie which have anything common to them both</td>\n",
              "      <td>It is impossible that there should be in the universe two substances with an identical attribute, ie which have anything common to them both</td>\n",
              "      <td>1677</td>\n",
              "      <td>2003</td>\n",
              "      <td>140</td>\n",
              "      <td>it is impossible that there should be in the universe two substances with an identical attribute, ie which have anything common to them both</td>\n",
              "      <td>['it', 'is', 'impossible', 'that', 'there', 'should', 'be', 'in', 'the', 'universe', 'two', 'substances', 'with', 'an', 'identical', 'attribute', 'ie', 'which', 'have', 'anything', 'common', 'to',...</td>\n",
              "      <td>-PRON- be impossible that there should be in the universe two substance with an identical attribute , ie which have anything common to -PRON- both</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45566</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>It is clear then that chance is an accidental cause in the sphere of those actions for the sake of something which involve choice.</td>\n",
              "      <td>It is clear then that chance is an accidental cause in the sphere of those actions for the sake of something which involve choice.</td>\n",
              "      <td>-320</td>\n",
              "      <td>1991</td>\n",
              "      <td>130</td>\n",
              "      <td>it is clear then that chance is an accidental cause in the sphere of those actions for the sake of something which involve choice.</td>\n",
              "      <td>['it', 'is', 'clear', 'then', 'that', 'chance', 'is', 'an', 'accidental', 'cause', 'in', 'the', 'sphere', 'of', 'those', 'actions', 'for', 'the', 'sake', 'of', 'something', 'which', 'involve', 'ch...</td>\n",
              "      <td>-PRON- be clear then that chance be an accidental cause in the sphere of those action for the sake of something which involve choice .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98023</th>\n",
              "      <td>A Treatise Of Human Nature</td>\n",
              "      <td>Hume</td>\n",
              "      <td>empiricism</td>\n",
              "      <td>For as like causes always produce like effects, when in any instance we find our expectation to be disappointed, we must conclude that this irregularity proceeds from some difference in the causes.</td>\n",
              "      <td>For as like causes always produce like effects, when in any instance we find our expectation to be disappointed, we must conclude that this irregularity proceeds from some difference in the causes.</td>\n",
              "      <td>1739</td>\n",
              "      <td>2003</td>\n",
              "      <td>197</td>\n",
              "      <td>for as like causes always produce like effects, when in any instance we find our expectation to be disappointed, we must conclude that this irregularity proceeds from some difference in the causes.</td>\n",
              "      <td>['for', 'as', 'like', 'causes', 'always', 'produce', 'like', 'effects', 'when', 'in', 'any', 'instance', 'we', 'find', 'our', 'expectation', 'to', 'be', 'disappointed', 'we', 'must', 'conclude', '...</td>\n",
              "      <td>for as like cause always produce like effect , when in any instance -PRON- find -PRON- expectation to be disappoint , -PRON- must conclude that this irregularity proceed from some difference in t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282011</th>\n",
              "      <td>The Phenomenology Of Spirit</td>\n",
              "      <td>Hegel</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>In general, she maintains that itis the power of youth that really counts; the worth of the son lies in his being the lord and master of the mother who bore him, that ofthehrotherasheingone in who...</td>\n",
              "      <td>In general, she maintains that itis the power of youth that really counts; the worth of the son lies in his being the lord and master of the mother who bore him, that ofthehrotherasheingone in who...</td>\n",
              "      <td>1807</td>\n",
              "      <td>1977</td>\n",
              "      <td>386</td>\n",
              "      <td>in general, she maintains that itis the power of youth that really counts; the worth of the son lies in his being the lord and master of the mother who bore him, that ofthehrotherasheingone in who...</td>\n",
              "      <td>['in', 'general', 'she', 'maintains', 'that', 'itis', 'the', 'power', 'of', 'youth', 'that', 'really', 'counts', 'the', 'worth', 'of', 'the', 'son', 'lies', 'in', 'his', 'being', 'the', 'lord', 'a...</td>\n",
              "      <td>in general , -PRON- maintain that itis the power of youth that really count ; the worth of the son lie in -PRON- be the lord and master of the mother who bear -PRON- , that ofthehrotherasheingone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118366</th>\n",
              "      <td>The Search After Truth</td>\n",
              "      <td>Malebranche</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>an: indifferent to it.</td>\n",
              "      <td>an: indifferent to it.</td>\n",
              "      <td>1674</td>\n",
              "      <td>1997</td>\n",
              "      <td>22</td>\n",
              "      <td>an: indifferent to it.</td>\n",
              "      <td>['an', 'indifferent', 'to', 'it']</td>\n",
              "      <td>an : indifferent to -PRON- .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              title  ...                                                                                                                                                                                           lemmatized_str\n",
              "107115                       Ethics  ...                                                       -PRON- be impossible that there should be in the universe two substance with an identical attribute , ie which have anything common to -PRON- both\n",
              "45566    Aristotle - Complete Works  ...                                                                   -PRON- be clear then that chance be an accidental cause in the sphere of those action for the sake of something which involve choice .\n",
              "98023    A Treatise Of Human Nature  ...   for as like cause always produce like effect , when in any instance -PRON- find -PRON- expectation to be disappoint , -PRON- must conclude that this irregularity proceed from some difference in t...\n",
              "282011  The Phenomenology Of Spirit  ...   in general , -PRON- maintain that itis the power of youth that really count ; the worth of the son lie in -PRON- be the lord and master of the mother who bear -PRON- , that ofthehrotherasheingone...\n",
              "118366       The Search After Truth  ...                                                                                                                                                                             an : indifferent to -PRON- .\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfwEX5vzInx0",
        "outputId": "2bf95ccf-c25f-4265-c6fd-237b0ffd0825"
      },
      "source": [
        "og_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Aristotle          0.133687\n",
              "Plato              0.105148\n",
              "Hegel              0.062213\n",
              "Foucault           0.041768\n",
              "Heidegger          0.041765\n",
              "Kant               0.038720\n",
              "Nietzsche          0.037130\n",
              "Marx               0.036969\n",
              "Lewis              0.035957\n",
              "Beauvoir           0.035675\n",
              "Malebranche        0.035620\n",
              "Deleuze            0.034368\n",
              "Kripke             0.034201\n",
              "Smith              0.032047\n",
              "Wittgenstein       0.024759\n",
              "Locke              0.024351\n",
              "Hume               0.022780\n",
              "Merleau-Ponty      0.020807\n",
              "Quine              0.020207\n",
              "Derrida            0.016441\n",
              "Husserl            0.015737\n",
              "Fichte             0.014547\n",
              "Russell            0.013903\n",
              "Leibniz            0.013777\n",
              "Popper             0.012821\n",
              "Lenin              0.012248\n",
              "Augustine          0.011149\n",
              "Spinoza            0.010395\n",
              "Moore              0.010053\n",
              "Keynes             0.009348\n",
              "Ricardo            0.008469\n",
              "Davis              0.008384\n",
              "Berkeley           0.007493\n",
              "Wollstonecraft     0.007013\n",
              "Marcus Aurelius    0.006062\n",
              "Descartes          0.003102\n",
              "Epictetus          0.000885\n",
              "Name: author, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQcxBh37IoDJ",
        "outputId": "e06ffe44-7a43-4eaa-a1eb-1abfaa1a0bc1"
      },
      "source": [
        "# append the new data\n",
        "new_df = og_df.append(df)\n",
        "new_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Aristotle          0.133327\n",
              "Plato              0.104865\n",
              "Hegel              0.062045\n",
              "Foucault           0.041655\n",
              "Heidegger          0.041652\n",
              "Kant               0.038616\n",
              "Nietzsche          0.037030\n",
              "Marx               0.036869\n",
              "Lewis              0.035861\n",
              "Beauvoir           0.035579\n",
              "Malebranche        0.035524\n",
              "Deleuze            0.034275\n",
              "Kripke             0.034109\n",
              "Smith              0.031960\n",
              "Wittgenstein       0.024692\n",
              "Locke              0.024285\n",
              "Hume               0.022719\n",
              "Merleau-Ponty      0.020751\n",
              "Quine              0.020152\n",
              "Derrida            0.016397\n",
              "Husserl            0.015694\n",
              "Fichte             0.014508\n",
              "Russell            0.013866\n",
              "Leibniz            0.013740\n",
              "Popper             0.012786\n",
              "Lenin              0.012215\n",
              "Augustine          0.011119\n",
              "Spinoza            0.010367\n",
              "Moore              0.010026\n",
              "Keynes             0.009323\n",
              "Ricardo            0.008446\n",
              "Davis              0.008361\n",
              "Berkeley           0.007473\n",
              "Wollstonecraft     0.006994\n",
              "Marcus Aurelius    0.006046\n",
              "Descartes          0.003094\n",
              "Anselm             0.002692\n",
              "Epictetus          0.000883\n",
              "Name: author, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 820
        },
        "id": "bwgCHszFf6_p",
        "outputId": "167f2c27-1e18-436f-ce9e-bd6c38cb9c69"
      },
      "source": [
        "new_df[new_df['author']=='Anselm'].sample(5)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Tell, me, ,, then, ,, whether, you, think, that, there, is, still, another, rightness, in, addition, to, those, rightnesses, we, have, examined, .)</td>\n",
              "      <td>Tell me, then, whether you think that there is still another rightness in addition to those rightnesses we have examined.</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>121</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[tell, me, then, whether, you, think, that, there, is, still, another, rightness, in, addition, to, those, rightnesses, we, have, examined]</td>\n",
              "      <td>tell -PRON- , then , whether -PRON- think that there be still another rightness in addition to those rightness -PRON- have examine .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>802</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Your, answer, has, satisfied, me, .)</td>\n",
              "      <td>Your answer has satisfied me.</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>29</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[your, answer, has, satisfied, me]</td>\n",
              "      <td>-PRON- answer have satisfy -PRON- .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>648</th>\n",
              "      <td>De Veritate</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(I, do, not, think, it, is, .)</td>\n",
              "      <td>I do not think it is.</td>\n",
              "      <td>1086</td>\n",
              "      <td>2000</td>\n",
              "      <td>21</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[do, not, think, it, is]</td>\n",
              "      <td>-PRON- do not think -PRON- be .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Those, who, are, just, You, save, through, the, aid, of, their, merits, ;, those, who, are, evil)</td>\n",
              "      <td>Those who are just You save through the aid of their merits; those who are evil</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>79</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[those, who, are, just, you, save, through, the, aid, of, their, merits, those, who, are, evil]</td>\n",
              "      <td>those who be just -PRON- save through the aid of -PRON- merit ; those who be evil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Proslogion</td>\n",
              "      <td>Anselm</td>\n",
              "      <td>Scholasticism</td>\n",
              "      <td>(Afterwards, ,, considering, this, work, to, be, composed, of, a, chain, of, many, arguments, ,, I, began, to, ask, myself, whether, perhaps, a, single, consideration, could, be, found, which, wou...</td>\n",
              "      <td>Afterwards, considering this work to be composed of a chain of many arguments, I began to ask myself whether perhaps a single consideration could be found which would require nothing other than it...</td>\n",
              "      <td>1077</td>\n",
              "      <td>2000</td>\n",
              "      <td>277</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[afterwards, considering, this, work, to, be, composed, of, chain, of, many, arguments, began, to, ask, myself, whether, perhaps, single, consideration, could, be, found, which, would, require, no...</td>\n",
              "      <td>afterwards , consider this work to be compose of a chain of many argument , -PRON- begin to ask -PRON- whether perhaps a single consideration could be find which would require nothing other than ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           title  ...                                                                                                                                                                                           lemmatized_str\n",
              "941  De Veritate  ...                                                                     tell -PRON- , then , whether -PRON- think that there be still another rightness in addition to those rightness -PRON- have examine .\n",
              "802  De Veritate  ...                                                                                                                                                                      -PRON- answer have satisfy -PRON- .\n",
              "648  De Veritate  ...                                                                                                                                                                          -PRON- do not think -PRON- be .\n",
              "266   Proslogion  ...                                                                                                                        those who be just -PRON- save through the aid of -PRON- merit ; those who be evil\n",
              "1     Proslogion  ...   afterwards , consider this work to be compose of a chain of many argument , -PRON- begin to ask -PRON- whether perhaps a single consideration could be find which would require nothing other than ...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ncmXLdXuIoMl",
        "outputId": "840932df-e465-468b-c76f-df3162a3da64"
      },
      "source": [
        "# export as csv\n",
        "from google.colab import files\n",
        "new_df.to_csv('phil_nlp.csv', index=False) \n",
        "files.download('phil_nlp.csv')"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_5c585881-ff29-494b-9c11-eae256cb1694\", \"phil_nlp.csv\", 328679494)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz0aj3NrECm3"
      },
      "source": [
        "###Upload Data to the SQL Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "bW76POWkJL-b",
        "outputId": "089a6106-e8e4-47ac-83da-ce6f8bd3fe1d"
      },
      "source": [
        "# prepare to upload to the PostgreSQL database\n",
        "\n",
        "# note which dataframe you set this to - new_df for the whole dataset, df for \n",
        "# just the new text\n",
        "\n",
        "for_db = new_df\n",
        "for_db['date'] = for_db['original_publication_date']\n",
        "for_db['date'] = for_db['date'].apply(lambda x: str(x)[1:]+' BC' if x < 0 else str(x))\n",
        "for_db['sentence'] = for_db['sentence_str']\n",
        "for_db['school'] = for_db['school'].apply(lambda x: x.replace('_', ' ').title())\n",
        "for_db = for_db.drop(['sentence_spacy', \n",
        "                      'sentence_length',\n",
        "                      'sentence_lowered', \n",
        "                      'sentence_str', \n",
        "                      'tokenized_txt', \n",
        "                      'lemmatized_str',\n",
        "                      'corpus_edition_date',\n",
        "                      'original_publication_date'], axis=1)\n",
        "for_db.columns = [i.upper() for i in for_db.columns]\n",
        "\n",
        "for_db.sample(5)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>SCHOOL</th>\n",
              "      <th>DATE</th>\n",
              "      <th>SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7294</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>Plato</td>\n",
              "      <td>350 BC</td>\n",
              "      <td>The rest of it, visitor, seems to have been said in due measure; but that ideal rule may exist even without laws was something harder for a hearer to accept.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72796</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>320 BC</td>\n",
              "      <td>Yet all the parts must exist only potentially, when they are one and continuous by nature, not by force or even by growing together, for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57750</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>320 BC</td>\n",
              "      <td>Some assert that ring doves and turtle doves pair and procreate when only three months old, and instance their superabundant numbers by way of proof of the assertion.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174618</th>\n",
              "      <td>Philosophical Troubles</td>\n",
              "      <td>Kripke</td>\n",
              "      <td>Analytic</td>\n",
              "      <td>1975</td>\n",
              "      <td>What premise did we use?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83429</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>320 BC</td>\n",
              "      <td>Athletic excellence of the body consists in size and strength; for the swift man is strong he who can fling forward his legs in a certain way, and move them fast and far, is good at running; he wh...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             TITLE  ...                                                                                                                                                                                                 SENTENCE\n",
              "7294        Plato - Complete Works  ...                                            The rest of it, visitor, seems to have been said in due measure; but that ideal rule may exist even without laws was something harder for a hearer to accept.\n",
              "72796   Aristotle - Complete Works  ...                                                                 Yet all the parts must exist only potentially, when they are one and continuous by nature, not by force or even by growing together, for\n",
              "57750   Aristotle - Complete Works  ...                                   Some assert that ring doves and turtle doves pair and procreate when only three months old, and instance their superabundant numbers by way of proof of the assertion.\n",
              "174618      Philosophical Troubles  ...                                                                                                                                                                                 What premise did we use?\n",
              "83429   Aristotle - Complete Works  ...  Athletic excellence of the body consists in size and strength; for the swift man is strong he who can fling forward his legs in a certain way, and move them fast and far, is good at running; he wh...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWSVKbmoVaAW",
        "outputId": "9ee38d0b-d21b-42a4-df01-0f67440b7381"
      },
      "source": [
        "len(for_db)"
      ],
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "365861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mni3N-fyK-jZ",
        "outputId": "c11bca16-d523-4110-eac7-0cd16bf7113f"
      },
      "source": [
        "#importing sql library \n",
        "from sqlalchemy import create_engine \n",
        "  \n",
        "# create a reference  \n",
        "# for sql library \n",
        "engine = create_engine('postgo',\n",
        "                       echo=False)\n",
        "  \n",
        "# attach the data frame to the sql server \n",
        "for_db.to_sql('phil_nlp', \n",
        "               con = engine,\n",
        "              if_exists='replace',\n",
        "              index=False,\n",
        "              method='multi') \n",
        "  \n",
        "# show the completed data as a test\n",
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp WHERE \"AUTHOR\" = 'Anselm'\"\"\").fetchone()) "
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Proslogion', 'Anselm', 'Scholasticism', '1077', 'How is it, then, Lord, that You are all these things?')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRYDdaLGW2"
      },
      "source": [
        "Remember to add to the clipping and other elements to the notebook that creates the database as a whole. Then you're done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK50YeA-LNtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9b00e78-612e-481a-cbb4-4a0b8918b36a"
      },
      "source": [
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp where \"AUTHOR\" = 'Anselm'\"\"\").fetchone()) "
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Proslogion', 'Anselm', 'Scholasticism', '1077', 'How is it, then, Lord, that You are all these things?')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfaWbJkCid6W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}