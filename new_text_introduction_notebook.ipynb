{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new_text_introduction_notebook.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMmPo3DvEp0lyvMreGMjr4Y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/PDP_data_processing/blob/master/new_text_introduction_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Cw_rJlXCob_"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN4DvDsxCdio",
        "outputId": "f27c6edb-fd48-44bc-fbcc-5c7d740d4fcf"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\n",
        "# and relevant libraries via the functions.py file\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/philosophy_data_project'\n",
        "\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAk2WGLbCn3t"
      },
      "source": [
        "from import_functions import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fV19sbpUC2PF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35bbe288-9bb0-4675-b620-9988518b3042"
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")\n",
        "import en_core_web_lg\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbT8yZ0pC30A"
      },
      "source": [
        "###Load the Text and Clip Front and End Matter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-MzN2T2DUYm"
      },
      "source": [
        "# if you are deleting an old text that was added here, make sure it is in the \n",
        "# primary database construction notebook\n",
        "hobbes_leviathan = get_text(drive_path + '/phil_txts/hobbes_leviathan.txt')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eilq25ib1Ba"
      },
      "source": [
        "hobbes_leviathan = hobbes_leviathan[198:]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuWrhYwOUbck"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suHuy6isDUiC"
      },
      "source": [
        "### Clean the Text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4lfFHzvnDUpf"
      },
      "source": [
        "def baseline_clean(to_correct, \n",
        "                   capitals=True, \n",
        "                   bracketed_fn=False, \n",
        "                   odd_words_dict={}):\n",
        "  # remove utf8 encoding characters and some punctuations\n",
        "  result = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6§\\\\\\£\\Â*_<>\"\"⎫•{}Γ~]', ' ', to_correct)\n",
        "  result = re.sub(r'[\\u2014\\u2013\\u2012-]', ' ', result)\n",
        "\n",
        "  # replace whitespace characters with actual whitespace\n",
        "  result = re.sub(r'\\s', ' ', result)\n",
        "\n",
        "  # replace odd quotation marks with a standard\n",
        "  result = re.sub(r'[‘’“”]', \"'\", result)\n",
        "\n",
        "  # replace the ﬀ, ﬃ and ﬁ with the appropriate counterparts\n",
        "  result = re.sub(r'ﬀ', 'ff', result)\n",
        "  result = re.sub(r'ﬁ', 'fi', result)\n",
        "  result = re.sub(r'ﬃ', 'ffi', result)\n",
        "\n",
        "  # replace some accented characters for ease of searching\n",
        "  result = re.sub(r'é', 'e', result)\n",
        "\n",
        "  # remove or standardize some recurring common and meaninless words/phrases\n",
        "  result = re.sub(r'\\s*This\\s*page\\s*intentionally\\s*left\\s*blank\\s*', ' ', result)\n",
        "  result = re.sub(r'(?i)Aufgabe\\s+', ' ', result)\n",
        "  result = re.sub(r',*\\s+cf\\.', ' ', result)\n",
        "\n",
        "  # some texts have footnotes conveniently in brackets - this removes them all, \n",
        "  # with a safety measure for unpaired brackets, and deletes all brackets afterwards\n",
        "  if bracketed_fn:\n",
        "    result = re.sub(r'\\[.{0,300}\\]|{.{0,300}}|{.{0,300}\\]|\\[.{0,300}}', ' ', result)\n",
        "  result = re.sub(r'[\\[\\]{}]', ' ', result)\n",
        "\n",
        "  # unify some abbreviations\n",
        "  result = re.sub(r'&', 'and', result)\n",
        "  result = re.sub(r'\\se\\.g\\.\\s', ' eg ', result)\n",
        "  result = re.sub(r'\\si\\.e\\.\\s', ' ie ', result)\n",
        "  result = re.sub('coroll\\.', 'coroll', result)\n",
        "  result = re.sub('pt\\.', 'pt', result)\n",
        "\n",
        "  # remove roman numerals, first capitalized ones\n",
        "  result = re.sub(r'\\s((I{2,}V*X*\\.*)|(IV\\.*)|(IX\\.*)|(V\\.*)|(V+I*\\.*)|(X+L*V*I*]\\.*))\\s', ' ', result)\n",
        "  # then lowercase\n",
        "  result = re.sub(r'\\s((i{2,}v*x*\\.*)|(iv\\.*)|(ix\\.*)|(v\\.*)|(v+i*\\.*)|(x+l*v*i*\\.*))\\s', ' ', result)\n",
        "\n",
        "  # remove periods and commas flanked by numbers\n",
        "  result = re.sub(r'\\d\\.\\d', ' ', result)\n",
        "  result = re.sub(r'\\d,\\d', ' ', result)\n",
        "\n",
        "  # remove the number-letter-number pattern used for many citations\n",
        "  result = re.sub(r'\\d*\\w{,2}\\d', ' ', result)\n",
        "\n",
        "  # remove numerical characters\n",
        "  result = re.sub(r'\\d+', ' ', result)\n",
        "\n",
        "  # remove words of 2+ characters that are entirely capitalized \n",
        "  # (these are almost always titles, headings, or speakers in a dialogue)\n",
        "  # remove capital I's that follow capital words - these almost always roman numerals\n",
        "  # some texts do use these capitalizations meaningfully, so we make this optional\n",
        "  if capitals:\n",
        "    result = re.sub(r'[A-Z]{2,}\\s+I', ' ', result)\n",
        "    result = re.sub(r'[A-Z]{2,}', ' ', result)\n",
        "\n",
        "  # remove isolated colons and semicolons that result from removal of titles\n",
        "  result = re.sub(r'\\s+:\\s*', ' ', result)\n",
        "  result = re.sub(r'\\s+;\\s*', ' ', result)\n",
        "\n",
        "  # remove isolated letters (do it several times because strings of isolated letters do not get captured properly)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\n",
        "\n",
        "  # remove isolated letters at the end of sentences or before commas\n",
        "  result = re.sub(r'\\s[^aI]\\.', '.', result)\n",
        "  result = re.sub(r'\\s[^aI],', ',', result)\n",
        "\n",
        "  # deal with spaces around periods and commas\n",
        "  result = re.sub(r'\\s+,\\s+', ', ', result)\n",
        "  result = re.sub(r'\\s+\\.\\s+', '. ', result)\n",
        "\n",
        "  # remove empty parantheses\n",
        "  result = re.sub(r'(\\(\\s*\\.*\\s*\\))|(\\(\\s*,*\\s*)\\)', ' ', result)\n",
        "  result = re.sub(r'\\.\\)\\.', '.', result)\n",
        "  result = re.sub(r'\\.\\(\\.', '.', result)\n",
        "\n",
        "  # reduce multiple periods, commas, or whitespaces into a single one\n",
        "  result = re.sub(r'\\.+', '.', result)\n",
        "  result = re.sub(r',+', ',', result)\n",
        "  result = re.sub(r'\\s+', ' ', result)\n",
        "\n",
        "  # deal with isolated problem cases discovered in the data:\n",
        "  for key in odd_words_dict.keys():\n",
        "    result = re.sub(r''+key+'', odd_words_dict[key], result)\n",
        "\n",
        "  return result"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OjRlTV_EEHM"
      },
      "source": [
        "# note extras like bracketed footnotes or specific words to remove\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Y9RIRBED-F"
      },
      "source": [
        "# build a dictionary for the book\n",
        "hobbes_leviathan_dict = {\n",
        "    'author': 'Hobbes',\n",
        "    'title': 'Leviathan',\n",
        "    'text': hobbes_leviathan,\n",
        "    'school': 'Hobbes',\n",
        "    'words to remove': [],\n",
        "    'remove capitals': True,\n",
        "    'bracketed fn': False,\n",
        "    'original date': 1651,\n",
        "    'corpus date': 1651\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fkWlxhoIOjA",
        "cellView": "form"
      },
      "source": [
        "#@title Oddities Dictionary for Cleaning\n",
        "# a dictionary of oddities to clean up\n",
        "odd_words_dict = {'\\sderstanding': 'derstanding',\n",
        "                  '\\sditference\\s': ' difference ',\n",
        "                  '\\sforthe\\s': ' for the ',\n",
        "                  '\\sject': 'ject',\n",
        "                  '\\sSure ly\\s': ' Surely ',\n",
        "                  '\\spiness': 'piness',\n",
        "                  '\\sjects': 'jects', \n",
        "                  '\\sness': 'ness',\n",
        "                  '\\schil dren\\s': ' children ',\n",
        "                  '\\sper\\scent\\s': ' percent ',\n",
        "                  '\\sper\\scent\\.': ' percent.',\n",
        "                  '\\sper\\scent,': ' percent,',\n",
        "                  '\\wi\\son': 'ion',\n",
        "                  '\\spri\\sori': ' priori',\n",
        "                  '\\stences\\s': 'tences ',\n",
        "                  '\\sprincipleb': ' principle',\n",
        "                  '\\ssciousness': 'sciousness',\n",
        "                  '\\stion': 'tion',\n",
        "                  '\\spri\\s': ' pri',\n",
        "                  '\\scluding': 'cluding',\n",
        "                  '\\sdom': 'dom',\n",
        "                  '\\sers': 'ers',\n",
        "                  '\\scritiq\\s': ' critique ',\n",
        "                  '\\ssensati\\s': ' sensation ',\n",
        "                  '(?i)\\syou\\sll': \" you'll\",\n",
        "                  '\\sI\\sll': \" I'll\",\n",
        "                  '(?i)\\swe\\sll': \" we'll\",\n",
        "                  '(?i)he\\sll': \" he'll\",\n",
        "                  '(?i)who\\sll': \"who'll\",\n",
        "                  '(?i)\\sthere\\sll\\s': \" there'll \",\n",
        "                  '\\seduca\\s': ' education ',\n",
        "                  '\\slity\\s': 'lity ',\n",
        "                  '\\smultaneously\\s': 'multaneously ',\n",
        "                  '\\stically\\s': 'tically ',\n",
        "                  '\\sDa\\ssein\\s': ' Dasein ',\n",
        "                  '(?i)\\sthey\\sll\\s': \" they'll \",\n",
        "                  '(?i)\\sin\\tum\\s': ' in turn ',\n",
        "                  '\\scon~\\s': ' con',\n",
        "                  '\\sà\\s': ' a ',\n",
        "                  '\\sjor\\s': ' for ',\n",
        "                  '\\sluminating\\s': 'luminating ',\n",
        "                  '\\sselj\\s': ' self ',\n",
        "                  '\\stial\\s': 'tial ',\n",
        "                  '\\sversal\\s': 'versal ',\n",
        "                  '\\sexis\\st': ' exist',\n",
        "                  '\\splauded\\s': 'plauded ',\n",
        "                  '\\suiry\\s': 'uiry ',\n",
        "                  '\\svithin\\s': ' within ',\n",
        "                  '\\soj\\s': ' of ',\n",
        "                  '\\sposi\\st': ' posit',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '(?i)\\sthat\\sll\\s': \" that'll \",\n",
        "                  '(?i)\\sa\\sll\\s': ' all ',\n",
        "                  '\\so\\sther\\s': ' other ',\n",
        "                  '\\sra\\sther\\s': ' rather ',\n",
        "                  '\\snei\\sther\\s': ' neither ',\n",
        "                  '\\sei\\sther\\s': ' either ',\n",
        "                  '\\sfur\\sther\\s': ' further ',\n",
        "                  '\\sano\\sther': ' another ',\n",
        "                  '\\sneces\\s': ' neces',\n",
        "                  'u\\slar\\s': 'ular ',\n",
        "                  '\\sference\\s': 'ference ',\n",
        "                  '(?i)it\\sll\\s': \"it'll \",\n",
        "                  '\\stoge\\sther': ' together ',\n",
        "                  '\\sknowledgeb\\s': ' knowledge ',\n",
        "                  'r\\stain\\s': 'rtain ',\n",
        "                  'on\\stain\\s': 'ontain',\n",
        "                  '(?i)j\\sect\\s': 'ject',\n",
        "                  '\\sob\\sect\\s': ' object ',\n",
        "                  '\\sbtle\\s': 'btle ',\n",
        "                  '\\snition\\s': 'nition ',\n",
        "                  '\\sdering\\s': 'dering ', \n",
        "                  '\\sized\\s': 'ized ',\n",
        "                  '\\sther\\shand': ' other hand',\n",
        "                  '\\ture\\s': 'ture ',\n",
        "                  '\\sabso\\sl': ' absol',\n",
        "                  '\\stly\\s': 'tly ',\n",
        "                  '\\serty\\s': 'erty ',\n",
        "                  '\\sobj\\se': ' obj',\n",
        "                  '\\sffiir\\s': ' for ',\n",
        "                  '\\sndeed\\s': ' indeed ',\n",
        "                  '\\sfonn\\s': ' form ',\n",
        "                  '\\snally\\s': 'nally ',\n",
        "                  'ain\\sty\\s': 'ainty ',\n",
        "                  'ici\\sty\\s': 'icity ',\n",
        "                  '\\scog\\sni': ' cogni',\n",
        "                  '\\sacc\\s': ' acc',\n",
        "                  '\\sindi\\svid\\sual': ' individual', \n",
        "                  '\\sintu\\sit': ' intuit',\n",
        "                  'r\\sance\\s': 'rance ',\n",
        "                  '\\ssions\\s': 'sions ',\n",
        "                  '\\sances\\s': 'ances ',\n",
        "                  '\\sper\\sception\\s': ' perception ',\n",
        "                  '\\sse\\sries\\s': ' series ',\n",
        "                  '\\sque\\sries\\s': ' queries ',\n",
        "                  '\\sessary\\s': 'essary ',\n",
        "                  '\\sofa\\s': ' of a ',\n",
        "                  '\\scer\\stainty\\s': ' certainty ',\n",
        "                  'ec\\stivity\\s': 'ectivity ',\n",
        "                  '\\stivity\\s': 'tivity ',\n",
        "                  '\\slation\\s': 'lation ',\n",
        "                  '\\sir\\sr': ' irr',\n",
        "                  '\\ssub\\sstance\\s': ' substance ',\n",
        "                  'sec\\sond\\s': 'second ',\n",
        "                  '\\s\\.rv': '',\n",
        "                  '\\story\\s': 'tory ',\n",
        "                  '\\sture\\s': 'ture ',\n",
        "                  '\\sminate\\s': 'minate ',\n",
        "                  '\\sing\\s': 'ing ',\n",
        "                  '\\splicity\\s': 'plicity ',\n",
        "                  '\\ssimi\\slar\\s': ' similar ',\n",
        "                  '\\scom\\smunity\\s': ' community ',\n",
        "                  '\\sitselfa\\s': ' itself a ',\n",
        "                  '\\ssimp\\s': ' simply ',\n",
        "                  '\\scon\\stex': ' contex',\n",
        "                  '\\scon\\sseq': ' conseq',\n",
        "                  '\\scon\\stai': ' contai',\n",
        "                  '\\sofwhat\\s': ' of what ',\n",
        "                  '\\sui\\s': 'ui',\n",
        "                  '\\sofan\\s': ' of an ',\n",
        "                  '\\saccor\\sdance\\s': ' accordance ',\n",
        "                  '\\stranscen\\sdental\\s': ' transcendental ',\n",
        "                  '\\sap\\spearances\\s': ' appearances ',\n",
        "                  'e\\squences\\s': 'equences ',\n",
        "                  '\\sorits\\s': ' or its ',\n",
        "                  '\\simma\\sn': ' imman',\n",
        "                  '\\seq\\sua': ' equa',\n",
        "                  '\\simpl\\sied\\s': ' implied ',\n",
        "                  '\\sbuta\\s': ' but a ',\n",
        "                  '\\sa\\snd\\s': ' and ',\n",
        "                  '\\sence\\s': 'ence ',\n",
        "                  '\\stain\\s': 'tain ',\n",
        "                  '\\sunder\\sstanding\\s': ' understanding ',\n",
        "                  'i\\sence\\s': 'ience ',\n",
        "                  'r\\sence\\s': 'rence ',\n",
        "                  '\\stical\\s': 'tical ',\n",
        "                  '\\sobjectsb\\s': ' objects ',\n",
        "                  '\\stbe\\s': ' the ',\n",
        "                  '\\smul\\st': ' mult',\n",
        "                  '\\sgen\\seral\\s': ' general ',\n",
        "                  '\\suniver\\ssal\\s': ' universal ',\n",
        "                  '\\scon\\stent\\s': ' content ',\n",
        "                  '\\spar\\sticular\\s': ' particular ',\n",
        "                  'ver\\ssity\\s': 'versity ',\n",
        "                  '\\sCritiq\\s': ' Critique ',\n",
        "                  '\\sphilo\\ssophy\\s': ' philosophy ',\n",
        "                  '\\seq\\s': ' eq'}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXDII00UED1c"
      },
      "source": [
        "# a function that takes the dictionary and returns a dataframe of sentences\n",
        "def from_raw_to_df(text_dict):\n",
        "  nlp.max_length = 9000000\n",
        "  text = text_dict['text']\n",
        "  text = remove_words(text, text_dict['words to remove'])\n",
        "  text = baseline_clean(text, capitals=text_dict['remove capitals'],\n",
        "                        bracketed_fn=text_dict['bracketed fn'],\n",
        "                        odd_words_dict=odd_words_dict)\n",
        "  text_nlp = nlp(text, disable=['ner'])\n",
        "  text_df = pd.DataFrame(columns=['title', 'author', 'school', 'sentence_spacy'])\n",
        "  text_df['sentence_spacy'] = list(text_nlp.sents)\n",
        "  text_df['author'] = text_dict['author']\n",
        "  text_df['title'] = text_dict['title']\n",
        "  text_df['school'] = text_dict['school']\n",
        "  text_df['original_publication_date'] = text_dict['original date']\n",
        "  text_df['corpus_edition_date'] = text_dict['corpus date']\n",
        "  text_df['sentence_str'] = text_df['sentence_spacy'].apply(lambda x: ''.join(list(str(x))))\n",
        "  return text_df"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w14qMlTrFM4s"
      },
      "source": [
        "# use the function\n",
        "f_t_df = from_raw_to_df(hobbes_leviathan_dict)\n",
        "df = f_t_df"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 801
        },
        "id": "IZ3JhAyNFept",
        "outputId": "28ce9745-f39a-4172-e2ce-571ca1fc2e1f"
      },
      "source": [
        "# checking the result\n",
        "pd.options.display.max_colwidth = 200\n",
        "df.sample(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5574</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Therefore, the, safest, way, is, to, believe, that, by, the, descending, of, the, dove, upon, the, Apostles, ,, and, by, Christ, 's, breathing, on, them, when, he, gave, them, the, Holy, Ghost, ,...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Therefore the safest way is to believe that by the descending of the dove upon the Apostles, and by Christ's breathing on them when he gave them the Holy Ghost, and by the giving of it by impositi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4068</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(In, this, Trinity, on, earth, ,, the, unity, is, not, of, the, thing, ;, for, the, spirit, ,, the, water, ,, and, the, blood, are, not, the, same, substance, ,, though, they, give, the, same, tes...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>In this Trinity on earth, the unity is not of the thing; for the spirit, the water, and the blood are not the same substance, though they give the same testimony: but in the Trinity of heaven, the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>774</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(For, duels, also, are, many, times, effects, of, courage, ,, and, the, ground, of, courage, is, always, strength, or, skill, ,, which, are, power, ;, though, for, the, most, part, they, be, effec...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>For duels also are many times effects of courage, and the ground of courage is always strength or skill, which are power; though for the most part they be effects of rash speaking, and of the fear...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2697</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(And, seeing, the, end, of, punishing, is, not, revenge, and, discharge, of, choler, ,, but, correction, either, of, the, offender, or, of, others, by, his, example, ,, the, severest, punishments,...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>And seeing the end of punishing is not revenge and discharge of choler, but correction either of the offender or of others by his example, the severest punishments are to be inflicted for those cr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2637</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Lastly, ,, they, are, to, be, taught, that, not, only, the, unjust, facts, ,, but, the, designs, and, intentions, to, do, them, ,, though, by, accident, hindered, ,, are, injustice, ;, which, con...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Lastly, they are to be taught that not only the unjust facts, but the designs and intentions to do them, though by accident hindered, are injustice; which consisteth in the pravity of the will, as...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5365</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(In, the, other, places, which, he, allegeth, out, of, the, Old, Testament, ,, there, is, not, so, much, as, any, show, or, colour, of, proof, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>In the other places which he allegeth out of the Old Testament, there is not so much as any show or colour of proof.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2954</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Joshua, had, set, up, twelve, stones, in, the, midst, of, Jordan, ,, for, a, monument, of, their, passage, ;, of, which, the, writer, saith, thus, ,, They, are, there, unto, this, day, for, unto,...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Joshua had set up twelve stones in the midst of Jordan, for a monument of their passage; of which the writer saith thus, They are there unto this day for unto this day is a phrase that signifieth ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1469</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Besides, ,, there, is, no, favourite, of, a, monarch, which, can, not, as, well, succour, his, friends, as, hurt, his, enemies, :, but, orators, ,, that, is, to, say, ,, favourites, of, sovereign...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Besides, there is no favourite of a monarch which cannot as well succour his friends as hurt his enemies: but orators, that is to say, favourites of sovereign assemblies, though they have great po...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2860</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(there, dependeth, much, upon, supernatural, revelations, of, the, will, of, God, ,, the, ground, of, my, discourse, must, be, not, only, the, natural, word, of, God, ,, but, also, the, prophetica...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>there dependeth much upon supernatural revelations of the will of God, the ground of my discourse must be not only the natural word of God, but also the prophetical.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1427</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(For, in, the, sovereignty, is, the, fountain, of, honour, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>For in the sovereignty is the fountain of honour.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          title  ...                                                                                                                                                                                             sentence_str\n",
              "5574  Leviathan  ...  Therefore the safest way is to believe that by the descending of the dove upon the Apostles, and by Christ's breathing on them when he gave them the Holy Ghost, and by the giving of it by impositi...\n",
              "4068  Leviathan  ...  In this Trinity on earth, the unity is not of the thing; for the spirit, the water, and the blood are not the same substance, though they give the same testimony: but in the Trinity of heaven, the...\n",
              "774   Leviathan  ...  For duels also are many times effects of courage, and the ground of courage is always strength or skill, which are power; though for the most part they be effects of rash speaking, and of the fear...\n",
              "2697  Leviathan  ...  And seeing the end of punishing is not revenge and discharge of choler, but correction either of the offender or of others by his example, the severest punishments are to be inflicted for those cr...\n",
              "2637  Leviathan  ...  Lastly, they are to be taught that not only the unjust facts, but the designs and intentions to do them, though by accident hindered, are injustice; which consisteth in the pravity of the will, as...\n",
              "5365  Leviathan  ...                                                                                     In the other places which he allegeth out of the Old Testament, there is not so much as any show or colour of proof.\n",
              "2954  Leviathan  ...  Joshua had set up twelve stones in the midst of Jordan, for a monument of their passage; of which the writer saith thus, They are there unto this day for unto this day is a phrase that signifieth ...\n",
              "1469  Leviathan  ...  Besides, there is no favourite of a monarch which cannot as well succour his friends as hurt his enemies: but orators, that is to say, favourites of sovereign assemblies, though they have great po...\n",
              "2860  Leviathan  ...                                    there dependeth much upon supernatural revelations of the will of God, the ground of my discourse must be not only the natural word of God, but also the prophetical.\n",
              "1427  Leviathan  ...                                                                                                                                                        For in the sovereignty is the fountain of honour.\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZMqd8G0Ra-1",
        "outputId": "6c307393-8cd7-4f75-95a4-3ddb81e3088e"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6029"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-mqOl9pFgwH"
      },
      "source": [
        "#### Remove Short Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "EfYhrwWuFzOl",
        "outputId": "6d034bd1-08ed-4335-fa83-0320b605bcb4"
      },
      "source": [
        "df['sentence_length'] = df['sentence_str'].map(lambda x: len(x))\n",
        "num_of_short_entries = len(df[df['sentence_length'] < 20])\n",
        "print(f\"there are {num_of_short_entries} so-called sentences with fewer than 20 characters\")\n",
        "df[df['sentence_length'] < 20].sample(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 518 so-called sentences with fewer than 20 characters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2648</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Hard, questions, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Hard questions.</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4329</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Exodus, ,, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Exodus,.</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4204</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Acts, ,, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Acts,.</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4562</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Ibid, ., ,, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Ibid.,.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4588</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Matthew, ,, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Matthew,.</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          title  author  ...     sentence_str sentence_length\n",
              "2648  Leviathan  Hobbes  ...  Hard questions.              15\n",
              "4329  Leviathan  Hobbes  ...         Exodus,.               8\n",
              "4204  Leviathan  Hobbes  ...           Acts,.               6\n",
              "4562  Leviathan  Hobbes  ...          Ibid.,.               7\n",
              "4588  Leviathan  Hobbes  ...        Matthew,.               9\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RW0AZpVyF1Qk",
        "outputId": "657508bb-38c3-4255-bdca-985ab4a94db6"
      },
      "source": [
        "df = df.drop(df[df['sentence_length'] < 20].index)\n",
        "len(df)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX9UfoDtF3Lz"
      },
      "source": [
        "#### Remove Cases of Self-Mention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66
        },
        "id": "LJnDfK9IF8hU",
        "outputId": "cbe54ab3-379e-486f-f2a6-90b794dfb153"
      },
      "source": [
        "# change the author name in this cell \n",
        "\n",
        "self_mentions = df[df['sentence_str'].str.contains('\\s'+'Kierkegaard'.lower())]\n",
        "print(len(self_mentions))\n",
        "self_mentions"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, author, school, sentence_spacy, original_publication_date, corpus_edition_date, sentence_str, sentence_length]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt86zZ3RF8q8",
        "outputId": "92ff3715-2aa3-4b4d-c390-a01b7848fb0b"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].str.contains('\\s'+'Augustine'.lower())].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vglbGXSFF8y4"
      },
      "source": [
        "#### Deal with Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRXjQSIQHpa-",
        "outputId": "3bfae6f3-42a2-4704-c5b0-af790190719b"
      },
      "source": [
        "# find the total number of duplicates\n",
        "len(df['sentence_str'])-len(df['sentence_str'].drop_duplicates())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "sHn4mTy2TR3P",
        "outputId": "bf4cc59b-1e58-40e9-b3cd-a4d4429dc4f7"
      },
      "source": [
        "doubles_df = pd.concat(g for _, g in df.groupby(\"sentence_str\") if len(g) > 1)\n",
        "doubles_df"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-c58ecf086ec5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdoubles_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentence_str\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdoubles_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No objects to concatenate\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti-7vXDjTh0s"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].duplicated(keep='first')].index)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eFT73wJCThrT",
        "outputId": "6ac0f8a4-b26e-439c-cbd3-c58dd3c1dfa8"
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HnVnn1WHrTW"
      },
      "source": [
        "#### Check for Foreign Languages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVcwhudjH5jY",
        "outputId": "81971f73-b34c-487b-e0c8-d9c9101e785d"
      },
      "source": [
        "# checking for 'der', a common article in German\n",
        "len((df[df['sentence_str'].str.contains('\\sder\\s')]))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBzPHm8PH4XB",
        "outputId": "2c946bbc-060a-4b99-b3e4-fafa49726e7b"
      },
      "source": [
        "# checking for 'il', a common article in French\n",
        "len(df[df['sentence_str'].str.contains('\\sil\\s')])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxWbjI0IiAzE"
      },
      "source": [
        "#### Some Ad Hoc Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8YsiZc_h-iu",
        "outputId": "17c3b154-d743-4135-c393-6c79bf7f0a60"
      },
      "source": [
        "# miscellaneous nonsense sentences\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\spp\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\stotam\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\srree\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sflir\\s')].index)\n",
        "df = df.drop(df[(df['sentence_str'].str.contains('\\smodis\\s')) & (df['author'] != 'Kant')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwQzpQ2_iJEU",
        "outputId": "71614281-fc60-4e1b-ae2b-f04c9ed4285b"
      },
      "source": [
        "# markers of french and notes\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\schapitre')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\salisme')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sHahn')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcQoVnariNWg",
        "outputId": "120d63a8-d8c8-42e7-e352-bae294be81f6"
      },
      "source": [
        "# some notes in Kant\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sVorl\\s')].index)\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sberschwenglich')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GI3dJy_dibCA",
        "outputId": "4844119b-40b6-417f-f4af-5a9675bb7220"
      },
      "source": [
        "# a common phrase in Plato / Aristotle footnotes\n",
        "df = df.drop(df[(df['author']=='Plato') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "df = df.drop(df[(df['author']=='Aristotle') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUt3mAjtigKB",
        "outputId": "35d6d7ea-4a63-46a8-c6f7-79b46722defc"
      },
      "source": [
        "# mentions of Aristotle in Plato\n",
        "df = df.drop(df[(df['author']=='Plato') & df['sentence_str'].str.contains('Aristotle')].index)\n",
        "\n",
        "len(df)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5511"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Sd2rbDJHraR"
      },
      "source": [
        "### Lemmatize and Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziLKswX_Hrhd"
      },
      "source": [
        "from gensim.utils import simple_preprocess\n",
        "\n",
        "# use gensim to tokenize sentences\n",
        "df['tokenized_txt'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
        "                                                        max_len=200))\n",
        "\n",
        "# use spacey to get intelligent lemmatization\n",
        "def lemmatize_sentence(sentence):\n",
        "  lemmatized_txt = ''\n",
        "  for word in sentence:\n",
        "    lemmatized_txt += ' ' + str(word.lemma_)\n",
        "  return lemmatized_txt"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Sg_V1rxIdzJ"
      },
      "source": [
        "df['lemmatized_str'] = df['sentence_spacy'].apply(lemmatize_sentence)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0pyznlhXId8n",
        "outputId": "1631022a-8eef-44d2-f812-04ba8ba445fb"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5258</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(And, after, Noah, came, out, of, the, ark, ,, God, saith, ,, He, will, no, more, smite, omnem, animam, viventem, ,, that, is, ,, every, living, creature, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>And after Noah came out of the ark, God saith, He will no more smite omnem animam viventem, that is, every living creature.</td>\n",
              "      <td>123</td>\n",
              "      <td>[and, after, noah, came, out, of, the, ark, god, saith, he, will, no, more, smite, omnem, animam, viventem, that, is, every, living, creature]</td>\n",
              "      <td>and after Noah come out of the ark , God saith , -PRON- will no more smite omnem animam viventem , that is , every live creature .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4739</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(But, this, also, maketh, only, for, the, legislative, power, of, civil, sovereigns, :, for, the, Scribes, and, Pharisees, sat, in, Moses, ', chair, ,, but, Moses, next, under, God, was, sovereign...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>But this also maketh only for the legislative power of civil sovereigns: for the Scribes and Pharisees sat in Moses' chair, but Moses next under God was sovereign of the people of Israel: and ther...</td>\n",
              "      <td>352</td>\n",
              "      <td>[but, this, also, maketh, only, for, the, legislative, power, of, civil, sovereigns, for, the, scribes, and, pharisees, sat, in, moses, chair, but, moses, next, under, god, was, sovereign, of, the...</td>\n",
              "      <td>but this also maketh only for the legislative power of civil sovereign : for the Scribes and Pharisees sit in Moses ' chair , but Moses next under God be sovereign of the people of Israel : and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2440</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(the, representative, will, :, for, in, denying, subjection, ,, he, denies, such, punishment, as, by, the, law, hath, been, ordained, ,, and, therefore, suffers, as, an, enemy, of, the, Commonweal...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>the representative will: for in denying subjection, he denies such punishment as by the law hath been ordained, and therefore suffers as an enemy of the Commonwealth;</td>\n",
              "      <td>166</td>\n",
              "      <td>[the, representative, will, for, in, denying, subjection, he, denies, such, punishment, as, by, the, law, hath, been, ordained, and, therefore, suffers, as, an, enemy, of, the, commonwealth]</td>\n",
              "      <td>the representative will : for in deny subjection , -PRON- deny such punishment as by the law hath be ordain , and therefore suffer as an enemy of the Commonwealth ;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2603</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(Wherein, they, argue, as, ill, ,, as, if, the, savage, people, of, America, should, deny, there, were, any, grounds, or, principles, of, reason, so, to, build, a, house, as, to, last, as, long, a...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>Wherein they argue as ill, as if the savage people of America should deny there were any grounds or principles of reason so to build a house as to last as long as the materials, because they never...</td>\n",
              "      <td>223</td>\n",
              "      <td>[wherein, they, argue, as, ill, as, if, the, savage, people, of, america, should, deny, there, were, any, grounds, or, principles, of, reason, so, to, build, house, as, to, last, as, long, as, the...</td>\n",
              "      <td>wherein -PRON- argue as ill , as if the savage people of America should deny there be any ground or principle of reason so to build a house as to last as long as the material , because -PRON- nev...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2405</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(And, to, rob, a, poor, man, is, a, greater, crime, than, to, rob, a, rich, man, ,, because, it, is, to, the, poor, a, more, sensible, damage, .)</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>And to rob a poor man is a greater crime than to rob a rich man, because it is to the poor a more sensible damage.</td>\n",
              "      <td>114</td>\n",
              "      <td>[and, to, rob, poor, man, is, greater, crime, than, to, rob, rich, man, because, it, is, to, the, poor, more, sensible, damage]</td>\n",
              "      <td>and to rob a poor man be a great crime than to rob a rich man , because -PRON- be to the poor a more sensible damage .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          title  ...                                                                                                                                                                                           lemmatized_str\n",
              "5258  Leviathan  ...                                                                       and after Noah come out of the ark , God saith , -PRON- will no more smite omnem animam viventem , that is , every live creature .\n",
              "4739  Leviathan  ...   but this also maketh only for the legislative power of civil sovereign : for the Scribes and Pharisees sit in Moses ' chair , but Moses next under God be sovereign of the people of Israel : and t...\n",
              "2440  Leviathan  ...                                     the representative will : for in deny subjection , -PRON- deny such punishment as by the law hath be ordain , and therefore suffer as an enemy of the Commonwealth ;\n",
              "2603  Leviathan  ...   wherein -PRON- argue as ill , as if the savage people of America should deny there be any ground or principle of reason so to build a house as to last as long as the material , because -PRON- nev...\n",
              "2405  Leviathan  ...                                                                                   and to rob a poor man be a great crime than to rob a rich man , because -PRON- be to the poor a more sensible damage .\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJOxPwDpIeDT"
      },
      "source": [
        "### Combine with the Old Dataframe & Export to CSV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UU8QqgIXInkp",
        "outputId": "0397b7b2-310f-428f-e795-22a590718106"
      },
      "source": [
        "# load the old version and check it out\n",
        "og_df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/philosophy_data.csv')\n",
        "og_df.sample(5)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>227172</th>\n",
              "      <td>The Crisis Of The European Sciences And Phenomenology</td>\n",
              "      <td>Husserl</td>\n",
              "      <td>phenomenology</td>\n",
              "      <td>So it is understandable how, as a consequence of the awakened striving for philosophical knowledge, knowledge which determines the true, the objective being of the world, the empirical art of meas...</td>\n",
              "      <td>So it is understandable how, as a consequence of the awakened striving for philosophical knowledge, knowledge which determines the true, the objective being of the world, the empirical art of meas...</td>\n",
              "      <td>1936</td>\n",
              "      <td>1970</td>\n",
              "      <td>398</td>\n",
              "      <td>so it is understandable how, as a consequence of the awakened striving for philosophical knowledge, knowledge which determines the true, the objective being of the world, the empirical art of meas...</td>\n",
              "      <td>['so', 'it', 'is', 'understandable', 'how', 'as', 'consequence', 'of', 'the', 'awakened', 'striving', 'for', 'philosophical', 'knowledge', 'knowledge', 'which', 'determines', 'the', 'true', 'the',...</td>\n",
              "      <td>so -PRON- be understandable how , as a consequence of the awaken strive for philosophical knowledge , knowledge which determine the true , the objective being of the world , the empirical art of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52543</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>A rainbow is the reflection of a segment of the sun or of the moon, seen, as in a mirror, in a cloud which is moist, hollow, and continuous in appearance, and taking a circular form.</td>\n",
              "      <td>A rainbow is the reflection of a segment of the sun or of the moon, seen, as in a mirror, in a cloud which is moist, hollow, and continuous in appearance, and taking a circular form.</td>\n",
              "      <td>-320</td>\n",
              "      <td>1991</td>\n",
              "      <td>182</td>\n",
              "      <td>a rainbow is the reflection of a segment of the sun or of the moon, seen, as in a mirror, in a cloud which is moist, hollow, and continuous in appearance, and taking a circular form.</td>\n",
              "      <td>['rainbow', 'is', 'the', 'reflection', 'of', 'segment', 'of', 'the', 'sun', 'or', 'of', 'the', 'moon', 'seen', 'as', 'in', 'mirror', 'in', 'cloud', 'which', 'is', 'moist', 'hollow', 'and', 'contin...</td>\n",
              "      <td>a rainbow be the reflection of a segment of the sun or of the moon , see , as in a mirror , in a cloud which be moist , hollow , and continuous in appearance , and take a circular form .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165649</th>\n",
              "      <td>Quintessence</td>\n",
              "      <td>Quine</td>\n",
              "      <td>analytic</td>\n",
              "      <td>So our renunciation must extend to all de re belief, and similarly, doubt, for the other propositional attitudes.</td>\n",
              "      <td>So our renunciation must extend to all de re belief, and similarly, doubt, for the other propositional attitudes.</td>\n",
              "      <td>1950</td>\n",
              "      <td>2004</td>\n",
              "      <td>113</td>\n",
              "      <td>so our renunciation must extend to all de re belief, and similarly, doubt, for the other propositional attitudes.</td>\n",
              "      <td>['so', 'our', 'renunciation', 'must', 'extend', 'to', 'all', 'de', 're', 'belief', 'and', 'similarly', 'doubt', 'for', 'the', 'other', 'propositional', 'attitudes']</td>\n",
              "      <td>so -PRON- renunciation must extend to all de re belief , and similarly , doubt , for the other propositional attitude .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190464</th>\n",
              "      <td>History Of Madness</td>\n",
              "      <td>Foucault</td>\n",
              "      <td>continental</td>\n",
              "      <td>Only it did not offer itself then as madness but rather as a recognisable type, as the madman. '</td>\n",
              "      <td>Only it did not offer itself then as madness but rather as a recognisable type, as the madman. '</td>\n",
              "      <td>1961</td>\n",
              "      <td>2006</td>\n",
              "      <td>96</td>\n",
              "      <td>only it did not offer itself then as madness but rather as a recognisable type, as the madman. '</td>\n",
              "      <td>['only', 'it', 'did', 'not', 'offer', 'itself', 'then', 'as', 'madness', 'but', 'rather', 'as', 'recognisable', 'type', 'as', 'the', 'madman']</td>\n",
              "      <td>only -PRON- do not offer -PRON- then as madness but rather as a recognisable type , as the madman . '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219646</th>\n",
              "      <td>The Phenomenology Of Perception</td>\n",
              "      <td>Merleau-Ponty</td>\n",
              "      <td>phenomenology</td>\n",
              "      <td>A being capable of sense experience (sentir) in the sense of coinciding absolutely with an impression or a quality could have no other mode of knowing.</td>\n",
              "      <td>A being capable of sense experience (sentir) in the sense of coinciding absolutely with an impression or a quality could have no other mode of knowing.</td>\n",
              "      <td>1945</td>\n",
              "      <td>2002</td>\n",
              "      <td>151</td>\n",
              "      <td>a being capable of sense experience (sentir) in the sense of coinciding absolutely with an impression or a quality could have no other mode of knowing.</td>\n",
              "      <td>['being', 'capable', 'of', 'sense', 'experience', 'sentir', 'in', 'the', 'sense', 'of', 'coinciding', 'absolutely', 'with', 'an', 'impression', 'or', 'quality', 'could', 'have', 'no', 'other', 'mo...</td>\n",
              "      <td>a be capable of sense experience ( sentir ) in the sense of coincide absolutely with an impression or a quality could have no other mode of know .</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                        title  ...                                                                                                                                                                                           lemmatized_str\n",
              "227172  The Crisis Of The European Sciences And Phenomenology  ...   so -PRON- be understandable how , as a consequence of the awaken strive for philosophical knowledge , knowledge which determine the true , the objective being of the world , the empirical art of ...\n",
              "52543                              Aristotle - Complete Works  ...               a rainbow be the reflection of a segment of the sun or of the moon , see , as in a mirror , in a cloud which be moist , hollow , and continuous in appearance , and take a circular form .\n",
              "165649                                           Quintessence  ...                                                                                  so -PRON- renunciation must extend to all de re belief , and similarly , doubt , for the other propositional attitude .\n",
              "190464                                     History Of Madness  ...                                                                                                    only -PRON- do not offer -PRON- then as madness but rather as a recognisable type , as the madman . '\n",
              "219646                        The Phenomenology Of Perception  ...                                                       a be capable of sense experience ( sentir ) in the sense of coincide absolutely with an impression or a quality could have no other mode of know .\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfwEX5vzInx0",
        "outputId": "d962131e-7fac-472f-d793-e11443c24193"
      },
      "source": [
        "og_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Aristotle          0.131354\n",
              "Plato              0.103314\n",
              "Hegel              0.061128\n",
              "Anselm             0.043293\n",
              "Foucault           0.041039\n",
              "Heidegger          0.041036\n",
              "Kant               0.038034\n",
              "Marx               0.036324\n",
              "Lewis              0.035330\n",
              "Malebranche        0.034999\n",
              "Deleuze            0.033768\n",
              "Kripke             0.033604\n",
              "Smith              0.031487\n",
              "Wittgenstein       0.024327\n",
              "Locke              0.023926\n",
              "Hume               0.022383\n",
              "Merleau-Ponty      0.020444\n",
              "Quine              0.019854\n",
              "Nietzsche          0.018349\n",
              "Derrida            0.016154\n",
              "Davis              0.015931\n",
              "Husserl            0.015462\n",
              "Fichte             0.014294\n",
              "Russell            0.013661\n",
              "Leibniz            0.013537\n",
              "Seneca             0.013515\n",
              "Popper             0.012597\n",
              "Lenin              0.012034\n",
              "Spinoza            0.010214\n",
              "Moore              0.009877\n",
              "Keynes             0.009185\n",
              "Ricardo            0.008321\n",
              "Beauvoir           0.008246\n",
              "Berkeley           0.007362\n",
              "Augustine          0.006891\n",
              "Marcus Aurelius    0.005957\n",
              "Kierkegaard        0.004750\n",
              "Wollstonecraft     0.004099\n",
              "Descartes          0.003048\n",
              "Epictetus          0.000870\n",
              "Name: author, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1wqPSYwsrBN",
        "outputId": "d7411524-3780-43ad-e83c-1eba942c8791"
      },
      "source": [
        "len(og_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "369590"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQcxBh37IoDJ",
        "outputId": "bd8416c3-f83c-46bb-d817-819b03de7ee6"
      },
      "source": [
        "# append the new data\n",
        "new_df = og_df.append(df)\n",
        "new_df['author'].value_counts(normalize=True)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Aristotle          0.129434\n",
              "Plato              0.101803\n",
              "Hegel              0.060234\n",
              "Anselm             0.042660\n",
              "Foucault           0.040439\n",
              "Heidegger          0.040436\n",
              "Kant               0.037478\n",
              "Marx               0.035793\n",
              "Lewis              0.034814\n",
              "Malebranche        0.034487\n",
              "Deleuze            0.033275\n",
              "Kripke             0.033113\n",
              "Smith              0.031027\n",
              "Wittgenstein       0.023971\n",
              "Locke              0.023576\n",
              "Hume               0.022056\n",
              "Merleau-Ponty      0.020145\n",
              "Quine              0.019564\n",
              "Nietzsche          0.018081\n",
              "Derrida            0.015918\n",
              "Davis              0.015698\n",
              "Husserl            0.015236\n",
              "Hobbes             0.014623\n",
              "Fichte             0.014085\n",
              "Russell            0.013461\n",
              "Leibniz            0.013339\n",
              "Seneca             0.013318\n",
              "Popper             0.012413\n",
              "Lenin              0.011858\n",
              "Spinoza            0.010065\n",
              "Moore              0.009733\n",
              "Keynes             0.009051\n",
              "Ricardo            0.008199\n",
              "Beauvoir           0.008125\n",
              "Berkeley           0.007255\n",
              "Augustine          0.006790\n",
              "Marcus Aurelius    0.005869\n",
              "Kierkegaard        0.004681\n",
              "Wollstonecraft     0.004039\n",
              "Descartes          0.003004\n",
              "Epictetus          0.000857\n",
              "Name: author, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bwgCHszFf6_p",
        "outputId": "79cfc178-4210-47eb-ff54-3a8ada28eb50"
      },
      "source": [
        "new_df[new_df['author']=='Hobbes'].sample(5)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1153</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(For, the, question, is, not, of, promises, mutual, ,, where, there, is, no, security, of, performance, on, either, side, ,, as, when, there, is, no, civil, power, erected, over, the, parties, pro...</td>\n",
              "      <td>For the question is not of promises mutual, where there is no security of performance on either side, as when there is no civil power erected over the parties promising; for such promises are no c...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>425</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[for, the, question, is, not, of, promises, mutual, where, there, is, no, security, of, performance, on, either, side, as, when, there, is, no, civil, power, erected, over, the, parties, promising...</td>\n",
              "      <td>for the question be not of promise mutual , where there be no security of performance on either side , as when there be no civil power erect over the party promise ; for such promise be no covena...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2884</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(The, prophet, that, was, sent, to, prophesy, against, the, altar, set, up, by, Jeroboam, ,, though, a, true, prophet, ,, and, that, by, two, miracles, done, in, his, presence, appears, to, be, a,...</td>\n",
              "      <td>The prophet that was sent to prophesy against the altar set up by Jeroboam, though a true prophet, and that by two miracles done in his presence appears to be a prophet sent from God, was yet dece...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>296</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[the, prophet, that, was, sent, to, prophesy, against, the, altar, set, up, by, jeroboam, though, true, prophet, and, that, by, two, miracles, done, in, his, presence, appears, to, be, prophet, se...</td>\n",
              "      <td>the prophet that be send to prophesy against the altar set up by Jeroboam , though a true prophet , and that by two miracle do in -PRON- presence appear to be a prophet send from God , be yet dec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1328</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(For, the, laws, of, nature, ,, as, justice, ,, equity, ,, modesty, ,, mercy, ,, and, ,, in, sum, ,, doing, to, others, as, we, would, be, done, to, ,, of, themselves, ,, without, the, terror, of,...</td>\n",
              "      <td>For the laws of nature, as justice, equity, modesty, mercy, and, in sum, doing to others as we would be done to, of themselves, without the terror of some power to cause them to be observed, are c...</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>287</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[for, the, laws, of, nature, as, justice, equity, modesty, mercy, and, in, sum, doing, to, others, as, we, would, be, done, to, of, themselves, without, the, terror, of, some, power, to, cause, th...</td>\n",
              "      <td>for the law of nature , as justice , equity , modesty , mercy , and , in sum , do to other as -PRON- would be do to , of -PRON- , without the terror of some power to cause -PRON- to be observe , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2678</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(But, what, is, a, good, law, ?)</td>\n",
              "      <td>But what is a good law?</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>23</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[but, what, is, good, law]</td>\n",
              "      <td>but what be a good law ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>954</th>\n",
              "      <td>Leviathan</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>Hobbes</td>\n",
              "      <td>(That, the, clergy, ,, and, regulars, ,, in, what, country, soever, ,, shall, be, exempt, from, the, jurisdiction, of, their, king, in, cases, criminal, ?)</td>\n",
              "      <td>That the clergy, and regulars, in what country soever, shall be exempt from the jurisdiction of their king in cases criminal?</td>\n",
              "      <td>1651</td>\n",
              "      <td>1651</td>\n",
              "      <td>125</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[that, the, clergy, and, regulars, in, what, country, soever, shall, be, exempt, from, the, jurisdiction, of, their, king, in, cases, criminal]</td>\n",
              "      <td>that the clergy , and regular , in what country soever , shall be exempt from the jurisdiction of -PRON- king in case criminal ?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          title  ...                                                                                                                                                                                           lemmatized_str\n",
              "1153  Leviathan  ...   for the question be not of promise mutual , where there be no security of performance on either side , as when there be no civil power erect over the party promise ; for such promise be no covena...\n",
              "2884  Leviathan  ...   the prophet that be send to prophesy against the altar set up by Jeroboam , though a true prophet , and that by two miracle do in -PRON- presence appear to be a prophet send from God , be yet dec...\n",
              "1328  Leviathan  ...   for the law of nature , as justice , equity , modesty , mercy , and , in sum , do to other as -PRON- would be do to , of -PRON- , without the terror of some power to cause -PRON- to be observe , ...\n",
              "2678  Leviathan  ...                                                                                                                                                                                 but what be a good law ?\n",
              "954   Leviathan  ...                                                                         that the clergy , and regular , in what country soever , shall be exempt from the jurisdiction of -PRON- king in case criminal ?\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ncmXLdXuIoMl",
        "outputId": "44e9f39f-f247-460e-e675-3191dac7d8be"
      },
      "source": [
        "# export as csv\n",
        "from google.colab import files\n",
        "new_df.to_csv('phil_nlp.csv', index=False) \n",
        "files.download('phil_nlp.csv')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_886f6ac8-7f79-4c7c-9100-e63b238ad3f7\", \"phil_nlp.csv\", 339286760)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vz0aj3NrECm3"
      },
      "source": [
        "###Upload Data to the SQL Server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "bW76POWkJL-b",
        "outputId": "a6e3019e-5efd-4084-849b-09d426589a4b"
      },
      "source": [
        "# prepare to upload to the PostgreSQL database\n",
        "\n",
        "# note which dataframe you set this to - new_df for the whole dataset, df for \n",
        "# just the new text\n",
        "\n",
        "for_db = new_df\n",
        "for_db['date'] = for_db['original_publication_date']\n",
        "for_db['date'] = for_db['date'].apply(lambda x: str(x)[1:]+' BC' if x < 0 else str(x))\n",
        "for_db['sentence'] = for_db['sentence_str']\n",
        "for_db['school'] = for_db['school'].apply(lambda x: x.replace('_', ' ').title())\n",
        "for_db = for_db.drop(['sentence_spacy', \n",
        "                      'sentence_length',\n",
        "                      'sentence_lowered', \n",
        "                      'sentence_str', \n",
        "                      'tokenized_txt', \n",
        "                      'lemmatized_str',\n",
        "                      'corpus_edition_date',\n",
        "                      'original_publication_date'], axis=1)\n",
        "for_db.columns = [i.upper() for i in for_db.columns]\n",
        "\n",
        "for_db.sample(5)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>AUTHOR</th>\n",
              "      <th>SCHOOL</th>\n",
              "      <th>DATE</th>\n",
              "      <th>SENTENCE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>127519</th>\n",
              "      <td>The Search After Truth</td>\n",
              "      <td>Malebranche</td>\n",
              "      <td>Rationalism</td>\n",
              "      <td>1674</td>\n",
              "      <td>But we must not adorn a phantom without body or reality; we must not excite useless impulses.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76581</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>320 BC</td>\n",
              "      <td>Now parents know their offspring better than their children</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322153</th>\n",
              "      <td>On The Principles Of Political Economy And Taxation</td>\n",
              "      <td>Ricardo</td>\n",
              "      <td>Capitalism</td>\n",
              "      <td>1817</td>\n",
              "      <td>Let the two nations, between which the commercial treaty is made, be the mother country and her colony, and Adam Smith, it is evident, admits, that a mother country may be benefited by oppressing ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287639</th>\n",
              "      <td>Elements Of The Philosophy Of Right</td>\n",
              "      <td>Hegel</td>\n",
              "      <td>German Idealism</td>\n",
              "      <td>1820</td>\n",
              "      <td>The sun, moon, mountains, rivers, and all natural objects</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29615</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>Plato</td>\n",
              "      <td>350 BC</td>\n",
              "      <td>And, as for the land rings that separated the rings of sea, they pierced them at the point of the bridges, and thus joined them by water.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      TITLE  ...                                                                                                                                                                                                 SENTENCE\n",
              "127519                               The Search After Truth  ...                                                                                                            But we must not adorn a phantom without body or reality; we must not excite useless impulses.\n",
              "76581                            Aristotle - Complete Works  ...                                                                                                                                              Now parents know their offspring better than their children\n",
              "322153  On The Principles Of Political Economy And Taxation  ...  Let the two nations, between which the commercial treaty is made, be the mother country and her colony, and Adam Smith, it is evident, admits, that a mother country may be benefited by oppressing ...\n",
              "287639                  Elements Of The Philosophy Of Right  ...                                                                                                                                                The sun, moon, mountains, rivers, and all natural objects\n",
              "29615                                Plato - Complete Works  ...                                                                And, as for the land rings that separated the rings of sea, they pierced them at the point of the bridges, and thus joined them by water.\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWSVKbmoVaAW",
        "outputId": "c4ccf120-0b85-40c8-9acd-169dca69d41e"
      },
      "source": [
        "len(for_db)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "376865"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mni3N-fyK-jZ",
        "outputId": "01578592-065f-4d02-f69d-68734bc300d7"
      },
      "source": [
        "#importing sql library \n",
        "from sqlalchemy import create_engine \n",
        "  \n",
        "# create a reference  \n",
        "# for sql library \n",
        "engine = create_engine('postgresql://nrolc7ed7joo',\n",
        "                       echo=False)\n",
        "  \n",
        "# attach the data frame to the sql server \n",
        "for_db.to_sql('phil_nlp',          \n",
        "              con = engine,\n",
        "              if_exists='replace',\n",
        "              index=False,\n",
        "              method='multi') \n",
        "  \n",
        "# show the completed data as a test\n",
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp WHERE \"AUTHOR\" = 'Hobbes'\"\"\").fetchone()) "
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
            "  \"\"\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "('Leviathan', 'Hobbes', 'Hobbes', '1651', 'All which qualities called sensible are in the object that causeth them')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NxRYDdaLGW2"
      },
      "source": [
        "Remember to add to the clipping and other elements to the notebook that creates the database as a whole. Then you're done!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK50YeA-LNtD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25aebe0f-a340-48a6-c187-39a996ff88c9"
      },
      "source": [
        "print(engine.execute(\"\"\"SELECT * FROM phil_nlp where \"AUTHOR\" = 'Hobbes'\"\"\").fetchone()) "
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Leviathan', 'Hobbes', 'Hobbes', '1651', 'All which qualities called sensible are in the object that causeth them')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfaWbJkCid6W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}