{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data_load_clean_and_export.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyODy2xhjLn27+ZXxsiXlfRx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/PDP_data_processing/blob/master/data_load_clean_and_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce4uUmGtIwgG"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQnwn5oZqw4P",
        "outputId": "6033b02f-d55f-43e0-f78a-938a3a375298"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\r\n",
        "# and relevant libraries via the functions.py file\r\n",
        "from google.colab import drive\r\n",
        "import sys\r\n",
        "\r\n",
        "drive.mount('/gdrive',force_remount=True)\r\n",
        "\r\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/philosophy_data_project'\r\n",
        "\r\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icdKF0dyrAU5"
      },
      "source": [
        "from import_functions import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tym6E0D5rbwQ",
        "outputId": "b6630c87-f51f-46c3-9fd1-0ec3f08e50c0"
      },
      "source": [
        "import spacy.cli\r\n",
        "spacy.cli.download(\"en_core_web_lg\")\r\n",
        "import en_core_web_lg\r\n",
        "nlp = en_core_web_lg.load()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xksjWnqQIyNV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTfCjw3Rrt2I"
      },
      "source": [
        "# load the texts\r\n",
        "\r\n",
        "## plato\r\n",
        "plato_complete = get_text(drive_path + '/phil_txts/plato_complete_works.txt')\r\n",
        "\r\n",
        "# aristotle\r\n",
        "aristotle_vol_1 = get_text(drive_path + '/phil_txts/aristotle_complete_works_v1.txt')\r\n",
        "aristotle_vol_2 = get_text(drive_path + '/phil_txts/aristotle_complete_works_v2.txt')\r\n",
        "\r\n",
        "## rationalists\r\n",
        "spinoza_ethics = get_guten('http://www.gutenberg.org/cache/epub/3800/pg3800.txt')\r\n",
        "spinoza_improve_understanding = get_guten('http://www.gutenberg.org/cache/epub/1016/pg1016.txt')\r\n",
        "leibniz_theodicy = get_guten('http://www.gutenberg.org/cache/epub/17147/pg17147.txt')\r\n",
        "descartes_discourse_method = get_guten('http://www.gutenberg.org/cache/epub/59/pg59.txt')\r\n",
        "descartes_meditations = get_text(drive_path + '/phil_txts/descartes_meditations.txt')\r\n",
        "malebranche_search_truth = get_text(drive_path + '/phil_txts/malebranche_search_truth.txt')\r\n",
        "\r\n",
        "## empiricists\r\n",
        "locke_understanding_1 = get_guten('http://www.gutenberg.org/cache/epub/10615/pg10615.txt')\r\n",
        "locke_understanding_2 = get_guten('http://www.gutenberg.org/cache/epub/10616/pg10616.txt')\r\n",
        "locke_treatise_gov = get_guten('http://www.gutenberg.org/cache/epub/7370/pg7370.txt')\r\n",
        "hume_treatise = get_guten('http://www.gutenberg.org/cache/epub/4705/pg4705.txt')\r\n",
        "hume_natural_religion = get_guten('http://www.gutenberg.org/cache/epub/4583/pg4583.txt')\r\n",
        "berkeley_treatise = get_guten('http://www.gutenberg.org/cache/epub/4723/pg4723.txt')\r\n",
        "berkeley_three_dialogues = get_guten('http://www.gutenberg.org/cache/epub/4724/pg4724.txt')\r\n",
        "\r\n",
        "## german idealism\r\n",
        "kant_practical_reason = get_text(drive_path + '/phil_txts/kant_critique_practical_reason.txt')\r\n",
        "kant_judgement = get_text(drive_path + '/phil_txts/kant_critique_judgement.txt')\r\n",
        "kant_pure_reason = get_text(drive_path + '/phil_txts/kant_pure_reason.txt')\r\n",
        "fichte_ethics = get_text(drive_path + '/phil_txts/fichte_system_of_ethics.txt')\r\n",
        "hegel_logic = get_text(drive_path + '/phil_txts/hegel_science_of_logic.txt')\r\n",
        "hegel_phenomenology = get_text(drive_path + '/phil_txts/hegel_phenomenology_of_spirit.txt')\r\n",
        "hegel_right = get_text(drive_path + '/phil_txts/hegel_elements_of_right.txt')\r\n",
        "\r\n",
        "## analytic\r\n",
        "russell_problems_of_phil = get_guten('http://www.gutenberg.org/cache/epub/5827/pg5827.txt')\r\n",
        "russell_analylsis_of_mind = get_guten('http://www.gutenberg.org/cache/epub/2529/pg2529.txt')\r\n",
        "moore_studies = get_guten('http://www.gutenberg.org/files/50141/50141-0.txt')\r\n",
        "wittgenstein_tractatus = get_text(drive_path + '/phil_txts/wittgenstein_tractatus.txt')\r\n",
        "wittgenstein_investigations = get_text(drive_path + '/phil_txts/wittgenstien_philosophical_investigations.txt')\r\n",
        "lewis_papers1 = get_text(drive_path + '/phil_txts/lewis_papers_1.txt')\r\n",
        "lewis_papers2 = get_text(drive_path + '/phil_txts/lewis_papers_2.txt')\r\n",
        "quine_quintessence = get_text(drive_path + '/phil_txts/quine_quintessence.txt')\r\n",
        "popper_science = get_text(drive_path + '/phil_txts/popper_logic_of_science.txt')\r\n",
        "kripke_troubles = get_text(drive_path + '/phil_txts/kripke_philosophical_troubles.txt')\r\n",
        "kripke_naming = get_text(drive_path + '/phil_txts/kripke_naming_necessity.txt')\r\n",
        "\r\n",
        "## phenomenology\r\n",
        "ponty_perception = get_text(drive_path + '/phil_txts/merleau-ponty_phenomenology_of_perception.txt')\r\n",
        "husserl_idea_of = get_text(drive_path + '/phil_txts/husserl_idea_of_phenomenology.txt')\r\n",
        "husserl_crisis = get_text(drive_path + '/phil_txts/husserl_crisis_of_euro_sciences.txt')\r\n",
        "heidegger_being_time = get_text(drive_path + '/phil_txts/heidegger_being_and_time.txt')\r\n",
        "heidegger_track = get_text(drive_path + '/phil_txts/heidegger_off_the_beaten_track.txt')\r\n",
        "\r\n",
        "## continental\r\n",
        "foucault_order = get_text(drive_path + '/phil_txts/foucault_order_of_things.txt')\r\n",
        "foucault_madness = get_text(drive_path + '/phil_txts/foucault_history_of_madness.txt')\r\n",
        "foucault_clinic = get_text(drive_path + '/phil_txts/foucault_birth_of_clinic.txt')\r\n",
        "derrida_writing = get_text(drive_path + '/phil_txts/derrida_writing_difference.txt')\r\n",
        "deleuze_oedipus = get_text(drive_path + '/phil_txts/deleuze_guattari_anti-oedipus.txt')\r\n",
        "deleuze_difference = get_text(drive_path + '/phil_txts/deleuze_difference_repetition.txt')\r\n",
        "\r\n",
        "## marxism\r\n",
        "marx_kapital = get_text(drive_path + '/phil_txts/marx_kapital.txt')\r\n",
        "marx_manifesto = get_text(drive_path + '/phil_txts/marx_manifesto.txt')\r\n",
        "lenin_essential = get_text(drive_path + '/phil_txts/lenin_essential_works.txt')\r\n",
        "\r\n",
        "## capitalist economics\r\n",
        "smith_wealth = get_guten('http://www.gutenberg.org/files/3300/3300-0.txt')\r\n",
        "ricardo_political_economy = get_guten('http://www.gutenberg.org/cache/epub/33310/pg33310.txt')\r\n",
        "keynes_employment = get_text(drive_path + '/phil_txts/keynes_theory_of_employment.txt')\r\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtnCGgKbrwVa"
      },
      "source": [
        "# use this cell to bring in the new texts\r\n",
        "\r\n",
        "## stoicism\r\n",
        "epictetus_enchiridion = get_guten('http://www.gutenberg.org/files/45109/45109-0.txt')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gtbq1njQKsSn"
      },
      "source": [
        "With texts imported, we need to clip front and end matter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cvmG0rir1tU"
      },
      "source": [
        "plato_complete = plato_complete.split('find that an enticing')[1][388:].split('Demeter, whose cult at')[0]\r\n",
        "\r\n",
        "aristotle_vol_1 = aristotle_vol_1.split('1a20-1b9')[1].split('799a16')[0]\r\n",
        "aristotle_vol_2 = aristotle_vol_2.split('830a5-830b4')[1].split('1462a5-1462a13')[0]\r\n",
        "\r\n",
        "spinoza_ethics = spinoza_ethics.split('ranslated from the Latin by R.')[1][71:].split('End of the Ethics')[0]\r\n",
        "spinoza_improve_understanding = spinoza_improve_understanding.split('Farewell.*')[1][20:].split('End of ')[0]\r\n",
        "leibniz_theodicy = leibniz_theodicy.split('appeared in 1710 as the')[1][202:].split('SUMMARY OF THE CON')[0][:-140]\r\n",
        "descartes_discourse_method = descartes_discourse_method.split('PREFATORY NOTE')[1][18:].split('End of the Pr')[0]\r\n",
        "descartes_meditations = descartes_meditations.split('LETTER')[1][1:].split('AND REPLIES')[0]\r\n",
        "malebranche_search_truth = malebranche_search_truth.split(\"n's Mind and the Use H\")[1][64:].split('Beati qui')[0]\r\n",
        "\r\n",
        "locke_understanding_1 = locke_understanding_1.split('2 Dorset Court, 24th of May, 1689')[1][50:].split('End of the Pro')[0][:-30]\r\n",
        "locke_understanding_2 = locke_understanding_2.split('1. Man fitted to form articulated Sounds.')[1][4:].split('End of the Pro')[0][:-25]\r\n",
        "locke_treatise_gov = locke_treatise_gov.split('now lodged in Christ College, Cambridge.')[1][21:].split('FINIS.')[0]\r\n",
        "hume_treatise = hume_treatise.split('ADVERTISEMENT')[1][9:].split('End of Pro')[0][:-14]\r\n",
        "hume_natural_religion = hume_natural_religion.split('PAMPHILUS TO HERMIPPUS')[1][6:].split('End of the Pro')[0][:-22]\r\n",
        "berkeley_treatise = berkeley_treatise.split('are too apt to condemn an opinion before they rightly')[1][47:].split('End of the Pr')[0][:-22]\r\n",
        "berkeley_three_dialogues = berkeley_three_dialogues.split('THE FIRST DIALOGUE')[1][17:].split('End of the Pro')[0][:-22]\r\n",
        "\r\n",
        "kant_practical_reason = kant_practical_reason.split('erner Pluhar an')[1][329:].split('stone of the wi')[0][:-20]\r\n",
        "kant_judgement = kant_judgement.split('TO THE FIRST EDITION,* 1790')[1][1:].split('EXPLANATORY NOTES')[0][:-39]\r\n",
        "kant_pure_reason = kant_pure_reason.split('Bacon of Verulam')[1][33:].split('(Persius, Satires, iii, 78-9).')[0][:-1]\r\n",
        "fichte_ethics = fichte_ethics.split('(“Krause Nachschrift,” 1798/99)')[1][111:].split('Page 345')[0][:-2]\r\n",
        "hegel_logic = hegel_logic.split('complete transformati')[1][249:].split('It is a matter of speculation how Hegel would have rev')[0][:-80]\r\n",
        "hegel_phenomenology = hegel_phenomenology.split('PREFACE: ON SCIENTIFIC')[1][1:].split('1I Adaptation')[0][:-62]\r\n",
        "hegel_right = hegel_right.split('he immediate occasion f')[1][184:].split('I Hegel lectured on the topics in')[0][:-28]\r\n",
        "\r\n",
        "russell_problems_of_phil = russell_problems_of_phil.split('n the following pages')[1].split('BIBLIOGRAPHICAL NOTE')[0]\r\n",
        "russell_analylsis_of_mind = russell_analylsis_of_mind.split('H. D. Lewis')[2][21:].split('End of Pro')[0]\r\n",
        "moore_studies = moore_studies.split('Aristotelian Society,_ 1919-20.')[1][23:].split('E Wes')[0][:-10]\r\n",
        "wittgenstein_tractatus = wittgenstein_tractatus.split('TRACTATUS LOGICO-PHILOSOPHICUS')[1][70:].split('I NDEX')[0][:-8]\r\n",
        "wittgenstein_investigations = wittgenstein_investigations.split('catty')[1][787:].split(\"above', 351\")[0]\r\n",
        "lewis_papers1 = lewis_papers1.split('The fifteen papers')[1][61:].split('Acquai')[0][:-10]\r\n",
        "lewis_papers2 = lewis_papers2.split('Part Four Counterfactuals and Time')[1][17:].split('end p.342')[0]\r\n",
        "quine_quintessence = quine_quintessence.split('T R UT H B Y C O N V E N T I O N')[1].split('CREDITS')[0][:-7]\r\n",
        "popper_science = popper_science.split('F IRST E NGLISH E DITION, 1959')[1][2:].split('This is the end of the text of the original book.')[0]\r\n",
        "kripke_troubles = kripke_troubles.split('apters 2, 3, 7, 10, 11, and 13 are previously unpublish')[1][103:].split('ans, Gareth. 198')[0][:-25]\r\n",
        "kripke_naming = kripke_naming.split('xjvdsa')[1][10:].split('hese addenda represe')[0][:-35]\r\n",
        "\r\n",
        "ponty_perception = ponty_perception.split('P REFACE')[1].split('B IBLIOGRAPHY')[0][:-65]\r\n",
        "husserl_idea_of = husserl_idea_of.split('LECTUREl')[1][9:].split('Abstraction, ideating, 47, 50, 65')[0][:-10]\r\n",
        "husserl_crisis = husserl_crisis.split('§ 1.')[1].split('Appendix X:')[0]\r\n",
        "heidegger_being_time = heidegger_being_time.split(\"AUTHOR'S PREFACE TO THE\")[1][25:].split('Not \"the\" sole way.')[0][:-8]\r\n",
        "heidegger_track = heidegger_track.split('translated in several ')[1][15:].split('et-up [dar Gestellj as the uunost obli')[0][:-32]\r\n",
        "\r\n",
        "foucault_order = foucault_order.split('P REFACE')[1]\r\n",
        "foucault_madness = foucault_madness.split('ickering simulacra, an')[1][112:].split('Page 591')[0]\r\n",
        "foucault_clinic = foucault_clinic.split('iagnostic (Paris, 1962, p.')[1][15:].split('de Sade.')[0][:-33]\r\n",
        "derrida_writing = derrida_writing.split('(Flaubert, Preface d la d')[1][10:].split('Reb Derissa')[0]\r\n",
        "deleuze_oedipus = deleuze_oedipus.split('xjdsde')[1].split('jajielaks')[0]\r\n",
        "deleuze_difference = deleuze_difference.split('Introduction:')[1].split('Plateaus')[0][:-65]\r\n",
        "\r\n",
        "marx_kapital = ((marx_kapital.split('E MAGNITUDE OF VALUE)')[1].split('expropriation of the laborer.')[0])+'expropriation of the laborer.')\r\n",
        "marx_manifesto = marx_manifesto.split('page 29')[1].split('Mao')[0][:-15]\r\n",
        "lenin_essential = lenin_essential.split('We will now sum up the theoretical')[1].split('SUGGESTIONS FOR FURTHER READING')[0]\r\n",
        "\r\n",
        "smith_wealth = smith_wealth.split('INTRODUCTION AND PLAN OF THE WORK.')[2].split('End of the Project Gutenberg EBook of An Inquiry into the Nat')[0]\r\n",
        "ricardo_political_economy = ricardo_political_economy.split('ON VALUE.')[1].split('  FOOTNOTES:')[0]\r\n",
        "keynes_employment = keynes_employment.split('GENERAL INTRODUCTION')[1].split('PRINTING ERRORS IN THE FIRST EDITION CORRECTE')[0][:-145]\r\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uDGcFA-r3w7"
      },
      "source": [
        "# use this cell to deal with the new text and experiment until we have a good result\r\n",
        "\r\n",
        "epictetus_enchiridion = epictetus_enchiridion.split('New York, 1927.')[1][99:].split('Footnotes')[0][:-45]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtyqxKStKvsc"
      },
      "source": [
        "Now we aggregate them by school and create a dictionary of various aggregates for future use. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kghr6yp0r6Lv"
      },
      "source": [
        "# a list of books for each school, then aggregated and entered into a dictionary\r\n",
        "\r\n",
        "## original texts\r\n",
        "plato_texts = [plato_complete]\r\n",
        "aristotle_texts = [aristotle_vol_1, aristotle_vol_2]\r\n",
        "rationalist_texts = [spinoza_ethics, spinoza_improve_understanding, \r\n",
        "                    leibniz_theodicy, descartes_discourse_method, \r\n",
        "                     descartes_meditations, malebranche_search_truth]\r\n",
        "empiricist_texts = [locke_treatise_gov, locke_understanding_1, locke_understanding_2, \r\n",
        "                    hume_treatise, hume_natural_religion, berkeley_three_dialogues, \r\n",
        "                    berkeley_treatise]\r\n",
        "german_idealist_texts = [kant_practical_reason, kant_judgement, kant_pure_reason, \r\n",
        "                         fichte_ethics, hegel_logic, hegel_phenomenology, hegel_right]\r\n",
        "analytic_texts = [russell_analylsis_of_mind, russell_problems_of_phil, \r\n",
        "                  moore_studies, wittgenstein_investigations, wittgenstein_tractatus, \r\n",
        "                  lewis_papers1, lewis_papers2, quine_quintessence, popper_science, \r\n",
        "                  kripke_naming, kripke_troubles]\r\n",
        "phenomenology_texts = [ponty_perception, husserl_crisis, \r\n",
        "                       husserl_idea_of, heidegger_being_time, heidegger_track]\r\n",
        "continental_texts = [foucault_clinic, foucault_madness, foucault_order, \r\n",
        "                     derrida_writing, deleuze_difference, deleuze_oedipus]\r\n",
        "marxist_texts = [marx_kapital, marx_manifesto, lenin_essential]\r\n",
        "capitalist_texts = [smith_wealth, ricardo_political_economy, keynes_employment]\r\n",
        "\r\n",
        "# new texts\r\n",
        "stoicism_texts = [epictetus_enchiridion]\r\n",
        "\r\n",
        "\r\n",
        "all_texts = plato_texts + aristotle_texts + empiricist_texts + rationalist_texts + analytic_texts + continental_texts + phenomenology_texts + german_idealist_texts + marxist_texts + capitalist_texts + stoicism_texts\r\n",
        "all_texts_string = ' . '.join(all_texts)\r\n",
        "\r\n",
        "text_dict_list = {'plato': plato_texts, 'aristotle': aristotle_texts, \r\n",
        "             'empiricism': empiricist_texts, 'rationalism': rationalist_texts, \r\n",
        "            'german_idealism': german_idealist_texts, \r\n",
        "             'phenomenology': phenomenology_texts, 'analytic': analytic_texts, \r\n",
        "            'continental': continental_texts, 'marxism': marxist_texts,\r\n",
        "             'capitalism': capitalist_texts, 'stoicism': stoicism_texts}\r\n",
        "\r\n",
        "text_dict = {}\r\n",
        "for school in text_dict_list.keys():\r\n",
        "    text_dict[school] = ' . '.join(text_dict_list[school])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfajGZ7bK5Zg"
      },
      "source": [
        "### More In-Depth Cleaning\r\n",
        "\r\n",
        "The text here is often quite messy. We need to do some significant work to clean it up. This means dealing with things like:\r\n",
        "- headers of pages occurring repeatedly in the text\r\n",
        "- page numbers and citation numbers\r\n",
        "- footnotes, roman numerals, titles of chapters\r\n",
        "\r\n",
        "The process of dealing with these and getting the data ready for our models has a few steps:\r\n",
        "1. develop a general cleaning function that can work for every text (removing roman numerals, for example)\r\n",
        "2. examine each text itself and remove the specific headers that are relevant to it\r\n",
        "  - look for features that could capture all the footnotes here as well\r\n",
        "3. tokenize the text using spacy\r\n",
        "4. examine the tokens for unusual patterns \r\n",
        "  - there should be virtually no duplicate sentences\r\n",
        "  - we can remove sentences that are too short to mean anything\r\n",
        "  - remove sentences that contain terms that must be from footnotes (the author's name should be very rare in the actual text, for example)\r\n",
        "\r\n",
        "Unfortunately many of these steps can only be done ad hoc; there is no real way to know whether and what headers are in a text without examining the files individually. So the process is a bit tedious and time-consuming. Still, when we finish we will have data that is much cleaner and more useful for modeling. \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcoDD6vbLpu9"
      },
      "source": [
        "#### 1. Baseline Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JLtqH5SLInh"
      },
      "source": [
        "Our first step is to develop a baseline cleaning function that can be applied to every text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkT0egnbr89k"
      },
      "source": [
        "def baseline_clean(to_correct, capitals=True, bracketed_fn=False, odd_words_dict={}):\r\n",
        "  # remove utf8 encoding characters and some punctuations\r\n",
        "  result = re.sub(r'[\\x00-\\x08\\x0b\\x0c\\x0e-\\x1f\\x7f-\\xff\\xad\\x0c6§\\\\\\£\\Â*_<>\"\"⎫•{}Γ~]', ' ', to_correct)\r\n",
        "  result = re.sub(r'[\\u2014\\u2013\\u2012-]', ' ', result)\r\n",
        "\r\n",
        "  # replace whitespace characters with actual whitespace\r\n",
        "  result = re.sub(r'\\s', ' ', result)\r\n",
        "\r\n",
        "  # replace odd quotation marks with a standard\r\n",
        "  result = re.sub(r'[‘’“”]', \"'\", result)\r\n",
        "\r\n",
        "  # replace the ﬀ, ﬃ and ﬁ with the appropriate counterparts\r\n",
        "  result = re.sub(r'ﬀ', 'ff', result)\r\n",
        "  result = re.sub(r'ﬁ', 'fi', result)\r\n",
        "  result = re.sub(r'ﬃ', 'ffi', result)\r\n",
        "\r\n",
        "  # remove or standardize some recurring common and meaninless words/phrases\r\n",
        "  result = re.sub(r'\\s*This\\s*page\\s*intentionally\\s*left\\s*blank\\s*', ' ', result)\r\n",
        "  result = re.sub(r'(?i)Aufgabe\\s+', ' ', result)\r\n",
        "  result = re.sub(r',*\\s+cf\\.', ' ', result)\r\n",
        "\r\n",
        "  # some texts have footnotes conveniently in brackets - this removes them all, \r\n",
        "  # with a safety measure for unpaired brackets, and deletes all brackets afterwards\r\n",
        "  if bracketed_fn:\r\n",
        "    result = re.sub(r'\\[.{0,300}\\]|{.{0,300}}|{.{0,300}\\]|\\[.{0,300}}', ' ', result)\r\n",
        "  result = re.sub(r'[\\[\\]{}]', ' ', result)\r\n",
        "\r\n",
        "  # unify some abbreviations\r\n",
        "  result = re.sub(r'&', 'and', result)\r\n",
        "  result = re.sub(r'\\se\\.g\\.\\s', ' eg ', result)\r\n",
        "  result = re.sub(r'\\si\\.e\\.\\s', ' ie ', result)\r\n",
        "  result = re.sub('coroll\\.', 'coroll', result)\r\n",
        "  result = re.sub('pt\\.', 'pt', result)\r\n",
        "\r\n",
        "  # remove roman numerals, first capitalized ones\r\n",
        "  result = re.sub(r'\\s((I{2,}V*X*\\.*)|(IV\\.*)|(IX\\.*)|(V\\.*)|(V+I*\\.*)|(X+L*V*I*]\\.*))\\s', ' ', result)\r\n",
        "  # then lowercase\r\n",
        "  result = re.sub(r'\\s((i{2,}v*x*\\.*)|(iv\\.*)|(ix\\.*)|(v\\.*)|(v+i*\\.*)|(x+l*v*i*\\.*))\\s', ' ', result)\r\n",
        "\r\n",
        "  # remove periods and commas flanked by numbers\r\n",
        "  result = re.sub(r'\\d\\.\\d', ' ', result)\r\n",
        "  result = re.sub(r'\\d,\\d', ' ', result)\r\n",
        "\r\n",
        "  # remove the number-letter-number pattern used for many citations\r\n",
        "  result = re.sub(r'\\d*\\w{,2}\\d', ' ', result)\r\n",
        "\r\n",
        "  # remove numerical characters\r\n",
        "  result = re.sub(r'\\d+', ' ', result)\r\n",
        "\r\n",
        "  # remove words of 2+ characters that are entirely capitalized \r\n",
        "  # (these are almost always titles, headings, or speakers in a dialogue)\r\n",
        "  # remove capital I's that follow capital words - these almost always roman numerals\r\n",
        "  # some texts do use these capitalizations meaningfully, so we make this optional\r\n",
        "  if capitals:\r\n",
        "    result = re.sub(r'[A-Z]{2,}\\s+I', ' ', result)\r\n",
        "    result = re.sub(r'[A-Z]{2,}', ' ', result)\r\n",
        "\r\n",
        "  # remove isolated colons and semicolons that result from removal of titles\r\n",
        "  result = re.sub(r'\\s+:\\s*', ' ', result)\r\n",
        "  result = re.sub(r'\\s+;\\s*', ' ', result)\r\n",
        "\r\n",
        "  # remove isolated letters (do it several times because strings of isolated letters do not get captured properly)\r\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\r\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\r\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\r\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\r\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\r\n",
        "  result = re.sub(r'\\s[^aAI\\.]\\s', ' ', result)\r\n",
        "\r\n",
        "  # remove isolated letters at the end of sentences or before commas\r\n",
        "  result = re.sub(r'\\s[^aI]\\.', '.', result)\r\n",
        "  result = re.sub(r'\\s[^aI],', ',', result)\r\n",
        "\r\n",
        "  # deal with spaces around periods and commas\r\n",
        "  result = re.sub(r'\\s+,\\s+', ', ', result)\r\n",
        "  result = re.sub(r'\\s+\\.\\s+', '. ', result)\r\n",
        "\r\n",
        "  # remove empty parantheses\r\n",
        "  result = re.sub(r'(\\(\\s*\\.*\\s*\\))|(\\(\\s*,*\\s*)\\)', ' ', result)\r\n",
        "\r\n",
        "  # reduce multiple periods, commas, or whitespaces into a single one\r\n",
        "  result = re.sub(r'\\.+', '.', result)\r\n",
        "  result = re.sub(r',+', ',', result)\r\n",
        "  result = re.sub(r'\\s+', ' ', result)\r\n",
        "\r\n",
        "  # deal with isolated problem cases discovered in the data:\r\n",
        "  for key in odd_words_dict.keys():\r\n",
        "    result = re.sub(r''+key+'', odd_words_dict[key], result)\r\n",
        "\r\n",
        "  return result"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "id": "bOIF01WGsDzv",
        "outputId": "0b3ac2a2-6185-4d1b-9a17-32b94c0cba7e"
      },
      "source": [
        "# use this cell to run the function on the new text and see if anything looks odd\r\n",
        "baseline_clean(epictetus_enchiridion)[1000:3000]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"y, nor will you suffer any harm. Aiming, therefore, at such great things, remember that you must not allow yourself any inclination, however slight, toward the attainment of the others; but that you must entirely quit some of them, and for the present postpone the rest. But if you would have these, and possess power and wealth likewise, you may miss the latter in seeking the former; and you will certainly fail of that by which alone happiness and freedom are procured. Seek at once, therefore, to be able to say to every unpleasing semblance, 'You are but a semblance and by no means the real thing.' And then examine it by those rules which you have; and first and chiefly by this: whether it concerns the things which are within our own power or those which are not; and if it concerns anything beyond our power, be prepared to say that it is nothing to you. Remember that desire demands the attainment of that of which you are desirous; and aversion demands the avoidance of that to which you are averse; that he who fails of the object of his desires is disappointed; and he who incurs the object of his aversion is wretched. If, then, you shun only those undesirable things which you can control, you will never incur anything which you shun; but if you shun sickness, or death, or poverty, you will run the risk of wretchedness. Remove the habit of aversion, then, from all things that are not within our power, and apply it to things undesirable which are within our power. But for the present, altogether restrain desire; for if you desire any of the things not within our own power, you must necessarily be disappointed; and you are not yet secure of those which are within our power, and so are legitimate objects of desire. Where it is practically necessary for you to pursue or avoid anything, do even this with discretion and gentleness and moderation. With regard to whatever objects either delight the mind or contribute to use or are tenderly beloved, remind yourself of what natu\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e3D7iGALiMC"
      },
      "source": [
        "#### 2. Text-by-Text Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_T4TRdEL2aM"
      },
      "source": [
        "In this step we will remove headers and other offensive features of specific texts. \r\n",
        "\r\n",
        "The most common problem is the presence of headings that appear at the top of each page in the original book. When converted to a string, these then get interpolated into the text, interrupting the normal flow of sentences (this happens for page numbers and citations as well, but those cases are much easier to deal with). \r\n",
        "\r\n",
        "To deal with this, we build a list of the headers for each book and then delete them from the string that represents the book. In the process, we may create some issues if the header is common, so we are careful to only delete when the loss is worth it.\r\n",
        "\r\n",
        "In some cases, of course, the texts are already clean and no extra steps are required."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxmXkIWbsJVs"
      },
      "source": [
        "plato_to_rm = ['Apology', 'Sophist', 'Statesman', 'Symposium', \r\n",
        "                 'Second Alcibiades', 'Rival Lovers', 'Greater Hippias', \r\n",
        "                 'Lesser Hippias', 'Republic', 'Laws', 'Letters', 'Definitions',\r\n",
        "                 'On Virtue', 'On Justice', 'Epigrams', 'Translated b.+\\.']\r\n",
        "\r\n",
        "aristotle_to_rm = ['Aristotle', 'Book']\r\n",
        "\r\n",
        "descartes_meditations_to_rm = ['Letter of Dedication', 'Preface to the Reader', \r\n",
        "                               'Synopsis', 'First Meditation', 'Second Meditation', \r\n",
        "                               'Third Meditation', 'Fourth Meditation', 'Fifth Meditation', \r\n",
        "                               'Sixth Meditation']\r\n",
        "\r\n",
        "malebranche_search_to_rm = ['Nicolas Malebranche', 'Truth', 'Nicolas',]\r\n",
        "\r\n",
        "locke_gov_to_rm = ['Sect.']\r\n",
        "\r\n",
        "berkeley_dialogues_to_rm = ['PHIL.', 'PHILONOUS.', 'HYL.', 'HYLAS.']\r\n",
        "\r\n",
        "kant_judgement_to_rm = ['Introduction', 'Preface to the First Edition', \r\n",
        "                        'Critique of Aesthetic Judgement', 'Critique of Teleological Judgement',\r\n",
        "                        'Analytic of the Beautiful', 'Analytic of the Sublime',\r\n",
        "                        'Anaytic of Teleological Judgement', 'Dialectic of Aeshetic Judgement',\r\n",
        "                        'Critique of Teleological Judgement', 'Dialectic of Teleological Judgement',\r\n",
        "                        'Theory of the Method of Teleological Judgement',\r\n",
        "                        '‘First Introduction’ to the Critique of Judgement']\r\n",
        "\r\n",
        "kant_pure_reason_to_rm = ['Introduction', '\\s+Section\\s.+', '\\sDoctrine\\s*of\\s*Elements\\.\\s*.+',\r\n",
        "                          '\\sDoctrine\\s*of\\s*Method\\.\\s*.+']                        \r\n",
        "\r\n",
        "\r\n",
        "fichte_ethics_to_rm = ['Page']\r\n",
        "\r\n",
        "hegel_SoL_to_rm = ['Georg Wilhelm Friedrich Hegel', 'The Science of Logic']\r\n",
        "\r\n",
        "hegel_right_to_rm = ['Preface', 'Philosophy of Right', 'Philosophy ofRight', \r\n",
        "                     'Philosophy ojRight', 'Philosophy oj Right', \r\n",
        "                     'Introduction', 'Abstract Right', 'Ethical Life', 'Ethical Lift',\r\n",
        "                     'Morality']\r\n",
        "\r\n",
        "wittgenstein_tract_to_rm = ['tractatus logico-philosophicus']\r\n",
        "\r\n",
        "lewis_papers_1_to_rm = ['Introduction', 'Ontology', 'Holes', 'Anselm and Actuality', \r\n",
        "                        'Counterpart Theory and Quantified Modal Logic', \r\n",
        "                        'Counterparts of Persons and Their Bodies', 'Survival and Identity',\r\n",
        "                        'How to Define Theoretical Terms', 'Philosophy of Mind', \r\n",
        "                        'An Argument for the Identity Theory', 'Radical Interpretation',\r\n",
        "                        'Mad Pain and Partian Pain', 'Attitudes De Dicto and De Se',\r\n",
        "                        'Philosophy of Language', 'Languages and Language',\r\n",
        "                        'General Semantics', 'Scorekeeping in a Language Game',\r\n",
        "                        'Tensions', 'Truth in Fiction', 'This page intentionally left blank']\r\n",
        "\r\n",
        "lewis_papers_2_to_rm = ['end\\sp\\.']\r\n",
        "\r\n",
        "quine_quintessence_to_rm = ['(?i)\\s+Truth\\s+by\\s+Convention\\s+', '(?i)\\s+Two\\s+Dogams\\s+of\\s+Empiricism',\r\n",
        "                            '(?i)\\s+Two\\s+in\\s+Retrospect\\s+', '(?i)\\s+Carnap\\s+and\\s+Logical\\s+Truth',\r\n",
        "                            '(?i)\\s+Speaking\\s+of\\s+Objects\\s+', '(?i)\\s+Reference\\s+',\r\n",
        "                            '(?i)\\s+Translation\\s+and\\s+Meaning', '(?i)\\s+Progress\\s+on\\s+Two\\s+Fronts\\s+',\r\n",
        "                            '(?i)\\s+On\\s+What\\s+There\\s+is\\s+', '(?i)\\s+the\\s+scope\\s+and\\s+language\\s+of\\s+science\\s+',\r\n",
        "                            '(?i)\\s+on\\s+simple\\s+theories\\s+of\\s+a\\s+complex\\s+world\\s+',\r\n",
        "                            '(?i)\\s+ontic\\s+decision\\s+', '(?i)\\s+things\\s+and\\s+their\\s+place\\s+in\\s+theories\\s+',\r\n",
        "                            \"(?i)\\s+on\\s+Carnap\\s*'s\\s+views\\s+on\\s+ontology\\s+\",\r\n",
        "                            '(?i)\\s+empistemology\\s+naturalized\\s+', \r\n",
        "                            \"(?i)\\s+naturalism\\s;\\s+or,\\s+living\\s+within\\s+one\\s*'s\\s+means\\s+\",\r\n",
        "                            '(?i)\\s+the\\s+nature\\s+of\\s+natural\\s+knowledge\\s+',\r\n",
        "                            '(?i)\\s+five\\s+milestones\\s+of\\s+empiricism\\s+',\r\n",
        "                            '(?i)\\s+on\\s+mental\\s+entities\\s+', '(?i)\\s+mind\\s+and\\s+verbal\\s+dispositions\\s+',\r\n",
        "                            '(?i)\\s+confessions\\s+of\\s+a\\s+confirmed\\s+extensionalist\\s+',\r\n",
        "                            '(?i)\\s+quantifiers\\s+and\\s+propositional\\s+attitudes\\s+',\r\n",
        "                            '(?i)\\s+intensions\\s+revisited\\s+', '(?i)\\s+reference\\s+and\\s+modality\\s+',\r\n",
        "                            '(?i)\\s+three\\s+grades\\s+of\\s+modal\\s+involvement\\s+']\r\n",
        "\r\n",
        "popper_science_to_rm = ['the logic of science', 'a survey of some fundamental problems',\r\n",
        "                        'preface', 'on the problem of a theory of scientific method',\r\n",
        "                        'some structural components of a theory of experience',\r\n",
        "                        'degrees of testability', 'some observations on quantum theory',\r\n",
        "                        'corroboration, or how a theory stands up to tests']\r\n",
        "\r\n",
        "kripke_troubles_to_rm = ['Identity and Necessity', 'On Two Paradoxes of Knowledge',\r\n",
        "                          'Vacuous Names and Fictional Entities', 'Outline of a Theory of Truth',\r\n",
        "                          \"Speaker's Reference and Semantic Reference\",\r\n",
        "                          'A Puzzle about Belief', 'Nozick on Knowledge', \r\n",
        "                          \"Russell's Notion of Scope\", \"Frege's Theory of Sense and Reference\",\r\n",
        "                          'The First Person', 'Unrestricted Exportation and Some Morals for the Philosophy',\r\n",
        "                          'Presupposition and Anaphora', 'A Puzzle about Time and Thought']\r\n",
        "\r\n",
        "ponty_perception_to_rm = ['phenomenology of perception', 'preface',\r\n",
        "                          \"the 'sensation' as a unit of experience\", \r\n",
        "                          \"'association' and the 'projection of memories'\",\r\n",
        "                          \"'attention' and 'judgement'\", 'the phenomenal field', \r\n",
        "                          'experience and objective thought', 'the body as object and mechanistic psychology',\r\n",
        "                          'the experience of the body and classical psychology',\r\n",
        "                          \"the spatiality of one’s own body and motility\",\r\n",
        "                          \"the synthesis of one's own body\", 'the body in its sexual being',\r\n",
        "                          'the body as expression, and speech',\r\n",
        "                          'theory of the body is already a theory of perception',\r\n",
        "                          'sense experience', 'the thing and the natural world',\r\n",
        "                          'other selves and the human world']\r\n",
        "\r\n",
        "husserl_crisis_to_rm = ['Part\\s+', 'Idealization and the Science of Reality', \r\n",
        "                        'Denial of Scientific Philosophy', 'The Origin of Geometry',\r\n",
        "                        'Natural Science and Humanistic Science',\r\n",
        "                        'The Vienna Lecture']\r\n",
        "\r\n",
        "heidegger_b_and_t_to_rm = ['\\s+Being\\s*and\\s*Time\\s+', 'Int.', 'I.m', 'I.n']                                                  \r\n",
        "\r\n",
        "foucault_order_to_rm = ['the order of things', 'the prose of the world', '\\s+classifying\\s+',\r\n",
        "                        'exchanging', 'the limits of representation',\r\n",
        "                        'labour, life, language', 'man and his doubles']\r\n",
        "\r\n",
        "foucault_madness_to_rm = ['\\s+Page\\s']\r\n",
        "\r\n",
        "foucault_clinic_to_rm = ['\\(\\(.+\\)\\)']\r\n",
        "\r\n",
        "deleuze_difference_to_rm = ['Difference and Repetition', 'Difference in Itself',\r\n",
        "                            'Repetition for Itself', 'The Image of Thought',\r\n",
        "                            'Ideas and the Synthesis of Difference',\r\n",
        "                            'Asymmetrical Synthesis of the Sensible', 'Conclusion']\r\n",
        "\r\n",
        "marx_kapital_to_rm = ['http.+', 'Capital\\s+Vol\\..+']\r\n",
        "\r\n",
        "marx_manifesto_to_rm = ['\\s+page\\s+\\d+']\r\n",
        "\r\n",
        "keynes_employment_to_rm = ['(?i)\\s+The\\s+General\\s+Theory\\s+of\\s+Employment,*\\s+interest\\s+and\\s+money\\s+by\\s+john\\s+maynard\\s+keynes\\s+',\r\n",
        "                           'Table of Contents \\| Previous Chapter \\| Next Chapter', \r\n",
        "                           'Chapter\\s+\\d+']       \r\n",
        "\r\n",
        "do_not_remove_capitals = ['essay concerning human understanding bk 2', \r\n",
        "                          'a treatise of human nature', \r\n",
        "                          'dialogues concerning natural religion', 'three dialogues', \r\n",
        "                          'a treatise concerning the principles of human knowledge']\r\n",
        "\r\n",
        "bracketed_fn = ['critique of practical reason', 'the communist manifesto']                                          "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Z6-svnmMCtz"
      },
      "source": [
        "#### 3. Tokenizing and Rendering the Texts as a Dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meZEHHSgMEBd"
      },
      "source": [
        "We now are in a position to apply these methods to each text and return a dataframe for each of them. Although we are interested primarily in the schools of thought in general, it would be convenient and more useful for future projects if we also include the specific authors and titles. \r\n",
        "\r\n",
        "To prepare for this project, we build a dictionary for each school, so that we can then iterate over a list of dictionaries to create a dataframe for each."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ct6SmxnTsM1k",
        "outputId": "1f60c45b-a34d-4057-c5c8-6304a4cda501"
      },
      "source": [
        "# prepare lists that will be zipped into a dictionary\r\n",
        "\r\n",
        "# texts \r\n",
        "all_texts\r\n",
        "\r\n",
        "# titles\r\n",
        "title_list = [\"plato - complete works\", \"aristotle - complete works\", \"aristotle - complete works\",\r\n",
        "              'second treatise on government', 'essay concerning human understanding',\r\n",
        "              'essay concerning human understanding', 'a treatise of human nature', \r\n",
        "              'dialogues concerning natural religion', 'three dialogues', \r\n",
        "              'a treatise concerning the principles of human knowledge',\r\n",
        "              'ethics', 'on the improvement of understanding', 'theodicy',\r\n",
        "              'discourse on method', 'meditations', 'the search after truth',\r\n",
        "              'the analysis of mind', 'the problems of philosophy', 'philosophical studies',\r\n",
        "              'philosophical investigations', 'tractatus logico-philosophicus',\r\n",
        "              \"lewis - papers\", \"lewis - papers\", 'quintessence', \r\n",
        "              'the logic of scientific discovery', 'naming and necessity', \r\n",
        "              'philosophical troubles', 'the birth of the clinic', 'madness and civilization',\r\n",
        "              'the order of things', 'writing and difference', 'difference and repetition',\r\n",
        "              'anti-oedipus', 'the phenomenology of perception', \r\n",
        "              'the crisis of the european sciences and phenomenology', \r\n",
        "              'the idea of phenomenology',\r\n",
        "              'being and time', 'off the beaten track', 'critique of practical reason', \r\n",
        "              'critique of judgement', 'critique of pure reason', \r\n",
        "              'the system of ethics', 'science of logic', 'the phenomenology of spirit',\r\n",
        "              'elements of the philosophy of right', 'capital', 'the communist manifesto', \r\n",
        "              'essential works of lenin', 'the wealth of nations', \r\n",
        "              'on the principles of political economy and taxation',\r\n",
        "              'a general theory of employment, interest, and money', 'enchiridion']\r\n",
        "\r\n",
        "# authors\r\n",
        "author_list = ['plato', 'aristotle', 'aristotle', 'locke', 'locke', 'locke',\r\n",
        "               'hume', 'hume', 'berkeley', 'berkeley', 'spinoza', 'spinoza',\r\n",
        "               'leibniz', 'descartes', 'descartes', 'malebranche', 'russell', \r\n",
        "               'russell', 'moore', 'wittgenstein', 'wittgenstein', 'lewis', 'lewis',\r\n",
        "               'quine', 'popper', 'kripke', 'kripke', 'foucault', 'foucault', \r\n",
        "               'foucault', 'derrida', 'deleuze', 'deleuze', 'merleau-ponty', \r\n",
        "               'husserl', 'husserl', 'heidegger', 'heidegger', 'kant', 'kant',\r\n",
        "               'kant', 'fichte', 'hegel', 'hegel', 'hegel', 'marx', 'marx', 'lenin',\r\n",
        "               'smith', 'ricardo', 'keynes', 'epictetus']\r\n",
        "\r\n",
        "school_list = ['plato', 'aristotle', 'aristotle', 'empiricism', 'empiricism', \r\n",
        "               'empiricism', 'empiricism', 'empiricism', 'empiricism', 'empiricism',\r\n",
        "               'rationalism', 'rationalism', 'rationalism', 'rationalism', \r\n",
        "               'rationalism', 'rationalism', 'analytic', 'analytic', 'analytic', \r\n",
        "               'analytic', 'analytic', 'analytic', 'analytic', 'analytic', 'analytic', \r\n",
        "               'analytic', 'analytic', 'continental', 'continental', 'continental', \r\n",
        "               'continental', 'continental', 'continental', 'phenomenology', \r\n",
        "               'phenomenology', 'phenomenology', 'phenomenology', 'phenomenology', \r\n",
        "               'german_idealism', 'german_idealism', 'german_idealism', 'german_idealism',\r\n",
        "               'german_idealism', 'german_idealism', 'german_idealism', 'communism', \r\n",
        "               'communism', 'communism', 'capitalism', 'capitalism', 'capitalism', 'stoicism']               \r\n",
        "\r\n",
        "# words to remove \r\n",
        "to_rm_list = [plato_to_rm, aristotle_to_rm, aristotle_to_rm, locke_gov_to_rm, \r\n",
        "              [], [], [], [], berkeley_dialogues_to_rm, [], [], [], [], [], \r\n",
        "              descartes_meditations_to_rm, malebranche_search_to_rm, [],\r\n",
        "              [], [], [], wittgenstein_tract_to_rm, lewis_papers_1_to_rm, \r\n",
        "              lewis_papers_2_to_rm, quine_quintessence_to_rm, popper_science_to_rm,\r\n",
        "              [], kripke_troubles_to_rm, foucault_clinic_to_rm, foucault_madness_to_rm,\r\n",
        "              foucault_order_to_rm, [], deleuze_difference_to_rm, [],\r\n",
        "              ponty_perception_to_rm, husserl_crisis_to_rm, [], heidegger_b_and_t_to_rm,\r\n",
        "              [], [], kant_judgement_to_rm, kant_pure_reason_to_rm, fichte_ethics_to_rm, \r\n",
        "              hegel_SoL_to_rm, [], hegel_right_to_rm, marx_kapital_to_rm, \r\n",
        "              marx_manifesto_to_rm, [], [], [], keynes_employment_to_rm, []]\r\n",
        "\r\n",
        "# check lengths to make sure all are present\r\n",
        "len(to_rm_list), len(all_texts), len(author_list), len(title_list), len(school_list)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 52, 52, 52, 52)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWV3U1XIsPEe",
        "outputId": "755d0d85-5188-4df5-c184-79c9e455df6a"
      },
      "source": [
        "# combine all these into a single list of dictionaries\r\n",
        "book_dicts = []\r\n",
        "for i in range(0, len(all_texts)):\r\n",
        "  book_dict = {}\r\n",
        "  book_dict['author'] = author_list[i].title()\r\n",
        "  book_dict['title'] = title_list[i].title()\r\n",
        "  book_dict['text'] = all_texts[i]\r\n",
        "  book_dict['school'] = school_list[i]\r\n",
        "  book_dict['words to remove'] = to_rm_list[i]\r\n",
        "  book_dict['remove capitals'] = True\r\n",
        "  book_dict['bracketed fn'] = False\r\n",
        "  book_dicts.append(book_dict)\r\n",
        "\r\n",
        "# mark the ones with bracketed footnotes \r\n",
        "for book in book_dicts:\r\n",
        "  if book['title'] in bracketed_fn:\r\n",
        "    book['bracketed fn'] = True\r\n",
        "\r\n",
        "# mark the ones with capitals we want to keep\r\n",
        "for book in book_dicts:\r\n",
        "  if book['title'] in do_not_remove_capitals:\r\n",
        "    book['remove capitals'] = False\r\n",
        "  \r\n",
        "# check length again to make sure\r\n",
        "len(book_dicts)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Old9KJCnMSLo"
      },
      "source": [
        "With a dictionary for each text, we are prepared to clean them, build dataframes for each text, and combine them into a master dataframe for all our data. \r\n",
        "\r\n",
        "As part of that, we use a new dictionary where the keys correspond to textual oddities and the values correspond to their corrected version. This helps deal with many individual cases of strange behavior in the corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "Xe_GUeVisQ7C"
      },
      "source": [
        "#@title Oddities Dictionary for Cleaning\r\n",
        "# a dictionary of oddities to clean up\r\n",
        "odd_words_dict = {'\\sderstanding': 'derstanding',\r\n",
        "                  '\\sforthe\\s': ' for the ',\r\n",
        "                  '\\sject': 'ject',\r\n",
        "                  '\\sjects': 'jects', \r\n",
        "                  '\\sness': 'ness',\r\n",
        "                  '\\sper\\scent\\s': ' percent ',\r\n",
        "                  '\\sper\\scent\\.': ' percent.',\r\n",
        "                  '\\sper\\scent,': ' percent,',\r\n",
        "                  '\\wi\\son': 'ion',\r\n",
        "                  '\\spri\\sori': ' priori',\r\n",
        "                  '\\stences\\s': 'tences ',\r\n",
        "                  '\\sprincipleb': ' principle',\r\n",
        "                  '\\ssciousness': 'sciousness',\r\n",
        "                  '\\stion': 'tion',\r\n",
        "                  '\\spri\\s': ' pri',\r\n",
        "                  '\\scluding': 'cluding',\r\n",
        "                  '\\sdom': 'dom',\r\n",
        "                  '\\sers': 'ers',\r\n",
        "                  '\\scritiq\\s': ' critique ',\r\n",
        "                  '\\ssensati\\s': ' sensation ',\r\n",
        "                  '(?i)\\syou\\sll': \" you'll\",\r\n",
        "                  '\\sI\\sll': \" I'll\",\r\n",
        "                  '(?i)\\swe\\sll': \" we'll\",\r\n",
        "                  '(?i)he\\sll': \" he'll\",\r\n",
        "                  '(?i)who\\sll': \"who'll\",\r\n",
        "                  '(?i)\\sthere\\sll\\s': \" there'll \",\r\n",
        "                  '\\seduca\\s': ' education ',\r\n",
        "                  '\\slity\\s': 'lity ',\r\n",
        "                  '\\smultaneously\\s': 'multaneously ',\r\n",
        "                  '\\stically\\s': 'tically ',\r\n",
        "                  '\\sDa\\ssein\\s': ' Dasein ',\r\n",
        "                  '(?i)\\sthey\\sll\\s': \" they'll \",\r\n",
        "                  '(?i)\\sin\\tum\\s': ' in turn ',\r\n",
        "                  '\\scon~\\s': ' con',\r\n",
        "                  '\\sà\\s': ' a ',\r\n",
        "                  '\\sjor\\s': ' for ',\r\n",
        "                  '\\sluminating\\s': 'luminating ',\r\n",
        "                  '\\sselj\\s': ' self ',\r\n",
        "                  '\\stial\\s': 'tial ',\r\n",
        "                  '\\sversal\\s': 'versal ',\r\n",
        "                  '\\sexis\\st': ' exist',\r\n",
        "                  '\\splauded\\s': 'plauded ',\r\n",
        "                  '\\suiry\\s': 'uiry ',\r\n",
        "                  '\\svithin\\s': ' within ',\r\n",
        "                  '\\soj\\s': ' of ',\r\n",
        "                  '\\sposi\\st': ' posit',\r\n",
        "                  '\\sra\\sther\\s': ' rather ',\r\n",
        "                  '(?i)\\sthat\\sll\\s': \" that'll \",\r\n",
        "                  '(?i)\\sa\\sll\\s': ' all ',\r\n",
        "                  '\\so\\sther\\s': ' other ',\r\n",
        "                  '\\sra\\sther\\s': ' rather ',\r\n",
        "                  '\\snei\\sther\\s': ' neither ',\r\n",
        "                  '\\sei\\sther\\s': ' either ',\r\n",
        "                  '\\sfur\\sther\\s': ' further ',\r\n",
        "                  '\\sano\\sther': ' another ',\r\n",
        "                  '\\sneces\\s': ' neces',\r\n",
        "                  'u\\slar\\s': 'ular ',\r\n",
        "                  '\\sference\\s': 'ference ',\r\n",
        "                  '(?i)it\\sll\\s': \"it'll \",\r\n",
        "                  '\\stoge\\sther': ' together ',\r\n",
        "                  '\\sknowledgeb\\s': ' knowledge ',\r\n",
        "                  'r\\stain\\s': 'rtain ',\r\n",
        "                  'on\\stain\\s': 'ontain',\r\n",
        "                  '(?i)j\\sect\\s': 'ject',\r\n",
        "                  '\\sob\\sect\\s': ' object ',\r\n",
        "                  '\\sbtle\\s': 'btle ',\r\n",
        "                  '\\snition\\s': 'nition ',\r\n",
        "                  '\\sdering\\s': 'dering ', \r\n",
        "                  '\\sized\\s': 'ized ',\r\n",
        "                  '\\sther\\shand': ' other hand',\r\n",
        "                  '\\ture\\s': 'ture ',\r\n",
        "                  '\\sabso\\sl': ' absol',\r\n",
        "                  '\\stly\\s': 'tly ',\r\n",
        "                  '\\serty\\s': 'erty ',\r\n",
        "                  '\\sobj\\se': ' obj',\r\n",
        "                  '\\sffiir\\s': ' for ',\r\n",
        "                  '\\sndeed\\s': ' indeed ',\r\n",
        "                  '\\sfonn\\s': ' form ',\r\n",
        "                  '\\snally\\s': 'nally ',\r\n",
        "                  'ain\\sty\\s': 'ainty ',\r\n",
        "                  'ici\\sty\\s': 'icity ',\r\n",
        "                  '\\scog\\sni': ' cogni',\r\n",
        "                  '\\sacc\\s': ' acc',\r\n",
        "                  '\\sindi\\svid\\sual': ' individual', \r\n",
        "                  '\\sintu\\sit': ' intuit',\r\n",
        "                  'r\\sance\\s': 'rance ',\r\n",
        "                  '\\ssions\\s': 'sions ',\r\n",
        "                  '\\sances\\s': 'ances ',\r\n",
        "                  '\\sper\\sception\\s': ' perception ',\r\n",
        "                  '\\sse\\sries\\s': ' series ',\r\n",
        "                  '\\sque\\sries\\s': ' queries ',\r\n",
        "                  '\\sessary\\s': 'essary ',\r\n",
        "                  '\\sofa\\s': ' of a ',\r\n",
        "                  '\\scer\\stainty\\s': ' certainty ',\r\n",
        "                  'ec\\stivity\\s': 'ectivity ',\r\n",
        "                  '\\stivity\\s': 'tivity ',\r\n",
        "                  '\\slation\\s': 'lation ',\r\n",
        "                  '\\sir\\sr': ' irr',\r\n",
        "                  '\\ssub\\sstance\\s': ' substance ',\r\n",
        "                  'sec\\sond\\s': 'second ',\r\n",
        "                  '\\s\\.rv': '',\r\n",
        "                  '\\story\\s': 'tory ',\r\n",
        "                  '\\sture\\s': 'ture ',\r\n",
        "                  '\\sminate\\s': 'minate ',\r\n",
        "                  '\\sing\\s': 'ing ',\r\n",
        "                  '\\splicity\\s': 'plicity ',\r\n",
        "                  '\\ssimi\\slar\\s': ' similar ',\r\n",
        "                  '\\scom\\smunity\\s': ' community ',\r\n",
        "                  '\\sitselfa\\s': ' itself a ',\r\n",
        "                  '\\ssimp\\s': ' simply ',\r\n",
        "                  '\\scon\\stex': ' contex',\r\n",
        "                  '\\scon\\sseq': ' conseq',\r\n",
        "                  '\\scon\\stai': ' contai',\r\n",
        "                  '\\sofwhat\\s': ' of what ',\r\n",
        "                  '\\sui\\s': 'ui',\r\n",
        "                  '\\sofan\\s': ' of an ',\r\n",
        "                  '\\saccor\\sdance\\s': ' accordance ',\r\n",
        "                  '\\stranscen\\sdental\\s': ' transcendental ',\r\n",
        "                  '\\sap\\spearances\\s': ' appearances ',\r\n",
        "                  'e\\squences\\s': 'equences ',\r\n",
        "                  '\\sorits\\s': ' or its ',\r\n",
        "                  '\\simma\\sn': ' imman',\r\n",
        "                  '\\seq\\sua': ' equa',\r\n",
        "                  '\\simpl\\sied\\s': ' implied ',\r\n",
        "                  '\\sbuta\\s': ' but a ',\r\n",
        "                  '\\sa\\snd\\s': ' and ',\r\n",
        "                  '\\sence\\s': 'ence ',\r\n",
        "                  '\\stain\\s': 'tain ',\r\n",
        "                  '\\sunder\\sstanding\\s': ' understanding ',\r\n",
        "                  'i\\sence\\s': 'ience ',\r\n",
        "                  'r\\sence\\s': 'rence ',\r\n",
        "                  '\\stical\\s': 'tical ',\r\n",
        "                  '\\sobjectsb\\s': ' objects ',\r\n",
        "                  '\\stbe\\s': ' the ',\r\n",
        "                  '\\smul\\st': ' mult',\r\n",
        "                  '\\sgen\\seral\\s': ' general ',\r\n",
        "                  '\\suniver\\ssal\\s': ' universal ',\r\n",
        "                  '\\scon\\stent\\s': ' content ',\r\n",
        "                  '\\spar\\sticular\\s': ' particular ',\r\n",
        "                  'ver\\ssity\\s': 'versity ',\r\n",
        "                  '\\sCritiq\\s': ' Critique ',\r\n",
        "                  '\\sphilo\\ssophy\\s': ' philosophy ',\r\n",
        "                  '\\seq\\s': ' eq'}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_KZCE6YsYE7",
        "outputId": "b8caa3e7-b24a-4dfd-ee49-617599bc1f4b"
      },
      "source": [
        "def from_raw_to_df(text_dict):\r\n",
        "  nlp.max_length = 9000000\r\n",
        "  text = text_dict['text']\r\n",
        "  text = remove_words(text, text_dict['words to remove'])\r\n",
        "  text = baseline_clean(text, capitals=text_dict['remove capitals'],\r\n",
        "                        bracketed_fn=text_dict['bracketed fn'],\r\n",
        "                        odd_words_dict=odd_words_dict)\r\n",
        "  text_nlp = nlp(text, disable=['ner'])\r\n",
        "  text_df = pd.DataFrame(columns=['title', 'author', 'school', 'sentence_spacy'])\r\n",
        "  text_df['sentence_spacy'] = list(text_nlp.sents)\r\n",
        "  text_df['author'] = text_dict['author']\r\n",
        "  text_df['title'] = text_dict['title']\r\n",
        "  text_df['school'] = text_dict['school']\r\n",
        "  text_df['sentence_str'] = text_df['sentence_spacy'].apply(lambda x: ''.join(list(str(x))))\r\n",
        "  return text_df\r\n",
        "\r\n",
        "df = pd.DataFrame(columns=['title', 'author', 'school', 'sentence_spacy', 'sentence_str'])\r\n",
        "for book in book_dicts:\r\n",
        "  book_df = from_raw_to_df(book)\r\n",
        "  df = df.append(book_df, ignore_index=True)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "361717"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "id": "0rTa7P8KwXC6",
        "outputId": "23d3a5e6-2b6d-442c-dcd1-9209ac0985e0"
      },
      "source": [
        "pd.options.display.max_colwidth = 200\r\n",
        "df.sample(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>205985</th>\n",
              "      <td>Philosophical Troubles</td>\n",
              "      <td>Kripke</td>\n",
              "      <td>analytic</td>\n",
              "      <td>((, I, wish, I, had, had, the, opportunity, to, talk, with, her, about, the, paper, ., ))</td>\n",
              "      <td>(I wish I had had the opportunity to talk with her about the paper.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55193</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(de, me, echei, hosa, .)</td>\n",
              "      <td>de me echei hosa.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75055</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(For, no, sanguineous, animal, if, it, be, divided, into, more, parts, can, live, for, any, appreciable, length, of, time, ,, nor, can, it, enjoy, the, power, of, locomotion, which, it, possessed,...</td>\n",
              "      <td>For no sanguineous animal if it be divided into more parts can live for any appreciable length of time, nor can it enjoy the power of locomotion which it possessed while it was a continuous and un...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137717</th>\n",
              "      <td>The Search After Truth</td>\n",
              "      <td>Malebranche</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>(Thus, ,, the, soul, ,, being, no, longer, diverted, by, sensible, things, ,, can, easily, contemplate, the, truth, .)</td>\n",
              "      <td>Thus, the soul, being no longer diverted by sensible things, can easily contemplate the truth.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287290</th>\n",
              "      <td>Critique Of Pure Reason</td>\n",
              "      <td>Kant</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(:, only, this, concept, does, not, agree, with, what, is, usually, understood, by, an, infinite, whole, .)</td>\n",
              "      <td>: only this concept does not agree with what is usually understood by an infinite whole.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23105</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>(On, the, other, hand, ,, if, virtue, is, anything, other, than, knowledge, ,, as, Protagoras, has, been, trying, to, say, ,, then, it, would, clearly, be, unteachable, .)</td>\n",
              "      <td>On the other hand, if virtue is anything other than knowledge, as Protagoras has been trying to say, then it would clearly be unteachable.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132010</th>\n",
              "      <td>Theodicy</td>\n",
              "      <td>Leibniz</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>(I, mean, this, in, respect, of, metaphysical, necessity, ;, for, it, is, a, moral, necessity, that, the, wisest, should, be, bound, to, choose, the, best, .)</td>\n",
              "      <td>I mean this in respect of metaphysical necessity; for it is a moral necessity that the wisest should be bound to choose the best.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107111</th>\n",
              "      <td>Essay Concerning Human Understanding</td>\n",
              "      <td>Locke</td>\n",
              "      <td>empiricism</td>\n",
              "      <td>(Thirdly, ,, or, the, same, immaterial, spirit, united, to, the, same, animal, .)</td>\n",
              "      <td>Thirdly, or the same immaterial spirit united to the same animal.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5882</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>(Now, see, if, there, is, anything, in, this, .)</td>\n",
              "      <td>Now see if there is anything in this.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282837</th>\n",
              "      <td>Critique Of Pure Reason</td>\n",
              "      <td>Kant</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(In, space, their, shape, ,, magnitude, ,, and, relation, to, one, another, is, determined, ,, or, determinable, .)</td>\n",
              "      <td>In space their shape, magnitude, and relation to one another is determined, or determinable.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       title  ...                                                                                                                                                                                             sentence_str\n",
              "205985                Philosophical Troubles  ...                                                                                                                                     (I wish I had had the opportunity to talk with her about the paper.)\n",
              "55193             Aristotle - Complete Works  ...                                                                                                                                                                                        de me echei hosa.\n",
              "75055             Aristotle - Complete Works  ...  For no sanguineous animal if it be divided into more parts can live for any appreciable length of time, nor can it enjoy the power of locomotion which it possessed while it was a continuous and un...\n",
              "137717                The Search After Truth  ...                                                                                                           Thus, the soul, being no longer diverted by sensible things, can easily contemplate the truth.\n",
              "287290               Critique Of Pure Reason  ...                                                                                                                 : only this concept does not agree with what is usually understood by an infinite whole.\n",
              "23105                 Plato - Complete Works  ...                                                               On the other hand, if virtue is anything other than knowledge, as Protagoras has been trying to say, then it would clearly be unteachable.\n",
              "132010                              Theodicy  ...                                                                        I mean this in respect of metaphysical necessity; for it is a moral necessity that the wisest should be bound to choose the best.\n",
              "107111  Essay Concerning Human Understanding  ...                                                                                                                                        Thirdly, or the same immaterial spirit united to the same animal.\n",
              "5882                  Plato - Complete Works  ...                                                                                                                                                                    Now see if there is anything in this.\n",
              "282837               Critique Of Pure Reason  ...                                                                                                             In space their shape, magnitude, and relation to one another is determined, or determinable.\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFFcGwHUwTKv",
        "outputId": "2a3f74d5-638e-4398-b954-f3511d6b079c"
      },
      "source": [
        "df['school'].value_counts(normalize=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "analytic           0.161892\n",
              "aristotle          0.149645\n",
              "plato              0.132886\n",
              "german_idealism    0.132070\n",
              "continental        0.097853\n",
              "phenomenology      0.084328\n",
              "rationalism        0.072676\n",
              "empiricism         0.057763\n",
              "communism          0.057465\n",
              "capitalism         0.052497\n",
              "stoicism           0.000926\n",
              "Name: school, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 555
        },
        "id": "SujsiUfnsfvU",
        "outputId": "f2b4990d-9e0b-49ba-f4d8-ee7ab5a67bd6"
      },
      "source": [
        "# use this cell to check the new author's sentences and see if anything seems amiss\r\n",
        "print(len(df[df['author']=='Epictetus']))\r\n",
        "df[df['author']=='Epictetus'].sample(20)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>361382</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(There, are, things, which, are, within, our, power, ,, and, there, are, things, which, are, beyond, our, power, .)</td>\n",
              "      <td>There are things which are within our power, and there are things which are beyond our power.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361383</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(Within, our, power, are, opinion, ,, aim, ,, desire, ,, aversion, ,, and, ,, in, one, word, ,, whatever, affairs, are, our, own, .)</td>\n",
              "      <td>Within our power are opinion, aim, desire, aversion, and, in one word, whatever affairs are our own.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361384</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(Beyond, our, power, are, body, ,, property, ,, reputation, ,, office, ,, and, ,, in, one, word, ,, whatever, are, not, properly, our, own, affairs, .)</td>\n",
              "      <td>Beyond our power are body, property, reputation, office, and, in one word, whatever are not properly our own affairs.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361385</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(Now, the, things, within, our, power, are, by, nature, free, ,, unrestricted, ,, unhindered, ;, but, those, beyond, our, power, are, weak, ,, dependent, ,, restricted, ,, alien, .)</td>\n",
              "      <td>Now the things within our power are by nature free, unrestricted, unhindered; but those beyond our power are weak, dependent, restricted, alien.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361386</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(Remember, ,, then, ,, that, if, you, attribute, freedom, to, things, by, nature, dependent, and, take, what, belongs, to, others, for, your, own, ,, you, will, be, hindered)</td>\n",
              "      <td>Remember, then, that if you attribute freedom to things by nature dependent and take what belongs to others for your own, you will be hindered</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361712</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(I, follow, cheerfully, ;, and, ,, did, I, not, ,, Wicked, and, wretched, ,, I, must, follow, still, .)</td>\n",
              "      <td>I follow cheerfully; and, did I not, Wicked and wretched, I must follow still.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361713</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(Who'er, yields, properly, to, Fate, is, deemed, Wise, among, men, ,, and, knows, the, laws, of, Heaven, .)</td>\n",
              "      <td>Who'er yields properly to Fate is deemed Wise among men, and knows the laws of Heaven.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361714</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(And, this, third, :, ')</td>\n",
              "      <td>And this third: '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361715</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(O, Crito, ,, if, it, thus, pleases, the, gods, ,, thus, let, it, be, ., ', ')</td>\n",
              "      <td>O Crito, if it thus pleases the gods, thus let it be.' '</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361716</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(Anytus, and, Melitus, may, kill, me, indeed, ;, but, hurt, me, they, can, not, ., ')</td>\n",
              "      <td>Anytus and Melitus may kill me indeed; but hurt me they cannot.'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>335 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              title  ...                                                                                                                                      sentence_str\n",
              "361382  Enchiridion  ...                                                     There are things which are within our power, and there are things which are beyond our power.\n",
              "361383  Enchiridion  ...                                              Within our power are opinion, aim, desire, aversion, and, in one word, whatever affairs are our own.\n",
              "361384  Enchiridion  ...                             Beyond our power are body, property, reputation, office, and, in one word, whatever are not properly our own affairs.\n",
              "361385  Enchiridion  ...  Now the things within our power are by nature free, unrestricted, unhindered; but those beyond our power are weak, dependent, restricted, alien.\n",
              "361386  Enchiridion  ...    Remember, then, that if you attribute freedom to things by nature dependent and take what belongs to others for your own, you will be hindered\n",
              "...             ...  ...                                                                                                                                               ...\n",
              "361712  Enchiridion  ...                                                                    I follow cheerfully; and, did I not, Wicked and wretched, I must follow still.\n",
              "361713  Enchiridion  ...                                                            Who'er yields properly to Fate is deemed Wise among men, and knows the laws of Heaven.\n",
              "361714  Enchiridion  ...                                                                                                                                 And this third: '\n",
              "361715  Enchiridion  ...                                                                                          O Crito, if it thus pleases the gods, thus let it be.' '\n",
              "361716  Enchiridion  ...                                                                                  Anytus and Melitus may kill me indeed; but hurt me they cannot.'\n",
              "\n",
              "[335 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsIOtvZsMkdx"
      },
      "source": [
        "### Cleaning the Dataframe "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zuTIcCizMweb"
      },
      "source": [
        "But before the fun stuff, to ensure that we get good results, we need to clean the dataframe. This will take a few steps:\r\n",
        "1. Determine a threshold length and cut the (so-called) sentences that are shorter than that length (this will already eliminate meaningless duplicates like punctuations)\r\n",
        "2. Check for words that indicate footnotes (words like 'edition' or 'ibid'); we can then cut these sentences from the data\r\n",
        "3. Check for duplicates; there should be few if any duplicates in the dataframe for each school\r\n",
        "4. Check for words that indicate other languages so that we can eliminate quotations, citations, or other non-English sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI3KwHHVM8ck"
      },
      "source": [
        "#### 1. Deal with Short Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "LLkVXKfIwcup",
        "outputId": "44a8a878-0781-4e3d-c0af-7d1f65852e55"
      },
      "source": [
        "df['sentence_length'] = df['sentence_str'].map(lambda x: len(x))\r\n",
        "num_of_short_entries = len(df[df['sentence_length'] < 20])\r\n",
        "print(f\"there are {num_of_short_entries} so-called sentences with fewer than 20 characters\")\r\n",
        "df[df['sentence_length'] < 20].sample(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "there are 29984 so-called sentences with fewer than 20 characters\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>361705</th>\n",
              "      <td>Enchiridion</td>\n",
              "      <td>Epictetus</td>\n",
              "      <td>stoicism</td>\n",
              "      <td>(What, falsehood, ?)</td>\n",
              "      <td>What falsehood?</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34980</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>(He, will, .)</td>\n",
              "      <td>He will.</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355671</th>\n",
              "      <td>On The Principles Of Political Economy And Taxation</td>\n",
              "      <td>Ricardo</td>\n",
              "      <td>capitalism</td>\n",
              "      <td>(per, qr, .)</td>\n",
              "      <td>per qr.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323882</th>\n",
              "      <td>Capital</td>\n",
              "      <td>Marx</td>\n",
              "      <td>communism</td>\n",
              "      <td>(sq, ., ), .)</td>\n",
              "      <td>sq.).</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17878</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>(this, is, why, .)</td>\n",
              "      <td>this is why.</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      title  ... sentence_length\n",
              "361705                                          Enchiridion  ...              15\n",
              "34980                                Plato - Complete Works  ...               8\n",
              "355671  On The Principles Of Political Economy And Taxation  ...               7\n",
              "323882                                              Capital  ...               5\n",
              "17878                                Plato - Complete Works  ...              12\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FOolcqOwcgz",
        "outputId": "32add1f6-1ab8-4d8d-a695-3c678091dd55"
      },
      "source": [
        "df = df.drop(df[df['sentence_length'] < 20].index)\r\n",
        "len(df)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "331733"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaxL3byaM-RA"
      },
      "source": [
        "#### 2. Look at Words that Indicate Footnotes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRM_W5p3wbkE",
        "outputId": "84afbe73-310e-473d-8168-bc52bf664920"
      },
      "source": [
        "fn_words = ['ch\\.', 'bk', 'sect\\.', 'div\\.', 'cf', 'ibid', 'prop\\.', 'Q\\.E\\.D\\.',\r\n",
        "            'pt\\.', 'coroll\\.', 'cf\\.']\r\n",
        "\r\n",
        "df['sentence_lowered'] = df['sentence_str'].map(lambda x: x.lower())\r\n",
        "\r\n",
        "fn_df = pd.DataFrame()\r\n",
        "for word in fn_words:\r\n",
        "  found_word = df[df['sentence_lowered'].str.contains('\\s' + word.lower())].copy()\r\n",
        "  found_word['word'] = word\r\n",
        "  fn_df = fn_df.append(found_word)\r\n",
        "\r\n",
        "len(fn_df)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "705"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "PyjxVFLmwirp",
        "outputId": "60125388-efa7-4ca7-b6b1-e3df563bb345"
      },
      "source": [
        "fn_df.sample(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>word</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>298099</th>\n",
              "      <td>Science Of Logic</td>\n",
              "      <td>Hegel</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(It, contains, the, following, basic, thoughts, :, because, God, includes, within, itself, all, eternal, truths, ,, the, Cf, .)</td>\n",
              "      <td>It contains the following basic thoughts: because God includes within itself all eternal truths, the Cf.</td>\n",
              "      <td>104</td>\n",
              "      <td>it contains the following basic thoughts: because god includes within itself all eternal truths, the cf.</td>\n",
              "      <td>cf\\.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113204</th>\n",
              "      <td>A Treatise Of Human Nature</td>\n",
              "      <td>Hume</td>\n",
              "      <td>empiricism</td>\n",
              "      <td>(This, is, true, in, general, ;, though, we, shall, find, Part, Sect, .)</td>\n",
              "      <td>This is true in general; though we shall find Part Sect.</td>\n",
              "      <td>56</td>\n",
              "      <td>this is true in general; though we shall find part sect.</td>\n",
              "      <td>sect\\.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300906</th>\n",
              "      <td>Science Of Logic</td>\n",
              "      <td>Hegel</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(On, this, side, of, exclusive, relating, ,, numbers, have, lost, their, continuity, and, their, tendency, to, combine, ;, their, relating, is, one, of, more, Cf, .)</td>\n",
              "      <td>On this side of exclusive relating, numbers have lost their continuity and their tendency to combine; their relating is one of more Cf.</td>\n",
              "      <td>135</td>\n",
              "      <td>on this side of exclusive relating, numbers have lost their continuity and their tendency to combine; their relating is one of more cf.</td>\n",
              "      <td>cf\\.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123273</th>\n",
              "      <td>Ethics</td>\n",
              "      <td>Spinoza</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>(substance, absolutely, infinite, could, cease, to, exist, ,, which, (, by, Prop, ., xi, ., ), is, also, absurd, .)</td>\n",
              "      <td>substance absolutely infinite could cease to exist, which (by Prop. xi.) is also absurd.</td>\n",
              "      <td>88</td>\n",
              "      <td>substance absolutely infinite could cease to exist, which (by prop. xi.) is also absurd.</td>\n",
              "      <td>prop\\.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123435</th>\n",
              "      <td>Ethics</td>\n",
              "      <td>Spinoza</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>(necessarily, exists, ,, that, is, (, by, Prop, ., vii, ., ))</td>\n",
              "      <td>necessarily exists, that is (by Prop. vii.)</td>\n",
              "      <td>43</td>\n",
              "      <td>necessarily exists, that is (by prop. vii.)</td>\n",
              "      <td>prop\\.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             title  ...    word\n",
              "298099            Science Of Logic  ...    cf\\.\n",
              "113204  A Treatise Of Human Nature  ...  sect\\.\n",
              "300906            Science Of Logic  ...    cf\\.\n",
              "123273                      Ethics  ...  prop\\.\n",
              "123435                      Ethics  ...  prop\\.\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MqiX6cbVNDPw"
      },
      "source": [
        "Unfortunately, there was too much noise and too many differences in how the sentences were tokenized, so this kind of cleaning did not prove useful. As can be seen above, many of the relevant terms were used in meaningful sentences attributable to the correct authors. \r\n",
        "\r\n",
        "We were able to tell that 'bk.' was almost never used productively, so we cut that. For others, this was instructive in helping us clean the text and making revisions to the baseline cleaning function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2NY8j7Ewj1Q",
        "outputId": "29fd4639-a750-4314-e76e-e695f591cbaf"
      },
      "source": [
        "df = df.drop(df[df['sentence_lowered'].str.contains('\\s+bk'.lower())].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "331711"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEqfL_K_NE7C"
      },
      "source": [
        "#### 3. Look at cases of Self-Mention by Authors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7fhKsiFwj8K",
        "outputId": "88a6e9e3-0642-4182-eec3-4c94f41aed87"
      },
      "source": [
        "self_mention_df = pd.DataFrame()\r\n",
        "for author in df['author'].unique():\r\n",
        "  self_mention_slice = df[(df['author'] == author) & \r\n",
        "                          (df['sentence_lowered'].str.contains('\\s'+author.lower()))].copy()\r\n",
        "  self_mention_df = self_mention_df.append(self_mention_slice)\r\n",
        "\r\n",
        "len(self_mention_df)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "853"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "0GFzGEz_wkFt",
        "outputId": "38bfc2a3-ea33-43c5-d318-61441fba7793"
      },
      "source": [
        "self_mention_df.sample(5)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>297661</th>\n",
              "      <td>Science Of Logic</td>\n",
              "      <td>Hegel</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(This, connection, between, ', finite, ', and, ', end, ', is, clear, in, the, German, ,, endlich, ,, Endlichkeit, ,, Ende, ,, and, Hegel, plays, on, it, .)</td>\n",
              "      <td>This connection between 'finite' and 'end' is clear in the German, endlich, Endlichkeit, Ende, and Hegel plays on it.</td>\n",
              "      <td>117</td>\n",
              "      <td>this connection between 'finite' and 'end' is clear in the german, endlich, endlichkeit, ende, and hegel plays on it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341126</th>\n",
              "      <td>Essential Works Of Lenin</td>\n",
              "      <td>Lenin</td>\n",
              "      <td>communism</td>\n",
              "      <td>(According, to, Lenin, ,, Leninists, can, not, participate, in, democracy, for, any, purpose, other, than, to, destroy, it, .)</td>\n",
              "      <td>According to Lenin, Leninists cannot participate in democracy for any purpose other than to destroy it.</td>\n",
              "      <td>103</td>\n",
              "      <td>according to lenin, leninists cannot participate in democracy for any purpose other than to destroy it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28691</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>(Might, the, author, even, be, Plato, himself, ?)</td>\n",
              "      <td>Might the author even be Plato himself?</td>\n",
              "      <td>39</td>\n",
              "      <td>might the author even be plato himself?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236405</th>\n",
              "      <td>Anti-Oedipus</td>\n",
              "      <td>Deleuze</td>\n",
              "      <td>continental</td>\n",
              "      <td>(For, Oedipus, is, not, a, mere, psychoanalytic, construct, ,, Deleuze, and, Guattari, explain, .)</td>\n",
              "      <td>For Oedipus is not a mere psychoanalytic construct, Deleuze and Guattari explain.</td>\n",
              "      <td>81</td>\n",
              "      <td>for oedipus is not a mere psychoanalytic construct, deleuze and guattari explain.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196708</th>\n",
              "      <td>Philosophical Troubles</td>\n",
              "      <td>Kripke</td>\n",
              "      <td>analytic</td>\n",
              "      <td>(Perhaps, ,, it, would, have, been, neither, true, nor, false, ,, in, such, a, world, ,, to, say, that, Saul, Kripke, is, self, identical, .)</td>\n",
              "      <td>Perhaps, it would have been neither true nor false, in such a world, to say that Saul Kripke is self identical.</td>\n",
              "      <td>111</td>\n",
              "      <td>perhaps, it would have been neither true nor false, in such a world, to say that saul kripke is self identical.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           title  ...                                                                                                       sentence_lowered\n",
              "297661          Science Of Logic  ...  this connection between 'finite' and 'end' is clear in the german, endlich, endlichkeit, ende, and hegel plays on it.\n",
              "341126  Essential Works Of Lenin  ...                according to lenin, leninists cannot participate in democracy for any purpose other than to destroy it.\n",
              "28691     Plato - Complete Works  ...                                                                                might the author even be plato himself?\n",
              "236405              Anti-Oedipus  ...                                      for oedipus is not a mere psychoanalytic construct, deleuze and guattari explain.\n",
              "196708    Philosophical Troubles  ...        perhaps, it would have been neither true nor false, in such a world, to say that saul kripke is self identical.\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vxUnQkTwkNo",
        "outputId": "2522810f-5db8-46e7-905c-014dd38a9834"
      },
      "source": [
        "for author in df['author'].unique():\r\n",
        "  df = df.drop(df[(df['author'] == author) & \r\n",
        "                  (df['sentence_lowered'].str.contains('\\s'+author.lower()))].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "330858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMxaZemLNKeH"
      },
      "source": [
        "#### 4. Deal with Duplicates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzOcjqfYwkU4",
        "outputId": "bc0b8d52-30ad-4e0e-d2ee-b62f8f34f87d"
      },
      "source": [
        "# find the total number of duplicates\r\n",
        "len(df['sentence_str'])-len(df['sentence_str'].drop_duplicates())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4691"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtY8ZrQawvZC",
        "outputId": "3cc70643-a2a1-4f49-c725-a1239d6e5430"
      },
      "source": [
        "# get the number of duplicates in each school\r\n",
        "for school in df['school'].unique():\r\n",
        "  print(school)\r\n",
        "  print(len(df.loc[df['school'] == school]['sentence_str']) - \r\n",
        "        len(df.loc[df['school'] == school]['sentence_str'].drop_duplicates()))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "plato\n",
            "291\n",
            "aristotle\n",
            "3351\n",
            "empiricism\n",
            "14\n",
            "rationalism\n",
            "39\n",
            "analytic\n",
            "289\n",
            "continental\n",
            "97\n",
            "phenomenology\n",
            "87\n",
            "german_idealism\n",
            "287\n",
            "communism\n",
            "84\n",
            "capitalism\n",
            "92\n",
            "stoicism\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "juwoWPstwvgf",
        "outputId": "3b9c6579-fade-4d2b-b7ec-823232f90be8"
      },
      "source": [
        "doubles_df = pd.concat(g for _, g in df.groupby(\"sentence_str\") if len(g) > 1)\r\n",
        "doubles_df.sample(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>33318</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>(That, 's, completely, true, .)</td>\n",
              "      <td>That's completely true.</td>\n",
              "      <td>23</td>\n",
              "      <td>that's completely true.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97817</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(Mure, 's, version, has, been, replaced, by, that, of, .)</td>\n",
              "      <td>Mure's version has been replaced by that of.</td>\n",
              "      <td>44</td>\n",
              "      <td>mure's version has been replaced by that of.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97301</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(The, Oxford, Translation, was, to, remain, in, substance, its, original, self, ;, but, alterations, were, to, be, made, ,, where, advisable, ,, in, the, light, of, recent, scholarship, and, with,...</td>\n",
              "      <td>The Oxford Translation was to remain in substance its original self; but alterations were to be made, where advisable, in the light of recent scholarship and with the requirements of modern reader...</td>\n",
              "      <td>206</td>\n",
              "      <td>the oxford translation was to remain in substance its original self; but alterations were to be made, where advisable, in the light of recent scholarship and with the requirements of modern reader...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63813</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(In, those, places, where, the, translation, deviates, from, the, chosen, text, and, prefers, a, different, reading, in, the, Greek, ,, a, footnote, marks, the, fact, and, indicates, which, readin...</td>\n",
              "      <td>In those places where the translation deviates from the chosen text and prefers a different reading in the Greek, a footnote marks the fact and indicates which reading is preferred; such places ar...</td>\n",
              "      <td>203</td>\n",
              "      <td>in those places where the translation deviates from the chosen text and prefers a different reading in the greek, a footnote marks the fact and indicates which reading is preferred; such places ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75284</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(In, a, codicil, to, the, will, ,, appended, less, than, a, month, before, his, death, ,, he, expressed, the, hope, that, ', the, translation, of, may, be, finished, as, soon, as, possible, ., ')</td>\n",
              "      <td>In a codicil to the will, appended less than a month before his death, he expressed the hope that 'the translation of may be finished as soon as possible.'</td>\n",
              "      <td>155</td>\n",
              "      <td>in a codicil to the will, appended less than a month before his death, he expressed the hope that 'the translation of may be finished as soon as possible.'</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            title  ...                                                                                                                                                                                         sentence_lowered\n",
              "33318      Plato - Complete Works  ...                                                                                                                                                                                  that's completely true.\n",
              "97817  Aristotle - Complete Works  ...                                                                                                                                                             mure's version has been replaced by that of.\n",
              "97301  Aristotle - Complete Works  ...  the oxford translation was to remain in substance its original self; but alterations were to be made, where advisable, in the light of recent scholarship and with the requirements of modern reader...\n",
              "63813  Aristotle - Complete Works  ...  in those places where the translation deviates from the chosen text and prefers a different reading in the greek, a footnote marks the fact and indicates which reading is preferred; such places ar...\n",
              "75284  Aristotle - Complete Works  ...                                              in a codicil to the will, appended less than a month before his death, he expressed the hope that 'the translation of may be finished as soon as possible.'\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83xx0eHWNOX3"
      },
      "source": [
        "From this it is clear that many of these duplicates are notes, meaninglessly short, or else headings that somehow escaped earlier efforts. Oddly, an enormous number of Aristotle's sentences seem to be doubled. Looking at the doubled sentences, this appears to be because similar notes were made in both of the two volumes of the text. \r\n",
        "\r\n",
        "Let's eliminate the aristotle doubles first, then take another look to see what the others are like. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71OS1WlbwvqV",
        "outputId": "2b689afc-920d-4870-80b0-3b624f5bdd3c"
      },
      "source": [
        "len(doubles_df[doubles_df['author'] != 'Aristotle'])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2164"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "kotnwwvFwvy1",
        "outputId": "347e3c48-41f8-4fda-d26c-288b678a6ae1"
      },
      "source": [
        "doubles_df[doubles_df['author'] != 'Aristole'].sample(5)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>219947</th>\n",
              "      <td>The Order Of Things</td>\n",
              "      <td>Foucault</td>\n",
              "      <td>continental</td>\n",
              "      <td>(The, fire, which, I, see, is, not, the, cause, of, the, pain, I, suffer, upon, my, approaching, it, ,, but, the, mark, that, forewarns, me, of, it, .)</td>\n",
              "      <td>The fire which I see is not the cause of the pain I suffer upon my approaching it, but the mark that forewarns me of it.</td>\n",
              "      <td>120</td>\n",
              "      <td>the fire which i see is not the cause of the pain i suffer upon my approaching it, but the mark that forewarns me of it.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88603</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(Thus, a, ', marks, column, one, of, page, of, Bekker, 's, edition, ;, and, the, following, ,, ', ,, ', ,, ', etc, .)</td>\n",
              "      <td>Thus a' marks column one of page of Bekker's edition; and the following ,' ,' ,' etc.</td>\n",
              "      <td>85</td>\n",
              "      <td>thus a' marks column one of page of bekker's edition; and the following ,' ,' ,' etc.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48626</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(The, Complete, Works, of, Electronic, markup, by, Jamie, .)</td>\n",
              "      <td>The Complete Works of Electronic markup by Jamie.</td>\n",
              "      <td>49</td>\n",
              "      <td>the complete works of electronic markup by jamie.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100652</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(The, title, page, of, each, work, contains, a, reference, to, the, edition, of, the, Greek, text, against, which, the, translation, has, been, checked, .)</td>\n",
              "      <td>The title page of each work contains a reference to the edition of the Greek text against which the translation has been checked.</td>\n",
              "      <td>129</td>\n",
              "      <td>the title page of each work contains a reference to the edition of the greek text against which the translation has been checked.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58487</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(Ross, ,, a, Fellow, of, Oriel, College, ,, were, appointed, as, general, editors, to, supervise, the, project, of, translating, all, of, 's, writings, into, English, ;, and, the, College, came, t...</td>\n",
              "      <td>Ross, a Fellow of Oriel College, were appointed as general editors to supervise the project of translating all of 's writings into English; and the College came to an agreement with the Delegates ...</td>\n",
              "      <td>251</td>\n",
              "      <td>ross, a fellow of oriel college, were appointed as general editors to supervise the project of translating all of 's writings into english; and the college came to an agreement with the delegates ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             title  ...                                                                                                                                                                                         sentence_lowered\n",
              "219947         The Order Of Things  ...                                                                                 the fire which i see is not the cause of the pain i suffer upon my approaching it, but the mark that forewarns me of it.\n",
              "88603   Aristotle - Complete Works  ...                                                                                                                    thus a' marks column one of page of bekker's edition; and the following ,' ,' ,' etc.\n",
              "48626   Aristotle - Complete Works  ...                                                                                                                                                        the complete works of electronic markup by jamie.\n",
              "100652  Aristotle - Complete Works  ...                                                                        the title page of each work contains a reference to the edition of the greek text against which the translation has been checked.\n",
              "58487   Aristotle - Complete Works  ...  ross, a fellow of oriel college, were appointed as general editors to supervise the project of translating all of 's writings into english; and the college came to an agreement with the delegates ...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSzTX0yNNV-K"
      },
      "source": [
        "Deeper exploration of the duplicates reveals that Kant has a lot of doubles that seem to be authentically from his texts. Plato also has several duplicate sentences, but these are almost all short phrases from the dialogues ('of course, yes' and that kind of thing). \r\n",
        "\r\n",
        "To preserve the Kant, while also removing the irrelevant duplicates, we will remove both copies of all duplicates from texts other than the Kant's *Critique of Pure Reason*. For that text, we will remove the short duplicates and keep one copy of the longer ones, thus preserving the meaningful sentences. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qe5D6a2qwv7f",
        "outputId": "0f182fa0-b8b9-4dc6-f196-a45f4e6b37c7"
      },
      "source": [
        "non_kant_indexes = df[(df['title'] != 'critique of pure reason') & \r\n",
        "                       (df['sentence_str'].duplicated(keep=False))].index\r\n",
        "kant_short_indexes = df[(df['title'] == 'critique of pure reason') &\r\n",
        "                        (df['sentence_str'].duplicated(keep=False)) &\r\n",
        "                        (df['sentence_length'] < 40)].index\r\n",
        "kant_long_indexes = df[(df['title'] == 'critique of pure reason') &\r\n",
        "                        (df['sentence_str'].duplicated(keep='first')) &\r\n",
        "                        (df['sentence_length'] >= 40)].index\r\n",
        "\r\n",
        "indexes_to_drop = [non_kant_indexes, kant_short_indexes, kant_long_indexes]\r\n",
        "for index in indexes_to_drop:\r\n",
        "  df = df.drop(index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "325140"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "GnNdnY0MwwFM",
        "outputId": "51086021-fb73-4b4c-8737-bf1eb4d87639"
      },
      "source": [
        "(df[df['sentence_str'].str.contains('\\sder\\s')]).sample(5)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324352</th>\n",
              "      <td>Capital</td>\n",
              "      <td>Marx</td>\n",
              "      <td>communism</td>\n",
              "      <td>(See, Roscher, 's, Die, Grundlagen, der, National, konomie, ,, Dritte, Auflage, ,, .)</td>\n",
              "      <td>See Roscher's Die Grundlagen der National konomie, Dritte Auflage, .</td>\n",
              "      <td>68</td>\n",
              "      <td>see roscher's die grundlagen der national konomie, dritte auflage, .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275879</th>\n",
              "      <td>Critique Of Practical Reason</td>\n",
              "      <td>Kant</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(Ak., der, Mensch, ;, ', being,'below, ,, translates, Wesen, .)</td>\n",
              "      <td>Ak. der Mensch; 'being,'below, translates Wesen.</td>\n",
              "      <td>48</td>\n",
              "      <td>ak. der mensch; 'being,'below, translates wesen.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244114</th>\n",
              "      <td>The Phenomenology Of Perception</td>\n",
              "      <td>Merleau-Ponty</td>\n",
              "      <td>phenomenology</td>\n",
              "      <td>(Scheler, ,, Der, Formalismus, in, der, Ethik, ,, .)</td>\n",
              "      <td>Scheler, Der Formalismus in der Ethik,.</td>\n",
              "      <td>39</td>\n",
              "      <td>scheler, der formalismus in der ethik,.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320029</th>\n",
              "      <td>Elements Of The Philosophy Of Right</td>\n",
              "      <td>Hegel</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(The, individual, der, Einzeble, must, certainly, have, a, right, to, earn, his, living, in, this, way, or, that, ;)</td>\n",
              "      <td>The individual der Einzeble must certainly have a right to earn his living in this way or that;</td>\n",
              "      <td>95</td>\n",
              "      <td>the individual der einzeble must certainly have a right to earn his living in this way or that;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284310</th>\n",
              "      <td>Critique Of Pure Reason</td>\n",
              "      <td>Kant</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(Ursache, und, der, Causalitiit)</td>\n",
              "      <td>Ursache und der Causalitiit</td>\n",
              "      <td>27</td>\n",
              "      <td>ursache und der causalitiit</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      title  ...                                                                                 sentence_lowered\n",
              "324352                              Capital  ...                             see roscher's die grundlagen der national konomie, dritte auflage, .\n",
              "275879         Critique Of Practical Reason  ...                                                 ak. der mensch; 'being,'below, translates wesen.\n",
              "244114      The Phenomenology Of Perception  ...                                                          scheler, der formalismus in der ethik,.\n",
              "320029  Elements Of The Philosophy Of Right  ...  the individual der einzeble must certainly have a right to earn his living in this way or that;\n",
              "284310              Critique Of Pure Reason  ...                                                                      ursache und der causalitiit\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcdlnijMNaMA"
      },
      "source": [
        "#### Check for Foreign-Language Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXUfIsqkwwOY",
        "outputId": "df280822-f929-4bc4-f906-4ea9df16a946"
      },
      "source": [
        "# checking for 'der', a common article in German\r\n",
        "len((df[df['sentence_str'].str.contains('\\sder\\s')]))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "314"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sds3G-P8w-KH",
        "outputId": "1a488411-18af-498c-9b0d-4669daf4c66b"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].str.contains('\\sder\\s')].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324826"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "nsz9L0qCw-UM",
        "outputId": "f2f51898-0d5d-4210-a789-48fc66165427"
      },
      "source": [
        "# checking for 'il', a common article in French\r\n",
        "df[df['sentence_str'].str.contains('\\sil\\s')].sample(5)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>324084</th>\n",
              "      <td>Capital</td>\n",
              "      <td>Marx</td>\n",
              "      <td>communism</td>\n",
              "      <td>(Si, l'on, gagnait, longtemps, en, tout, avec, tous, ,, il, faudrait, rendre, de, bon, accord, les, plus, grandes, parties)</td>\n",
              "      <td>Si l'on gagnait longtemps en tout avec tous, il faudrait rendre de bon accord les plus grandes parties</td>\n",
              "      <td>102</td>\n",
              "      <td>si l'on gagnait longtemps en tout avec tous, il faudrait rendre de bon accord les plus grandes parties</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335587</th>\n",
              "      <td>Capital</td>\n",
              "      <td>Marx</td>\n",
              "      <td>communism</td>\n",
              "      <td>(Les, nations, pauvres, ,, c'est, le, peuple, est, son, aise, ;, et, les, nations, riches, ,, c'est, il, est, ordinairement, pauvre, .)</td>\n",
              "      <td>Les nations pauvres, c'est le peuple est son aise; et les nations riches, c'est il est ordinairement pauvre.</td>\n",
              "      <td>108</td>\n",
              "      <td>les nations pauvres, c'est le peuple est son aise; et les nations riches, c'est il est ordinairement pauvre.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268514</th>\n",
              "      <td>Off The Beaten Track</td>\n",
              "      <td>Heidegger</td>\n",
              "      <td>phenomenology</td>\n",
              "      <td>(Of, all, things, (, those, ,, namely, ,, that, man, has, around, him, in, use, and, usage, ,, il, .lcrra)</td>\n",
              "      <td>Of all things (those, namely, that man has around him in use and usage, il .lcrra</td>\n",
              "      <td>81</td>\n",
              "      <td>of all things (those, namely, that man has around him in use and usage, il .lcrra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132917</th>\n",
              "      <td>Theodicy</td>\n",
              "      <td>Leibniz</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>(lor, moto, sempre, Insieme, s'aggruppa, ,, dall, ', antico, Sempre, con, ordin, certo, il, nuovo, nasce, ;, Ne, tracciando, primi, semi, ,, fanno, Di, moto, un, tal, principio, ,, il, qual, poi, ...</td>\n",
              "      <td>lor moto sempre Insieme s'aggruppa, dall' antico Sempre con ordin certo il nuovo nasce; Ne tracciando primi semi, fanno Di moto un tal principio, il qual poi rompa I decreti del fato, acci non seg...</td>\n",
              "      <td>330</td>\n",
              "      <td>lor moto sempre insieme s'aggruppa, dall' antico sempre con ordin certo il nuovo nasce; ne tracciando primi semi, fanno di moto un tal principio, il qual poi rompa i decreti del fato, acci non seg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270169</th>\n",
              "      <td>Off The Beaten Track</td>\n",
              "      <td>Heidegger</td>\n",
              "      <td>phenomenology</td>\n",
              "      <td>(Aristotle, characterizes, the, contem, plation, of, beings, as, beings, as, hna, il, a, way, in, which, our, seeing, and, perceiving, stands, by, ,, that, is, ,, stands, by, what, is, present, as...</td>\n",
              "      <td>Aristotle characterizes the contem plation of beings as beings as hna il a way in which our seeing and perceiving stands by, that is, stands by what is present as such.</td>\n",
              "      <td>168</td>\n",
              "      <td>aristotle characterizes the contem plation of beings as beings as hna il a way in which our seeing and perceiving stands by, that is, stands by what is present as such.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       title  ...                                                                                                                                                                                         sentence_lowered\n",
              "324084               Capital  ...                                                                                                   si l'on gagnait longtemps en tout avec tous, il faudrait rendre de bon accord les plus grandes parties\n",
              "335587               Capital  ...                                                                                             les nations pauvres, c'est le peuple est son aise; et les nations riches, c'est il est ordinairement pauvre.\n",
              "268514  Off The Beaten Track  ...                                                                                                                        of all things (those, namely, that man has around him in use and usage, il .lcrra\n",
              "132917              Theodicy  ...  lor moto sempre insieme s'aggruppa, dall' antico sempre con ordin certo il nuovo nasce; ne tracciando primi semi, fanno di moto un tal principio, il qual poi rompa i decreti del fato, acci non seg...\n",
              "270169  Off The Beaten Track  ...                                 aristotle characterizes the contem plation of beings as beings as hna il a way in which our seeing and perceiving stands by, that is, stands by what is present as such.\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ER9muOkw-qu",
        "outputId": "2323ea24-12be-4f32-ba6b-9f0fa3d2b6b9"
      },
      "source": [
        "df = df.drop(df[df['sentence_str'].str.contains('\\sil\\s')].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324778"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jsR1QpNNlNJ"
      },
      "source": [
        "#### Some Ad Hoc Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1sF0lzxw-zd",
        "outputId": "85c1b515-b7c5-4f61-f39f-7a8ed3ada971"
      },
      "source": [
        "# miscellaneous nonsense sentences\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\spp\\s')].index)\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\stotam\\s')].index)\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\srree\\s')].index)\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sflir\\s')].index)\r\n",
        "df = df.drop(df[(df['sentence_str'].str.contains('\\smodis\\s')) & (df['author'] != 'Kant')].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324772"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqBnHZG6w-9F",
        "outputId": "6b8c77e1-b241-41af-deca-41da842fcac0"
      },
      "source": [
        "# markers of french and notes\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\schapitre')].index)\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\salisme')].index)\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sHahn')].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324755"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oq5I3pL4w9r7",
        "outputId": "934308b6-7bff-4b10-aecd-299b6fa86a7d"
      },
      "source": [
        "# some notes in Kant\r\n",
        "df = df.drop(df[df['sentence_str'].str.contains('\\sVorl\\s')].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324737"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3nv5S4exJXK",
        "outputId": "c0135b5d-db64-44d0-b4ae-910a2b629743"
      },
      "source": [
        "# a common phrase in Plato / Aristotle footnotes\r\n",
        "df = df.drop(df[(df['author']=='Plato') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\r\n",
        "df = df.drop(df[(df['author']=='Aristotle') & (df['sentence_str'].str.contains('(?i)reading')) & (df['sentence_length'] < 40)].index)\r\n",
        "\r\n",
        "len(df)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "324463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtli1TPlNq55"
      },
      "source": [
        "### Lemmatizing, Tokenizing, and Exporting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybCPk5oixJgd",
        "outputId": "bcb50ca3-47f5-4187-dc20-29012c579594"
      },
      "source": [
        "df['school'].value_counts(normalize=True)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "analytic           0.164718\n",
              "aristotle          0.150338\n",
              "german_idealism    0.129867\n",
              "plato              0.118322\n",
              "continental        0.104114\n",
              "phenomenology      0.088062\n",
              "rationalism        0.070732\n",
              "empiricism         0.061428\n",
              "capitalism         0.056074\n",
              "communism          0.055350\n",
              "stoicism           0.000995\n",
              "Name: school, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1wT-MvpxJot"
      },
      "source": [
        "from gensim.utils import simple_preprocess\r\n",
        "\r\n",
        "# use gensim to tokenize sentences\r\n",
        "df['tokenized_txt'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\r\n",
        "                                                        max_len=200))\r\n",
        "\r\n",
        "# use spacey to get intelligent lemmatization\r\n",
        "def lemmatize_sentence(sentence):\r\n",
        "  lemmatized_txt = ''\r\n",
        "  for word in sentence:\r\n",
        "    lemmatized_txt += ' ' + str(word.lemma_)\r\n",
        "  return lemmatized_txt"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O3mXZKkxJxM"
      },
      "source": [
        "df['lemmatized_str'] = df['sentence_spacy'].apply(lemmatize_sentence)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 849
        },
        "id": "mxmcq_BQxJ48",
        "outputId": "8cc6b3db-84be-4f30-faf6-f7e2ef107f35"
      },
      "source": [
        "df.sample(5)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>84534</th>\n",
              "      <td>Aristotle - Complete Works</td>\n",
              "      <td>Aristotle</td>\n",
              "      <td>aristotle</td>\n",
              "      <td>(For, since, there, is, no, smallest, body, ,, every, part, is, mixed, with, every, other, part, ,, just, as, the, whole, is, mixed, .)</td>\n",
              "      <td>For since there is no smallest body, every part is mixed with every other part, just as the whole is mixed.</td>\n",
              "      <td>107</td>\n",
              "      <td>for since there is no smallest body, every part is mixed with every other part, just as the whole is mixed.</td>\n",
              "      <td>[for, since, there, is, no, smallest, body, every, part, is, mixed, with, every, other, part, just, as, the, whole, is, mixed]</td>\n",
              "      <td>for since there be no small body , every part be mix with every other part , just as the whole be mixed .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287940</th>\n",
              "      <td>Critique Of Pure Reason</td>\n",
              "      <td>Kant</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>(Thus, I, can, not, infer, from, its, magnitude, to, the, magnitude, of, the, regress, ,, and, determine, the, latter, according, to, the, for, This, world, series, ', can, thus, be, neither, bigg...</td>\n",
              "      <td>Thus I cannot infer from its magnitude to the magnitude of the regress, and determine the latter according to the for This world series' can thus be neither bigger nor smaller than the possible em...</td>\n",
              "      <td>246</td>\n",
              "      <td>thus i cannot infer from its magnitude to the magnitude of the regress, and determine the latter according to the for this world series' can thus be neither bigger nor smaller than the possible em...</td>\n",
              "      <td>[thus, cannot, infer, from, its, magnitude, to, the, magnitude, of, the, regress, and, determine, the, latter, according, to, the, for, this, world, series, can, thus, be, neither, bigger, nor, sm...</td>\n",
              "      <td>thus -PRON- can not infer from -PRON- magnitude to the magnitude of the regress , and determine the latter accord to the for this world series ' can thus be neither big nor small than the possibl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33443</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>(And, ,, as, you, 'd, expect, ,, some, of, the, carriers, are, talking, ,, and, some, are, silent, .)</td>\n",
              "      <td>And, as you'd expect, some of the carriers are talking, and some are silent.</td>\n",
              "      <td>76</td>\n",
              "      <td>and, as you'd expect, some of the carriers are talking, and some are silent.</td>\n",
              "      <td>[and, as, you, expect, some, of, the, carriers, are, talking, and, some, are, silent]</td>\n",
              "      <td>and , as -PRON- would expect , some of the carrier be talk , and some be silent .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237838</th>\n",
              "      <td>Anti-Oedipus</td>\n",
              "      <td>Deleuze</td>\n",
              "      <td>continental</td>\n",
              "      <td>(Or, is, it, the, confusion, of, the, process, with, a, goal, (, the, production, of, the, pervert, artifice, ), ,, or, the, premature, interruption, of, the, process, (, the, production, of, the,...</td>\n",
              "      <td>Or is it the confusion of the process with a goal (the production of the pervert artifice), or the premature interruption of the process (the production of the neurotic analysis)?</td>\n",
              "      <td>179</td>\n",
              "      <td>or is it the confusion of the process with a goal (the production of the pervert artifice), or the premature interruption of the process (the production of the neurotic analysis)?</td>\n",
              "      <td>[or, is, it, the, confusion, of, the, process, with, goal, the, production, of, the, pervert, artifice, or, the, premature, interruption, of, the, process, the, production, of, the, neurotic, anal...</td>\n",
              "      <td>or be -PRON- the confusion of the process with a goal ( the production of the pervert artifice ) , or the premature interruption of the process ( the production of the neurotic analysis ) ?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127999</th>\n",
              "      <td>On The Improvement Of Understanding</td>\n",
              "      <td>Spinoza</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>(In, order, to, bring, this, about, ,, it, is, necessary, to, understand, as, much, of, nature, as, will, enable, us, to, attain, to, the, aforesaid, character, ,, and, also, to, form, a, social, ...</td>\n",
              "      <td>In order to bring this about, it is necessary to understand as much of nature as will enable us to attain to the aforesaid character, and also to form a social order such as is most conducive to t...</td>\n",
              "      <td>288</td>\n",
              "      <td>in order to bring this about, it is necessary to understand as much of nature as will enable us to attain to the aforesaid character, and also to form a social order such as is most conducive to t...</td>\n",
              "      <td>[in, order, to, bring, this, about, it, is, necessary, to, understand, as, much, of, nature, as, will, enable, us, to, attain, to, the, aforesaid, character, and, also, to, form, social, order, su...</td>\n",
              "      <td>in order to bring this about , -PRON- be necessary to understand as much of nature as will enable -PRON- to attain to the aforesaid character , and also to form a social order such as be most con...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      title  ...                                                                                                                                                                                           lemmatized_str\n",
              "84534            Aristotle - Complete Works  ...                                                                                                for since there be no small body , every part be mix with every other part , just as the whole be mixed .\n",
              "287940              Critique Of Pure Reason  ...   thus -PRON- can not infer from -PRON- magnitude to the magnitude of the regress , and determine the latter accord to the for this world series ' can thus be neither big nor small than the possibl...\n",
              "33443                Plato - Complete Works  ...                                                                                                                        and , as -PRON- would expect , some of the carrier be talk , and some be silent .\n",
              "237838                         Anti-Oedipus  ...            or be -PRON- the confusion of the process with a goal ( the production of the pervert artifice ) , or the premature interruption of the process ( the production of the neurotic analysis ) ?\n",
              "127999  On The Improvement Of Understanding  ...   in order to bring this about , -PRON- be necessary to understand as much of nature as will enable -PRON- to attain to the aforesaid character , and also to form a social order such as be most con...\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlX3Aq4sx3QQ",
        "outputId": "79796dce-4c89-47c3-e671-5d34d1fa3bfb"
      },
      "source": [
        "# check the new author's presence\r\n",
        "len(df[df['author']=='Epictetus'])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "323"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeEVIBYZN64H"
      },
      "source": [
        "Now we can export the new CSV to use in other projects. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6v0M4jbUxKBt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "15c6f8e0-0812-4164-e84a-d604d3385aec"
      },
      "source": [
        "from google.colab import files\r\n",
        "df.to_csv('phil_nlp.csv', index=False) \r\n",
        "files.download('phil_nlp.csv')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_0fceaf5e-af2b-4d0e-92eb-360c2b95ba9a\", \"phil_nlp.csv\", 292499384)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}