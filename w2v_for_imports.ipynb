{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "w2v_for_imports.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "fRqjeaLlmZHe",
        "_7J7_WOz2VK8"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPKgyY6ddl4G0SNPGEF2vbg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kcalizadeh/PDP_data_processing/blob/master/w2v_for_imports.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrxG_6U1lGEa"
      },
      "source": [
        "### Imports and Mounting Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRT6BjwbiM8n",
        "outputId": "81cba416-fc2d-45a2-d554-7555e60ae8ab"
      },
      "source": [
        "# this cell mounts drive, sets the correct directory, then imports all functions\n",
        "# and relevant libraries via the functions.py file\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "\n",
        "drive_path = '/gdrive/MyDrive/Colab_Projects/philosophy_data_project'\n",
        "\n",
        "sys.path.append(drive_path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_FSrsN8l0J4"
      },
      "source": [
        "import pandas as pd\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Phrases\n",
        "from gensim.models.phrases import Phraser\n",
        "\n",
        "\n",
        "# a function for quickly testing w2v models\n",
        "def test_w2v(model, pairs):\n",
        "  for (pos, neg) in pairs:\n",
        "    math_result = model.most_similar(positive=pos, negative=neg)\n",
        "    print(f'Positive - {pos}\\tNegative - {neg}')\n",
        "    [print(f\"- {result[0]} ({round(result[1],5)})\") for result in math_result[:5]]\n",
        "    print()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fRqjeaLlmZHe"
      },
      "source": [
        "### Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "PHxy7346l3hZ",
        "outputId": "fc18e3a1-a33a-476a-e500-759e83e9853f"
      },
      "source": [
        "df = pd.read_csv('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/philosophy_data.csv')\n",
        "\n",
        "df.sample(5)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>author</th>\n",
              "      <th>school</th>\n",
              "      <th>sentence_spacy</th>\n",
              "      <th>sentence_str</th>\n",
              "      <th>original_publication_date</th>\n",
              "      <th>corpus_edition_date</th>\n",
              "      <th>sentence_length</th>\n",
              "      <th>sentence_lowered</th>\n",
              "      <th>tokenized_txt</th>\n",
              "      <th>lemmatized_str</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>95349</th>\n",
              "      <td>Essay Concerning Human Understanding</td>\n",
              "      <td>Locke</td>\n",
              "      <td>empiricism</td>\n",
              "      <td>Because the properties of such bodies, dependi...</td>\n",
              "      <td>Because the properties of such bodies, dependi...</td>\n",
              "      <td>1689</td>\n",
              "      <td>2004</td>\n",
              "      <td>360</td>\n",
              "      <td>because the properties of such bodies, dependi...</td>\n",
              "      <td>['because', 'the', 'properties', 'of', 'such',...</td>\n",
              "      <td>because the property of such body , depend no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25597</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>I mean those of whom the prosecutor of philoso...</td>\n",
              "      <td>I mean those of whom the prosecutor of philoso...</td>\n",
              "      <td>-350</td>\n",
              "      <td>1997</td>\n",
              "      <td>135</td>\n",
              "      <td>i mean those of whom the prosecutor of philoso...</td>\n",
              "      <td>['mean', 'those', 'of', 'whom', 'the', 'prosec...</td>\n",
              "      <td>-PRON- mean those of whom the prosecutor of p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16392</th>\n",
              "      <td>Plato - Complete Works</td>\n",
              "      <td>Plato</td>\n",
              "      <td>plato</td>\n",
              "      <td>Removing the brackets in and accepting the eme...</td>\n",
              "      <td>Removing the brackets in and accepting the eme...</td>\n",
              "      <td>-350</td>\n",
              "      <td>1997</td>\n",
              "      <td>71</td>\n",
              "      <td>removing the brackets in and accepting the eme...</td>\n",
              "      <td>['removing', 'the', 'brackets', 'in', 'and', '...</td>\n",
              "      <td>remove the bracket in and accept the emendati...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125545</th>\n",
              "      <td>The Search After Truth</td>\n",
              "      <td>Malebranche</td>\n",
              "      <td>rationalism</td>\n",
              "      <td>But we can reduce them all to two, namely, to ...</td>\n",
              "      <td>But we can reduce them all to two, namely, to ...</td>\n",
              "      <td>1674</td>\n",
              "      <td>1997</td>\n",
              "      <td>253</td>\n",
              "      <td>but we can reduce them all to two, namely, to ...</td>\n",
              "      <td>['but', 'we', 'can', 'reduce', 'them', 'all', ...</td>\n",
              "      <td>but -PRON- can reduce -PRON- all to two , nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253837</th>\n",
              "      <td>Critique Of Judgement</td>\n",
              "      <td>Kant</td>\n",
              "      <td>german_idealism</td>\n",
              "      <td>Consequently the concept of freedom, as the fu...</td>\n",
              "      <td>Consequently the concept of freedom, as the fu...</td>\n",
              "      <td>1790</td>\n",
              "      <td>2007</td>\n",
              "      <td>223</td>\n",
              "      <td>consequently the concept of freedom, as the fu...</td>\n",
              "      <td>['consequently', 'the', 'concept', 'of', 'free...</td>\n",
              "      <td>consequently the concept of freedom , as the ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       title  ...                                     lemmatized_str\n",
              "95349   Essay Concerning Human Understanding  ...   because the property of such body , depend no...\n",
              "25597                 Plato - Complete Works  ...   -PRON- mean those of whom the prosecutor of p...\n",
              "16392                 Plato - Complete Works  ...   remove the bracket in and accept the emendati...\n",
              "125545                The Search After Truth  ...   but -PRON- can reduce -PRON- all to two , nam...\n",
              "253837                 Critique Of Judgement  ...   consequently the concept of freedom , as the ...\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGHVsx7ZbrVj",
        "outputId": "b726938d-6892-469d-991c-ff96bbb053a8"
      },
      "source": [
        "df['school'].value_counts()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "analytic           55425\n",
              "aristotle          48779\n",
              "german_idealism    42136\n",
              "plato              38366\n",
              "continental        33779\n",
              "phenomenology      28573\n",
              "rationalism        22949\n",
              "empiricism         19931\n",
              "feminism           18635\n",
              "capitalism         18194\n",
              "communism          17958\n",
              "nietzsche          13548\n",
              "stoicism            2535\n",
              "Name: school, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR-d0hRI7hmQ"
      },
      "source": [
        "# using gensim's built-in tokenizer \n",
        "df['gensim_tokenized'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
        "                                                        max_len=100))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-mTBCSDojS1",
        "outputId": "4968a4f8-c958-4ddf-e8ab-436704f1902d"
      },
      "source": [
        "# check how it worked\n",
        "print(df.iloc[290646]['sentence_str'])\n",
        "df['gensim_tokenized'][290646]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The economic discoverers of this chemical element, who by the by lay special claim to critical acumen, find however that the use value of objects belongs to them independently of their material properties, while their value, on the other hand, forms a part of them as objects.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'economic',\n",
              " 'discoverers',\n",
              " 'of',\n",
              " 'this',\n",
              " 'chemical',\n",
              " 'element',\n",
              " 'who',\n",
              " 'by',\n",
              " 'the',\n",
              " 'by',\n",
              " 'lay',\n",
              " 'special',\n",
              " 'claim',\n",
              " 'to',\n",
              " 'critical',\n",
              " 'acumen',\n",
              " 'find',\n",
              " 'however',\n",
              " 'that',\n",
              " 'the',\n",
              " 'use',\n",
              " 'value',\n",
              " 'of',\n",
              " 'objects',\n",
              " 'belongs',\n",
              " 'to',\n",
              " 'them',\n",
              " 'independently',\n",
              " 'of',\n",
              " 'their',\n",
              " 'material',\n",
              " 'properties',\n",
              " 'while',\n",
              " 'their',\n",
              " 'value',\n",
              " 'on',\n",
              " 'the',\n",
              " 'other',\n",
              " 'hand',\n",
              " 'forms',\n",
              " 'part',\n",
              " 'of',\n",
              " 'them',\n",
              " 'as',\n",
              " 'objects']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KxV2JTIoyxE"
      },
      "source": [
        "Hmm, an interesting observation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef5ZnODM2V_P"
      },
      "source": [
        "### Transfer Learning with GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VAOaelq2WIr"
      },
      "source": [
        "We'll import GloVe vectors as w2v, then use those as a base from which to train new vectors that are tuned to our corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcFZMRT82WRC"
      },
      "source": [
        "# load the vectors. other vector sizes were used but yielded generally less sensible models\n",
        "glove_file = datapath('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/glove.6B.50d.txt')\n",
        "tmp_file = get_tmpfile(\"test_word2vec.txt\")\n",
        "\n",
        "_ = glove2word2vec(glove_file, tmp_file)\n",
        "\n",
        "glove_vectors = KeyedVectors.load_word2vec_format(tmp_file)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12hPyZ2aHugg"
      },
      "source": [
        "pairs_to_try = [(['law', 'moral'], []),\n",
        "                (['self', 'consciousness'], []),\n",
        "                (['dialectic'], []),\n",
        "                (['logic'], []),\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjdDWtd72Tli",
        "outputId": "9d553b61-b960-4668-9cc5-87600ee56722"
      },
      "source": [
        "# check out how GloVe works on our test pairs\n",
        "test_w2v(glove_vectors, pairs_to_try)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive - ['law', 'moral']\tNegative - []\n",
            "- morality (0.82654)\n",
            "- legal (0.82652)\n",
            "- laws (0.81529)\n",
            "- constitutional (0.80616)\n",
            "- fundamental (0.80217)\n",
            "\n",
            "Positive - ['self', 'consciousness']\tNegative - []\n",
            "- sense (0.83446)\n",
            "- mind (0.79755)\n",
            "- vision (0.78202)\n",
            "- belief (0.78031)\n",
            "- life (0.77984)\n",
            "\n",
            "Positive - ['dialectic']\tNegative - []\n",
            "- hegelian (0.88376)\n",
            "- dialectical (0.83417)\n",
            "- dialectics (0.80672)\n",
            "- materialist (0.77674)\n",
            "- metaphysics (0.77488)\n",
            "\n",
            "Positive - ['logic']\tNegative - []\n",
            "- reasoning (0.81405)\n",
            "- intuitionistic (0.76531)\n",
            "- concepts (0.75831)\n",
            "- logical (0.75604)\n",
            "- theory (0.75026)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhFyauZoo7KW"
      },
      "source": [
        "Now we want these to be trained on our actual philosophical texts - that way we can see how different thinkers use different words and potentially use the vectors for classification.\n",
        "\n",
        "So in the cells below we train the existing GloVe model on on the German Idealist texts as a test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVDl6FwMmwp9"
      },
      "source": [
        "#### German Idealism Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSOA8Zz2o7vX"
      },
      "source": [
        "# isolate the relevant school\n",
        "documents = df[df['school'] == 'german_idealism']['gensim_tokenized']\n",
        "\n",
        "# format the series to be used\n",
        "stopwords = []\n",
        "\n",
        "sentences = [sentence for sentence in documents]\n",
        "cleaned = []\n",
        "for sentence in sentences:\n",
        "  cleaned_sentence = [word.lower() for word in sentence]\n",
        "  cleaned_sentence = [word for word in sentence if word not in stopwords]\n",
        "  cleaned.append(cleaned_sentence)\n",
        "\n",
        "# get bigrams\n",
        "bigram = Phrases(cleaned, min_count=20, threshold=10, delimiter=b' ')\n",
        "bigram_phraser = Phraser(bigram)\n",
        "\n",
        "bigramed_tokens = []\n",
        "for sent in cleaned:\n",
        "    tokens = bigram_phraser[sent]\n",
        "    bigramed_tokens.append(tokens)\n",
        "\n",
        "# run again to get trigrams\n",
        "trigram = Phrases(bigramed_tokens, min_count=20, threshold=10, delimiter=b' ')\n",
        "trigram_phraser = Phraser(trigram)\n",
        "\n",
        "trigramed_tokens = []\n",
        "for sent in bigramed_tokens:\n",
        "    tokens = trigram_phraser[sent]\n",
        "    trigramed_tokens.append(tokens)\n",
        "\n",
        "# build a toy model to update with\n",
        "base_model = Word2Vec(size=300, min_count=5)\n",
        "base_model.build_vocab(trigramed_tokens)\n",
        "total_examples = base_model.corpus_count\n",
        "\n",
        "# add GloVe's vocabulary & weights\n",
        "base_model.build_vocab([list(glove_vectors.vocab.keys())], update=True)\n",
        "\n",
        "# train on our data\n",
        "base_model.train(trigramed_tokens, total_examples=total_examples, epochs=base_model.epochs)\n",
        "base_model_wv = base_model.wv\n",
        "del base_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0FjXahncQya",
        "outputId": "305641d2-b529-438b-e6ee-9a43b0c244ec"
      },
      "source": [
        "test_w2v(base_model_wv, pairs_to_try)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive - ['law', 'moral']\tNegative - []\n",
            "- rule (0.82387)\n",
            "- moral law (0.80709)\n",
            "- freedom (0.80685)\n",
            "- causality (0.79339)\n",
            "- happiness (0.79102)\n",
            "\n",
            "Positive - ['self', 'consciousness']\tNegative - []\n",
            "- self consciousness (0.92469)\n",
            "- essence (0.87722)\n",
            "- immediacy (0.87623)\n",
            "- objectivity (0.87523)\n",
            "- negativity (0.87135)\n",
            "\n",
            "Positive - ['dialectic']\tNegative - []\n",
            "- method (0.93279)\n",
            "- doctrine (0.9254)\n",
            "- antinomy (0.92351)\n",
            "- deduction (0.91393)\n",
            "- exposition (0.89874)\n",
            "\n",
            "Positive - ['logic']\tNegative - []\n",
            "- pure reason (0.85429)\n",
            "- doctrine (0.84595)\n",
            "- method (0.838)\n",
            "- science (0.82746)\n",
            "- dialectic (0.81556)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR3MnHFbcl7d"
      },
      "source": [
        "These seem to reflect the true uses of words in German Idealism. 'Self' + 'consciousness' is rightly associated with 'self consciousness' and 'moral' + 'law' with 'moral law'. It even identifies the German Idealist tendency to unify logic and metaphysics. \n",
        "\n",
        "These vectors can be fairly said to reflect how german idealists use these terms. Moreover, they are significantly different than the original GloVe model, which indicates that there was real learning going on here.\n",
        "\n",
        "For comparison, let's check these same terms, but as used by Phenomenologists."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPdzhIk0m0Qz"
      },
      "source": [
        "#### Phenomenology Comparision"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0s1Jkkc7dqk9"
      },
      "source": [
        "def train_glove(source_type, source, glove_vectors, threshold=10, stopwords=[],\n",
        "                min_count=20):\n",
        "  # isolate the relevant school\n",
        "  documents = df[df[source_type] == source]['gensim_tokenized']\n",
        "\n",
        "  # format the series to be used\n",
        "  stopwords = []\n",
        "\n",
        "  sentences = [sentence for sentence in documents]\n",
        "  cleaned = []\n",
        "  for sentence in sentences:\n",
        "    cleaned_sentence = [word.lower() for word in sentence]\n",
        "    cleaned_sentence = [word for word in sentence if word not in stopwords]\n",
        "    cleaned.append(cleaned_sentence)\n",
        "\n",
        "  # get bigrams\n",
        "  bigram = Phrases(cleaned, min_count=min_count, threshold=threshold, \n",
        "                   delimiter=b' ')\n",
        "  bigram_phraser = Phraser(bigram)\n",
        "\n",
        "  bigramed_tokens = []\n",
        "  for sent in cleaned:\n",
        "      tokens = bigram_phraser[sent]\n",
        "      bigramed_tokens.append(tokens)\n",
        "\n",
        "  # run again to get trigrams\n",
        "  trigram = Phrases(bigramed_tokens, min_count=min_count, threshold=threshold, \n",
        "                    delimiter=b' ')\n",
        "  trigram_phraser = Phraser(trigram)\n",
        "\n",
        "  trigramed_tokens = []\n",
        "  for sent in bigramed_tokens:\n",
        "      tokens = trigram_phraser[sent]\n",
        "      trigramed_tokens.append(tokens)\n",
        "\n",
        "  # build a toy model to update with\n",
        "  model = Word2Vec(size=300, min_count=5)\n",
        "  model.build_vocab(trigramed_tokens)\n",
        "  total_examples = model.corpus_count\n",
        "\n",
        "  # add GloVe's vocabulary & weights\n",
        "  model.build_vocab([list(glove_vectors.vocab.keys())], update=True)\n",
        "\n",
        "  # train on our data\n",
        "  model.train(trigramed_tokens, total_examples=total_examples, epochs=model.epochs)\n",
        "  model_wv = model.wv\n",
        "  del model\n",
        "  return model_wv"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIMLCNVHdxID"
      },
      "source": [
        "ph_model = train_glove(source_type='school', source='phenomenology', glove_vectors=glove_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI3_J1HGnxd-",
        "outputId": "54d33179-2b7d-45af-bf00-885de145fb8d"
      },
      "source": [
        "test_w2v(ph_model, pairs_to_try)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive - ['law', 'moral']\tNegative - []\n",
            "- ideality (0.99645)\n",
            "- unfolding (0.99551)\n",
            "- ab (0.99506)\n",
            "- class (0.99357)\n",
            "- intentionality (0.99174)\n",
            "\n",
            "Positive - ['self', 'consciousness']\tNegative - []\n",
            "- certainty (0.95246)\n",
            "- potentiality (0.94868)\n",
            "- existence (0.94029)\n",
            "- nature (0.93831)\n",
            "- authentic (0.93513)\n",
            "\n",
            "Positive - ['dialectic']\tNegative - []\n",
            "- danger (0.98913)\n",
            "- room (0.9881)\n",
            "- shadow (0.9869)\n",
            "- furthermore (0.9869)\n",
            "- publicness (0.98683)\n",
            "\n",
            "Positive - ['logic']\tNegative - []\n",
            "- definition (0.98022)\n",
            "- rpretation (0.9788)\n",
            "- type (0.9781)\n",
            "- transcendence (0.97677)\n",
            "- dispensation (0.97635)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRp6eNmHeP01"
      },
      "source": [
        "Using the phenomenology vectors on some central terms of German idealism once again yields some pretty compelling results, except for where the words are rarely used by the phenomenologists. This is to be expected. Let's try the word vectors on some central terms of phenomenology."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWzc_fFGnXnF",
        "outputId": "afb3d1b6-64e1-4954-af5c-39b3f571c9ae"
      },
      "source": [
        "pairs_to_try = [(['perception'], []),\n",
        "                (['dasein'], []),\n",
        "                (['consciousness'], []),\n",
        "                (['method'], []),]\n",
        "\n",
        "test_w2v(ph_model, pairs_to_try)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive - ['perception']\tNegative - []\n",
            "- act (0.9331)\n",
            "- death (0.93105)\n",
            "- representation (0.93053)\n",
            "- movement (0.92326)\n",
            "- synthesis (0.91799)\n",
            "\n",
            "Positive - ['dasein']\tNegative - []\n",
            "- being (0.8908)\n",
            "- truth (0.87897)\n",
            "- itself (0.87614)\n",
            "- future (0.85072)\n",
            "- consciousness (0.83773)\n",
            "\n",
            "Positive - ['consciousness']\tNegative - []\n",
            "- movement (0.93418)\n",
            "- representation (0.91543)\n",
            "- body (0.90922)\n",
            "- existence (0.90389)\n",
            "- future (0.90297)\n",
            "\n",
            "Positive - ['method']\tNegative - []\n",
            "- spirit (0.97806)\n",
            "- necessity (0.95537)\n",
            "- phenomenology (0.95236)\n",
            "- ontology (0.95015)\n",
            "- history (0.95015)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5UPKzWjrWMQ"
      },
      "source": [
        "#### Training on every school & author"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIREGokArZQK"
      },
      "source": [
        "To further explore this, we'll train w2v models in this way for each school and examine how each of them looks at the same word - 'philosophy.' We can use these in our future dashboard work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8_XI24ogh17",
        "outputId": "b0b6a4d3-1c80-41ed-d506-ddc2dfa851d4"
      },
      "source": [
        "w2v_dict = {}\n",
        "\n",
        "for school in df['school'].unique():\n",
        "  w2v_dict[school] = train_glove('school', school, glove_vectors=glove_vectors)\n",
        "  print(f'{school} completed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "plato completed\n",
            "aristotle completed\n",
            "empiricism completed\n",
            "rationalism completed\n",
            "analytic completed\n",
            "continental completed\n",
            "phenomenology completed\n",
            "german_idealism completed\n",
            "communism completed\n",
            "capitalism completed\n",
            "stoicism completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "euZktiqighpT",
        "outputId": "7d393b42-0fa1-4344-e504-f5cfe7b046ba"
      },
      "source": [
        "for school in df['school'].unique():\n",
        "  print(f'\\t{school.upper()}')\n",
        "  print('----------------------')\n",
        "  test_w2v(w2v_dict[school], [(['philosophy'], [])])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tPLATO\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- exploits (0.94807)\n",
            "- every kind (0.94536)\n",
            "- nourishment (0.9443)\n",
            "- construction (0.9407)\n",
            "- waves (0.93759)\n",
            "\n",
            "\tARISTOTLE\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- practice (0.90368)\n",
            "- affairs (0.89227)\n",
            "- writer (0.8858)\n",
            "- mortals (0.88398)\n",
            "- philosophical (0.87431)\n",
            "\n",
            "\tEMPIRICISM\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- subtle (0.91686)\n",
            "- practice (0.913)\n",
            "- religion (0.91133)\n",
            "- ethics (0.88737)\n",
            "- popular (0.87861)\n",
            "\n",
            "\tRATIONALISM\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- name (0.93098)\n",
            "- prince (0.92751)\n",
            "- territory (0.92547)\n",
            "- intention (0.92448)\n",
            "- doctrine (0.92422)\n",
            "\n",
            "\tANALYTIC\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- philosophical (0.88962)\n",
            "- semantics (0.85898)\n",
            "- symbolism (0.83177)\n",
            "- quotation (0.82118)\n",
            "- modern (0.81951)\n",
            "\n",
            "\tCONTINENTAL\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- history (0.95461)\n",
            "- notion (0.94806)\n",
            "- unreason (0.94588)\n",
            "- metaphysics (0.93707)\n",
            "- capitalism (0.92847)\n",
            "\n",
            "\tPHENOMENOLOGY\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- spirit (0.90423)\n",
            "- metaphysics (0.89827)\n",
            "- phenomenology (0.89371)\n",
            "- punctuality (0.89011)\n",
            "- science (0.88829)\n",
            "\n",
            "\tGERMAN_IDEALISM\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- science (0.87732)\n",
            "- metaphysics (0.85916)\n",
            "- mathematics (0.8103)\n",
            "- method (0.79468)\n",
            "- critique (0.78717)\n",
            "\n",
            "\tCOMMUNISM\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- preliminary (0.99842)\n",
            "- employing (0.9984)\n",
            "- abolishing (0.99828)\n",
            "- patriarchal (0.99827)\n",
            "- combines (0.99811)\n",
            "\n",
            "\tCAPITALISM\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- italy (0.99112)\n",
            "- thedominions (0.99071)\n",
            "- loans (0.99042)\n",
            "- continent (0.98852)\n",
            "- skins (0.98764)\n",
            "\n",
            "\tSTOICISM\n",
            "----------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- upon (0.9999)\n",
            "- but (0.99988)\n",
            "- me (0.99988)\n",
            "- let (0.99988)\n",
            "- thou hast (0.99988)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmP9U0WrghgT"
      },
      "source": [
        "Interestingly, many of these top words align quite strongly with the school's general attitude towards philosophy. Continental thinkers mentioning unreason, analytic philosophers focusing on semantics, and phenomenologists associating philosophy with a method all track well. The ones that don't make sense are those that don't problematize the nature of philosophy to any great degree - capitalist thinkers aren't out there trying to discuss the nature of philosophy.\n",
        "\n",
        "We'd also like vectors trained for each individual author. We can use these in our dashboard to enable intra-school comparisons of authors and generally allow for more fine-grained data exploration."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "V6KZckIvrDv8"
      },
      "source": [
        "#@title Glove Training Function Modified for Authors\n",
        "def train_glove_author(school, glove_vectors, threshold=10, stopwords=[],\n",
        "                min_count=20):\n",
        "  # isolate the relevant school\n",
        "  documents = df[df['author'] ==school]['gensim_tokenized']\n",
        "\n",
        "  # format the series to be used\n",
        "  stopwords = []\n",
        "\n",
        "  sentences = [sentence for sentence in documents]\n",
        "  cleaned = []\n",
        "  for sentence in sentences:\n",
        "    cleaned_sentence = [word.lower() for word in sentence]\n",
        "    cleaned_sentence = [word for word in sentence if word not in stopwords]\n",
        "    cleaned.append(cleaned_sentence)\n",
        "\n",
        "  # get bigrams\n",
        "  bigram = Phrases(cleaned, min_count=min_count, threshold=threshold, \n",
        "                   delimiter=b' ')\n",
        "  bigram_phraser = Phraser(bigram)\n",
        "\n",
        "  bigramed_tokens = []\n",
        "  for sent in cleaned:\n",
        "      tokens = bigram_phraser[sent]\n",
        "      bigramed_tokens.append(tokens)\n",
        "\n",
        "  # run again to get trigrams\n",
        "  trigram = Phrases(bigramed_tokens, min_count=min_count, threshold=threshold, \n",
        "                    delimiter=b' ')\n",
        "  trigram_phraser = Phraser(trigram)\n",
        "\n",
        "  trigramed_tokens = []\n",
        "  for sent in bigramed_tokens:\n",
        "      tokens = trigram_phraser[sent]\n",
        "      trigramed_tokens.append(tokens)\n",
        "\n",
        "  # build a toy model to update with\n",
        "  model = Word2Vec(size=300, min_count=5)\n",
        "  model.build_vocab(trigramed_tokens)\n",
        "  total_examples = model.corpus_count\n",
        "\n",
        "  # add GloVe's vocabulary & weights\n",
        "  model.build_vocab([list(glove_vectors.vocab.keys())], update=True)\n",
        "\n",
        "  # train on our data\n",
        "  model.train(trigramed_tokens, total_examples=total_examples, epochs=model.epochs)\n",
        "  model_wv = model.wv\n",
        "  del model\n",
        "  return model_wv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_IheEwhqWRi",
        "outputId": "5f67e7da-efc3-4ff4-f0bd-97b65fb7706e"
      },
      "source": [
        "for author in df['author'].unique():\n",
        "  w2v_dict[author] = train_glove('author', author, glove_vectors=glove_vectors)\n",
        "  print(f'{author} completed')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Plato completed\n",
            "Aristotle completed\n",
            "Locke completed\n",
            "Hume completed\n",
            "Berkeley completed\n",
            "Spinoza completed\n",
            "Leibniz completed\n",
            "Descartes completed\n",
            "Malebranche completed\n",
            "Russell completed\n",
            "Moore completed\n",
            "Wittgenstein completed\n",
            "Lewis completed\n",
            "Quine completed\n",
            "Popper completed\n",
            "Kripke completed\n",
            "Foucault completed\n",
            "Derrida completed\n",
            "Deleuze completed\n",
            "Merleau-Ponty completed\n",
            "Husserl completed\n",
            "Heidegger completed\n",
            "Kant completed\n",
            "Fichte completed\n",
            "Hegel completed\n",
            "Marx completed\n",
            "Lenin completed\n",
            "Smith completed\n",
            "Ricardo completed\n",
            "Keynes completed\n",
            "Epictetus completed\n",
            "Marcus Aurelius completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "av0A9Ohwsizl"
      },
      "source": [
        "With this finished - our next step is to train one on the entire corpus for use in classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YaV6IV5esoW7"
      },
      "source": [
        "#### Building a Model for the full Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQu70aYwChpm"
      },
      "source": [
        "documents = df['gensim_tokenized']\n",
        "\n",
        "# format the series to be used\n",
        "stopwords = []\n",
        "\n",
        "sentences = [sentence for sentence in documents]\n",
        "cleaned = []\n",
        "for sentence in sentences:\n",
        "  cleaned_sentence = [word.lower() for word in sentence]\n",
        "  cleaned_sentence = [word for word in sentence if word not in stopwords]\n",
        "  cleaned.append(cleaned_sentence)\n",
        "\n",
        "# get bigrams\n",
        "bigram = Phrases(cleaned, min_count=30, threshold=10, \n",
        "                  delimiter=b' ')\n",
        "bigram_phraser = Phraser(bigram)\n",
        "\n",
        "bigramed_tokens = []\n",
        "for sent in cleaned:\n",
        "    tokens = bigram_phraser[sent]\n",
        "    bigramed_tokens.append(tokens)\n",
        "\n",
        "# run again to get trigrams\n",
        "trigram = Phrases(bigramed_tokens, min_count=30, threshold=10, \n",
        "                  delimiter=b' ')\n",
        "trigram_phraser = Phraser(trigram)\n",
        "\n",
        "trigramed_tokens = []\n",
        "for sent in bigramed_tokens:\n",
        "    tokens = trigram_phraser[sent]\n",
        "    trigramed_tokens.append(tokens)\n",
        "\n",
        "# build a toy model to update with\n",
        "all_text_model = Word2Vec(size=300, min_count=5)\n",
        "all_text_model.build_vocab(trigramed_tokens)\n",
        "total_examples = all_text_model.corpus_count\n",
        "\n",
        "# add GloVe's vocabulary & weights\n",
        "all_text_model.build_vocab([list(glove_vectors.vocab.keys())], update=True)\n",
        "\n",
        "# train on our data\n",
        "all_text_model.train(trigramed_tokens, total_examples=total_examples, \n",
        "                     epochs=all_text_model.epochs)\n",
        "all_text_wv = all_text_model.wv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wk3zbVgDbxl"
      },
      "source": [
        "As a test case, let's see how the philosophy thinks of itself as compared to how glove thinks of philosophy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GNhMEqvDnpN",
        "outputId": "7100b0c8-a9f9-4b41-8885-1d5b948048ec"
      },
      "source": [
        "for model in [1, 2]:\n",
        "  if model == 1:\n",
        "    print(f'\\tPHILOSOPHY CORPUS')\n",
        "    print('------------------------------------')\n",
        "    test_w2v(all_text_wv, [(['philosophy'], [])])\n",
        "  if model == 2:\n",
        "    print(f'\\tBASE GLOVE')\n",
        "    print('------------------------------------')\n",
        "    test_w2v(glove_vectors, [(['philosophy'], [])])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\tPHILOSOPHY CORPUS\n",
            "------------------------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- theology (0.78782)\n",
            "- metaphysics (0.76086)\n",
            "- science (0.72245)\n",
            "- philosophical (0.70852)\n",
            "- religion (0.69931)\n",
            "\n",
            "\tBASE GLOVE\n",
            "------------------------------------\n",
            "Positive - ['philosophy']\tNegative - []\n",
            "- theology (0.88151)\n",
            "- philosophical (0.84362)\n",
            "- mathematics (0.83389)\n",
            "- psychology (0.82387)\n",
            "- sociology (0.81085)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeVE7mUFzlY"
      },
      "source": [
        "This sort of stands to reason - 'metaphysics' often has a different meaning outside of philosophical discussion, so it's not surprising to see it as the most changed term here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cyhr9Cqpm3p4"
      },
      "source": [
        "#### Exporting for Only New Texts\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3tZfuM9j192"
      },
      "source": [
        "w2v_dict['Wittgenstein'].save('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/Wittgenstein_w2v.wordvectors')\n",
        "w2v_dict['analytic'].save('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/analytic_w2v.wordvectors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KT2C31yemkFO"
      },
      "source": [
        "# use this cell to build the newest author/text/school in the corpus, then export in the cell below\n",
        "epictetus_wv = train_glove(source_type='author', source='Epictetus', glove_vectors=glove_vectors)\n",
        "aurelius_wv = train_glove(source_type='author', source='Marcus Aurelius', glove_vectors=glove_vectors)\n",
        "stoicism_wv = train_glove(source_type='school', source='stoicism', glove_vectors=glove_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Q7VIqmwb5CP"
      },
      "source": [
        "feminism_wv = train_glove(source_type='school', source='feminism', glove_vectors=glove_vectors)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgi2_RYaoJsQ",
        "outputId": "f391c09d-0ea1-49b0-ebc6-654efc1c20c0"
      },
      "source": [
        "# test out new model\n",
        "feminism_wv.most_similar('woman')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('man', 0.9556863903999329),\n",
              " ('being', 0.9291601181030273),\n",
              " ('one', 0.9211259484291077),\n",
              " ('itself', 0.9138535857200623),\n",
              " ('object', 0.9020975232124329),\n",
              " ('child', 0.9018499851226807),\n",
              " ('wife', 0.8998592495918274),\n",
              " ('body', 0.8909246921539307),\n",
              " ('flesh', 0.889091968536377),\n",
              " ('frailty', 0.8886901140213013)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA92f721cReA"
      },
      "source": [
        "feminism_wv.save('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/Feminism_w2v.wordvectors')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpYziok8npUj"
      },
      "source": [
        "epictetus_wv.save('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/Epictetus_w2v.wordvectors')\n",
        "stoicism_wv.save('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/Stoiticism_w2v.wordvectors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzkFHnfrvpmp"
      },
      "source": [
        "nietzsche_wv = train_glove(source_type='author', source='Nietzsche', glove_vectors=glove_vectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LV2SZynZv6Qa",
        "outputId": "e995272d-411e-4e83-85b6-e07b2cb9d241"
      },
      "source": [
        "nietzsche_wv.most_similar('false')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('similar', 0.9997142553329468),\n",
              " ('innocent', 0.9997087717056274),\n",
              " ('whatever', 0.9996904730796814),\n",
              " ('seeing', 0.9996882081031799),\n",
              " ('forbidden', 0.9996852874755859),\n",
              " ('weakness', 0.999677836894989),\n",
              " ('counter', 0.9996709823608398),\n",
              " ('familiar', 0.9996637105941772),\n",
              " ('consequence', 0.9996539354324341),\n",
              " ('delicate', 0.9996402859687805)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9OKKtExwjeL"
      },
      "source": [
        "nietzsche_wv.save('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/Nietzsche_w2v.wordvectors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A24iStA_rtOf"
      },
      "source": [
        "#### Finalized exporting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUxG_7YlrvIP"
      },
      "source": [
        "All in all, things look good, so let's export the vectors so that they can be used in our neural networks and in our dash app. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mg6rnhbD235n"
      },
      "source": [
        "# do not run these cells if you want to keep old w2v versions\n",
        "all_text_wv.save_word2vec_format('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/w2v_for_nn.bin')\n",
        "all_text_wv.save('/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/w2v_for_nn.wordvectors')\n",
        "\n",
        "for source in w2v_dict.keys():\n",
        "  w2v_dict[source].save(f'/gdrive/MyDrive/Colab_Projects/philosophy_data_project/w2v_models/{source}_w2v.wordvectors')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0wn9YYoGXel"
      },
      "source": [
        "And that's it! See our other notebooks for more of the modeling work. "
      ]
    }
  ]
}