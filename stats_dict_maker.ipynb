{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "learn-env",
   "display_name": "learn-env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      title       author       school  \\\n",
       "117472               The Search After Truth  Malebranche  rationalism   \n",
       "65236            Aristotle - Complete Works    Aristotle    aristotle   \n",
       "181924               Philosophical Troubles       Kripke     analytic   \n",
       "110889  On The Improvement Of Understanding      Spinoza  rationalism   \n",
       "148417                       Lewis - Papers        Lewis     analytic   \n",
       "\n",
       "                                           sentence_spacy  \\\n",
       "117472  We should ne, er absolutely love some good if ...   \n",
       "65236   In the Pantheon there is an olive tree, which ...   \n",
       "181924  The inﬂuence goes down to the use of initials ...   \n",
       "110889  That is, it is known that the senses sometimes...   \n",
       "148417  , the third component of our desired interprea...   \n",
       "\n",
       "                                             sentence_str  sentence_length  \\\n",
       "117472  We should ne, er absolutely love some good if ...               87   \n",
       "65236   In the Pantheon there is an olive tree, which ...               87   \n",
       "181924  The inﬂuence goes down to the use of initials ...              110   \n",
       "110889  That is, it is known that the senses sometimes...               58   \n",
       "148417  , the third component of our desired interprea...              153   \n",
       "\n",
       "                                         sentence_lowered  \\\n",
       "117472  we should ne, er absolutely love some good if ...   \n",
       "65236   in the pantheon there is an olive tree, which ...   \n",
       "181924  the inﬂuence goes down to the use of initials ...   \n",
       "110889  that is, it is known that the senses sometimes...   \n",
       "148417  , the third component of our desired interprea...   \n",
       "\n",
       "                                            tokenized_txt  \\\n",
       "117472  ['we', 'should', 'ne', 'er', 'absolutely', 'lo...   \n",
       "65236   ['in', 'the', 'pantheon', 'there', 'is', 'an',...   \n",
       "181924  ['the', 'inﬂuence', 'goes', 'down', 'to', 'the...   \n",
       "110889  ['that', 'is', 'it', 'is', 'known', 'that', 't...   \n",
       "148417  ['the', 'third', 'component', 'of', 'our', 'de...   \n",
       "\n",
       "                                           lemmatized_str  \n",
       "117472   -PRON- should ne , er absolutely love some go...  \n",
       "65236    in the Pantheon there be an olive tree , whic...  \n",
       "181924   the inﬂuence go down to the use of initial to...  \n",
       "110889   that is , -PRON- be know that the sense somet...  \n",
       "148417   , the third component of -PRON- desire interp...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author</th>\n      <th>school</th>\n      <th>sentence_spacy</th>\n      <th>sentence_str</th>\n      <th>sentence_length</th>\n      <th>sentence_lowered</th>\n      <th>tokenized_txt</th>\n      <th>lemmatized_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>117472</th>\n      <td>The Search After Truth</td>\n      <td>Malebranche</td>\n      <td>rationalism</td>\n      <td>We should ne, er absolutely love some good if ...</td>\n      <td>We should ne, er absolutely love some good if ...</td>\n      <td>87</td>\n      <td>we should ne, er absolutely love some good if ...</td>\n      <td>['we', 'should', 'ne', 'er', 'absolutely', 'lo...</td>\n      <td>-PRON- should ne , er absolutely love some go...</td>\n    </tr>\n    <tr>\n      <th>65236</th>\n      <td>Aristotle - Complete Works</td>\n      <td>Aristotle</td>\n      <td>aristotle</td>\n      <td>In the Pantheon there is an olive tree, which ...</td>\n      <td>In the Pantheon there is an olive tree, which ...</td>\n      <td>87</td>\n      <td>in the pantheon there is an olive tree, which ...</td>\n      <td>['in', 'the', 'pantheon', 'there', 'is', 'an',...</td>\n      <td>in the Pantheon there be an olive tree , whic...</td>\n    </tr>\n    <tr>\n      <th>181924</th>\n      <td>Philosophical Troubles</td>\n      <td>Kripke</td>\n      <td>analytic</td>\n      <td>The inﬂuence goes down to the use of initials ...</td>\n      <td>The inﬂuence goes down to the use of initials ...</td>\n      <td>110</td>\n      <td>the inﬂuence goes down to the use of initials ...</td>\n      <td>['the', 'inﬂuence', 'goes', 'down', 'to', 'the...</td>\n      <td>the inﬂuence go down to the use of initial to...</td>\n    </tr>\n    <tr>\n      <th>110889</th>\n      <td>On The Improvement Of Understanding</td>\n      <td>Spinoza</td>\n      <td>rationalism</td>\n      <td>That is, it is known that the senses sometimes...</td>\n      <td>That is, it is known that the senses sometimes...</td>\n      <td>58</td>\n      <td>that is, it is known that the senses sometimes...</td>\n      <td>['that', 'is', 'it', 'is', 'known', 'that', 't...</td>\n      <td>that is , -PRON- be know that the sense somet...</td>\n    </tr>\n    <tr>\n      <th>148417</th>\n      <td>Lewis - Papers</td>\n      <td>Lewis</td>\n      <td>analytic</td>\n      <td>, the third component of our desired interprea...</td>\n      <td>, the third component of our desired interprea...</td>\n      <td>153</td>\n      <td>, the third component of our desired interprea...</td>\n      <td>['the', 'third', 'component', 'of', 'our', 'de...</td>\n      <td>, the third component of -PRON- desire interp...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('phil_nlp.csv')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Analytic           0.163603\n",
       "Aristotle          0.149320\n",
       "German Idealism    0.128988\n",
       "Plato              0.117520\n",
       "Continental        0.103409\n",
       "Phenomenology      0.087466\n",
       "Rationalism        0.070253\n",
       "Empiricism         0.061012\n",
       "Capitalism         0.055694\n",
       "Communism          0.054975\n",
       "Stoicism           0.007760\n",
       "Name: school, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df['school'] = df['school'].apply(lambda x: x.replace('_', ' ').title())\n",
    "df['school'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\kcali\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import wordcloud\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import plotly.express as px \n",
    "import pandas as pd\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "classifier_dict = {}\n",
    "for author in df['author'].unique():\n",
    "  classifier_dict[author] = 'author'\n",
    "for title in df['title'].unique():\n",
    "  classifier_dict[title] = 'title'\n",
    "for school in df['school'].unique():\n",
    "  classifier_dict[school] = 'school'\n",
    "\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation) \n",
    "stopwords_list += ['“','”','...',\"''\",'’','``', \"'\", \"‘\"]\n",
    "custom_stopwords = ['–', 'also', 'something', 'cf', 'thus', 'two', 'now', 'would', \n",
    "                    'make', 'eb', 'u', 'well', 'even', 'said', 'eg', 'us',\n",
    "                    'n', 'sein', 'e', 'da', 'therefore', 'however', 'would', \n",
    "                    'thing', 'must', 'merely', 'way', 'since', 'latter', 'first',\n",
    "                    'B', 'mean', 'upon', 'yet', 'cannot', 'c', 'C', 'let', 'may', \n",
    "                    'might', \"'s\", 'b', 'ofthe', 'p.', '_', '-', 'eg', 'e.g.',\n",
    "                    'ie', 'i.e.', 'f', 'l', \"n't\", 'e.g', 'i.e', '—', '--', \n",
    "                    'hyl', 'phil', 'one', 'another', 'could', 'come', 'things', 'thing',\n",
    "                    'else', 'every', 'shall'] + stopwords_list\n",
    "\n",
    "df['gensim_tokenized'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
    "                                                        max_len=500))\n",
    "\n",
    "def get_average_word_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', '[']\n",
    "  num_words = 0\n",
    "  sum_word_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    sentence_list = [re.sub(\"[',]\", '', word) for word in sentence_list]\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    for word in no_punctuation_tokens:\n",
    "      num_words += 1\n",
    "      sum_word_lengths += len(word)\n",
    "  return round((sum_word_lengths / num_words), 2)\n",
    "\n",
    "def get_average_sentence_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  num_sentences = 0\n",
    "  sum_sentence_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_sentences += 1\n",
    "    sum_sentence_lengths += len(no_punctuation_tokens)\n",
    "  return round(sum_sentence_lengths / num_sentences, 2)\n",
    "\n",
    "def make_word_cloud(input, df, classifier, stopwords=stopwords.words('english')):\n",
    "    text = ''\n",
    "    for sentence in df[df[classifier[input]]==input]['sentence_str']:\n",
    "      text += sentence\n",
    "    cloud = wordcloud.WordCloud(width=500, \n",
    "                            height=400, \n",
    "                            background_color='#D1D1D1', \n",
    "                            max_words=30, \n",
    "                            stopwords=stopwords, \n",
    "                            color_func=lambda *args, **kwargs: (95,95,95)).generate(text)\n",
    "    return cloud\n",
    "\n",
    "def get_num_unique_words(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  word_list = []\n",
    "  num_words = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_words += len(no_punctuation_tokens)\n",
    "    for word in no_punctuation_tokens:\n",
    "      word_list.append(word)\n",
    "  num_unique_words = len(set(word_list))\n",
    "  return num_unique_words, num_words\n",
    "\n",
    "def plot_word_frequency(input, df, classifier_dict, stopwords):\n",
    "  word_list = []\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['gensim_tokenized'][:50]:\n",
    "    for word in sentence:\n",
    "      word_list.append(word)\n",
    "  cleaned_words = [x.lower() for x in word_list if x.lower() not in stopwords]\n",
    "  freq_dist = FreqDist(cleaned_words)\n",
    "  freq_dict = {'words': [x[0] for x in freq_dist.most_common(7)], \n",
    "              'frequency': [x[1] for x in freq_dist.most_common(7)]}\n",
    "  freq_df = pd.DataFrame(freq_dict)\n",
    "  fig = px.bar(freq_df,\n",
    "              x='words',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Words')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} Word Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def plot_ngram_frequency(input, df, classifier_dict, stopwords): \n",
    "  word_list = []\n",
    "  for sent in df[df[classifier_dict[input]]==input]['gensim_tokenized']:\n",
    "    for word in sent:\n",
    "      word_list.append(word)\n",
    "  cleaned = [word.lower() for word in word_list if word not in custom_stopwords]\n",
    "  bigram_finder = BigramCollocationFinder.from_words(cleaned, window_size=3)\n",
    "  top_10 = sorted(bigram_finder.ngram_fd.items(), key=lambda t: (-t[1], t[0]))[:7]\n",
    "  bigram_df = pd.DataFrame(top_10, columns=['bigram', 'frequency'])\n",
    "  bigram_df['bigram'] = bigram_df['bigram'].apply(lambda x: ', '.join(x))\n",
    "  fig = px.bar(bigram_df,\n",
    "              x='bigram',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Phrases')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} N-gram Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def get_title_list(input, df, classifier_dict):\n",
    "  title_list = list(df[df[classifier_dict[input]]==input]['title'].unique())\n",
    "  title_list = [title.title() for title in title_list] \n",
    "  return ', '.join(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict_master = {}\n",
    "for option in classifier_dict.keys():\n",
    "    stats_dict = {}\n",
    "    stats_dict['title_list'] = get_title_list(option, df, classifier_dict)\n",
    "    stats_dict['ngram_chart'] = plot_ngram_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['word_freq_chart'] = plot_word_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['num_unique'] = get_num_unique_words(option, df, classifier_dict)\n",
    "    stats_dict['mean_sent_length'] = get_average_sentence_length(option, df, classifier_dict)\n",
    "    stats_dict['mean_word_length'] = get_average_word_length(option, df, classifier_dict)\n",
    "    stats_dict_master[option] = stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'title_list': 'Enchiridion, Meditations',\n",
       " 'ngram_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'bigram=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['unto, thee', 'thou, art', 'thou, shalt', 'thou, hast', 'thee, thou',\n",
       "                           'thou, dost', 'thy, mind'], dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([93, 92, 87, 65, 64, 54, 51], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Stoicism N-gram Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Phrases'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'word_freq_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'words=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['power', 'others', 'within', 'say', 'nature', 'elated', 'desire'],\n",
       "                          dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([13,  9,  8,  8,  7,  6,  5], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Stoicism Word Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Words'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'num_unique': (5999, 62624),\n",
       " 'mean_sent_length': 24.7,\n",
       " 'mean_word_length': 4.47}"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "stats_dict_master['Stoicism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for option in stats_dict_master.keys():\n",
    "    dict_pkl = open(f'../stats_app/stats_pickles/{option.title()}_stats.pkl', 'wb')\n",
    "    pickle.dump(stats_dict_master[option], dict_pkl)\n",
    "    dict_pkl.close()\n"
   ]
  },
  {
   "source": [
    "Now we get the updated dropdown menu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A General Theory Of Employment, Interest, And Money',\n",
       " 'A Treatise Concerning The Principles Of Human Knowledge',\n",
       " 'A Treatise Of Human Nature',\n",
       " 'Analytic',\n",
       " 'Anti-Oedipus',\n",
       " 'Aristotle',\n",
       " 'Aristotle - Complete Works',\n",
       " 'Being And Time',\n",
       " 'Berkeley',\n",
       " 'Capital',\n",
       " 'Capitalism',\n",
       " 'Communism',\n",
       " 'Continental',\n",
       " 'Critique Of Judgement',\n",
       " 'Critique Of Practical Reason',\n",
       " 'Critique Of Pure Reason',\n",
       " 'Deleuze',\n",
       " 'Derrida',\n",
       " 'Descartes',\n",
       " 'Dialogues Concerning Natural Religion',\n",
       " 'Difference And Repetition',\n",
       " 'Discourse On Method',\n",
       " 'Elements Of The Philosophy Of Right',\n",
       " 'Empiricism',\n",
       " 'Enchiridion',\n",
       " 'Epictetus',\n",
       " 'Essay Concerning Human Understanding',\n",
       " 'Essential Works Of Lenin',\n",
       " 'Ethics',\n",
       " 'Fichte',\n",
       " 'Foucault',\n",
       " 'German Idealism',\n",
       " 'Hegel',\n",
       " 'Heidegger',\n",
       " 'Hume',\n",
       " 'Husserl',\n",
       " 'Kant',\n",
       " 'Keynes',\n",
       " 'Kripke',\n",
       " 'Leibniz',\n",
       " 'Lenin',\n",
       " 'Lewis',\n",
       " 'Lewis - Papers',\n",
       " 'Locke',\n",
       " 'Madness And Civilization',\n",
       " 'Malebranche',\n",
       " 'Marcus Aurelius',\n",
       " 'Marx',\n",
       " 'Meditations',\n",
       " 'Meditations On First Philosophy',\n",
       " 'Merleau-Ponty',\n",
       " 'Moore',\n",
       " 'Naming And Necessity',\n",
       " 'Off The Beaten Track',\n",
       " 'On The Improvement Of Understanding',\n",
       " 'On The Principles Of Political Economy And Taxation',\n",
       " 'Phenomenology',\n",
       " 'Philosophical Investigations',\n",
       " 'Philosophical Studies',\n",
       " 'Philosophical Troubles',\n",
       " 'Plato',\n",
       " 'Plato - Complete Works',\n",
       " 'Popper',\n",
       " 'Quine',\n",
       " 'Quintessence',\n",
       " 'Rationalism',\n",
       " 'Ricardo',\n",
       " 'Russell',\n",
       " 'Science Of Logic',\n",
       " 'Second Treatise On Government',\n",
       " 'Smith',\n",
       " 'Spinoza',\n",
       " 'Stoicism',\n",
       " 'The Analysis Of Mind',\n",
       " 'The Birth Of The Clinic',\n",
       " 'The Communist Manifesto',\n",
       " 'The Crisis Of The European Sciences And Phenomenology',\n",
       " 'The Idea Of Phenomenology',\n",
       " 'The Logic Of Scientific Discovery',\n",
       " 'The Order Of Things',\n",
       " 'The Phenomenology Of Perception',\n",
       " 'The Phenomenology Of Spirit',\n",
       " 'The Problems Of Philosophy',\n",
       " 'The Search After Truth',\n",
       " 'The System Of Ethics',\n",
       " 'The Wealth Of Nations',\n",
       " 'Theodicy',\n",
       " 'Three Dialogues',\n",
       " 'Tractatus Logico-Philosophicus',\n",
       " 'Wittgenstein',\n",
       " 'Writing And Difference']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "all_options = sorted([x.title() for x in list(classifier_dict.keys())])\n",
    "all_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'A General Theory Of Employment, Interest, And Money',\n",
       "  'value': 'A General Theory Of Employment, Interest, And Money'},\n",
       " {'label': 'A Treatise Concerning The Principles Of Human Knowledge',\n",
       "  'value': 'A Treatise Concerning The Principles Of Human Knowledge'},\n",
       " {'label': 'A Treatise Of Human Nature',\n",
       "  'value': 'A Treatise Of Human Nature'},\n",
       " {'label': 'Analytic', 'value': 'Analytic'},\n",
       " {'label': 'Anti-Oedipus', 'value': 'Anti-Oedipus'},\n",
       " {'label': 'Aristotle', 'value': 'Aristotle'},\n",
       " {'label': 'Aristotle - Complete Works',\n",
       "  'value': 'Aristotle - Complete Works'},\n",
       " {'label': 'Being And Time', 'value': 'Being And Time'},\n",
       " {'label': 'Berkeley', 'value': 'Berkeley'},\n",
       " {'label': 'Capital', 'value': 'Capital'},\n",
       " {'label': 'Capitalism', 'value': 'Capitalism'},\n",
       " {'label': 'Communism', 'value': 'Communism'},\n",
       " {'label': 'Continental', 'value': 'Continental'},\n",
       " {'label': 'Critique Of Judgement', 'value': 'Critique Of Judgement'},\n",
       " {'label': 'Critique Of Practical Reason',\n",
       "  'value': 'Critique Of Practical Reason'},\n",
       " {'label': 'Critique Of Pure Reason', 'value': 'Critique Of Pure Reason'},\n",
       " {'label': 'Deleuze', 'value': 'Deleuze'},\n",
       " {'label': 'Derrida', 'value': 'Derrida'},\n",
       " {'label': 'Descartes', 'value': 'Descartes'},\n",
       " {'label': 'Dialogues Concerning Natural Religion',\n",
       "  'value': 'Dialogues Concerning Natural Religion'},\n",
       " {'label': 'Difference And Repetition', 'value': 'Difference And Repetition'},\n",
       " {'label': 'Discourse On Method', 'value': 'Discourse On Method'},\n",
       " {'label': 'Elements Of The Philosophy Of Right',\n",
       "  'value': 'Elements Of The Philosophy Of Right'},\n",
       " {'label': 'Empiricism', 'value': 'Empiricism'},\n",
       " {'label': 'Enchiridion', 'value': 'Enchiridion'},\n",
       " {'label': 'Epictetus', 'value': 'Epictetus'},\n",
       " {'label': 'Essay Concerning Human Understanding',\n",
       "  'value': 'Essay Concerning Human Understanding'},\n",
       " {'label': 'Essential Works Of Lenin', 'value': 'Essential Works Of Lenin'},\n",
       " {'label': 'Ethics', 'value': 'Ethics'},\n",
       " {'label': 'Fichte', 'value': 'Fichte'},\n",
       " {'label': 'Foucault', 'value': 'Foucault'},\n",
       " {'label': 'German Idealism', 'value': 'German Idealism'},\n",
       " {'label': 'Hegel', 'value': 'Hegel'},\n",
       " {'label': 'Heidegger', 'value': 'Heidegger'},\n",
       " {'label': 'Hume', 'value': 'Hume'},\n",
       " {'label': 'Husserl', 'value': 'Husserl'},\n",
       " {'label': 'Kant', 'value': 'Kant'},\n",
       " {'label': 'Keynes', 'value': 'Keynes'},\n",
       " {'label': 'Kripke', 'value': 'Kripke'},\n",
       " {'label': 'Leibniz', 'value': 'Leibniz'},\n",
       " {'label': 'Lenin', 'value': 'Lenin'},\n",
       " {'label': 'Lewis', 'value': 'Lewis'},\n",
       " {'label': 'Lewis - Papers', 'value': 'Lewis - Papers'},\n",
       " {'label': 'Locke', 'value': 'Locke'},\n",
       " {'label': 'Madness And Civilization', 'value': 'Madness And Civilization'},\n",
       " {'label': 'Malebranche', 'value': 'Malebranche'},\n",
       " {'label': 'Marcus Aurelius', 'value': 'Marcus Aurelius'},\n",
       " {'label': 'Marx', 'value': 'Marx'},\n",
       " {'label': 'Meditations', 'value': 'Meditations'},\n",
       " {'label': 'Meditations On First Philosophy',\n",
       "  'value': 'Meditations On First Philosophy'},\n",
       " {'label': 'Merleau-Ponty', 'value': 'Merleau-Ponty'},\n",
       " {'label': 'Moore', 'value': 'Moore'},\n",
       " {'label': 'Naming And Necessity', 'value': 'Naming And Necessity'},\n",
       " {'label': 'Off The Beaten Track', 'value': 'Off The Beaten Track'},\n",
       " {'label': 'On The Improvement Of Understanding',\n",
       "  'value': 'On The Improvement Of Understanding'},\n",
       " {'label': 'On The Principles Of Political Economy And Taxation',\n",
       "  'value': 'On The Principles Of Political Economy And Taxation'},\n",
       " {'label': 'Phenomenology', 'value': 'Phenomenology'},\n",
       " {'label': 'Philosophical Investigations',\n",
       "  'value': 'Philosophical Investigations'},\n",
       " {'label': 'Philosophical Studies', 'value': 'Philosophical Studies'},\n",
       " {'label': 'Philosophical Troubles', 'value': 'Philosophical Troubles'},\n",
       " {'label': 'Plato', 'value': 'Plato'},\n",
       " {'label': 'Plato - Complete Works', 'value': 'Plato - Complete Works'},\n",
       " {'label': 'Popper', 'value': 'Popper'},\n",
       " {'label': 'Quine', 'value': 'Quine'},\n",
       " {'label': 'Quintessence', 'value': 'Quintessence'},\n",
       " {'label': 'Rationalism', 'value': 'Rationalism'},\n",
       " {'label': 'Ricardo', 'value': 'Ricardo'},\n",
       " {'label': 'Russell', 'value': 'Russell'},\n",
       " {'label': 'Science Of Logic', 'value': 'Science Of Logic'},\n",
       " {'label': 'Second Treatise On Government',\n",
       "  'value': 'Second Treatise On Government'},\n",
       " {'label': 'Smith', 'value': 'Smith'},\n",
       " {'label': 'Spinoza', 'value': 'Spinoza'},\n",
       " {'label': 'Stoicism', 'value': 'Stoicism'},\n",
       " {'label': 'The Analysis Of Mind', 'value': 'The Analysis Of Mind'},\n",
       " {'label': 'The Birth Of The Clinic', 'value': 'The Birth Of The Clinic'},\n",
       " {'label': 'The Communist Manifesto', 'value': 'The Communist Manifesto'},\n",
       " {'label': 'The Crisis Of The European Sciences And Phenomenology',\n",
       "  'value': 'The Crisis Of The European Sciences And Phenomenology'},\n",
       " {'label': 'The Idea Of Phenomenology', 'value': 'The Idea Of Phenomenology'},\n",
       " {'label': 'The Logic Of Scientific Discovery',\n",
       "  'value': 'The Logic Of Scientific Discovery'},\n",
       " {'label': 'The Order Of Things', 'value': 'The Order Of Things'},\n",
       " {'label': 'The Phenomenology Of Perception',\n",
       "  'value': 'The Phenomenology Of Perception'},\n",
       " {'label': 'The Phenomenology Of Spirit',\n",
       "  'value': 'The Phenomenology Of Spirit'},\n",
       " {'label': 'The Problems Of Philosophy',\n",
       "  'value': 'The Problems Of Philosophy'},\n",
       " {'label': 'The Search After Truth', 'value': 'The Search After Truth'},\n",
       " {'label': 'The System Of Ethics', 'value': 'The System Of Ethics'},\n",
       " {'label': 'The Wealth Of Nations', 'value': 'The Wealth Of Nations'},\n",
       " {'label': 'Theodicy', 'value': 'Theodicy'},\n",
       " {'label': 'Three Dialogues', 'value': 'Three Dialogues'},\n",
       " {'label': 'Tractatus Logico-Philosophicus',\n",
       "  'value': 'Tractatus Logico-Philosophicus'},\n",
       " {'label': 'Wittgenstein', 'value': 'Wittgenstein'},\n",
       " {'label': 'Writing And Difference', 'value': 'Writing And Difference'}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dropdown_menu = []\n",
    "for source in all_options:\n",
    "    dropdown_menu.append({'label': source, 'value': source})\n",
    "\n",
    "dropdown_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}