{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "learn-env",
   "display_name": "learn-env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      title     author           school  \\\n",
       "116144                  Discourse On Method  Descartes      rationalism   \n",
       "248446         Critique Of Practical Reason       Kant  german_idealism   \n",
       "46974            Aristotle - Complete Works  Aristotle        aristotle   \n",
       "285275  Elements Of The Philosophy Of Right      Hegel  german_idealism   \n",
       "137709                Philosophical Studies      Moore         analytic   \n",
       "\n",
       "                                           sentence_spacy  \\\n",
       "116144  Of this we have abundant proof in the ordinary...   \n",
       "248446  So distinctly and sharply cut are the boundari...   \n",
       "46974   It is impossible, therefore, for anything to b...   \n",
       "285275  This method leaves out of account what is alon...   \n",
       "137709  Perhaps, even, there may be some justification...   \n",
       "\n",
       "                                             sentence_str  sentence_length  \\\n",
       "116144  Of this we have abundant proof in the ordinary...              424   \n",
       "248446  So distinctly and sharply cut are the boundari...              188   \n",
       "46974   It is impossible, therefore, for anything to b...               67   \n",
       "285275  This method leaves out of account what is alon...              118   \n",
       "137709  Perhaps, even, there may be some justification...              339   \n",
       "\n",
       "                                         sentence_lowered  \\\n",
       "116144  of this we have abundant proof in the ordinary...   \n",
       "248446  so distinctly and sharply cut are the boundari...   \n",
       "46974   it is impossible, therefore, for anything to b...   \n",
       "285275  this method leaves out of account what is alon...   \n",
       "137709  perhaps, even, there may be some justification...   \n",
       "\n",
       "                                            tokenized_txt  \\\n",
       "116144  ['of', 'this', 'we', 'have', 'abundant', 'proo...   \n",
       "248446  ['so', 'distinctly', 'and', 'sharply', 'cut', ...   \n",
       "46974   ['it', 'is', 'impossible', 'therefore', 'for',...   \n",
       "285275  ['this', 'method', 'leaves', 'out', 'of', 'acc...   \n",
       "137709  ['perhaps', 'even', 'there', 'may', 'be', 'som...   \n",
       "\n",
       "                                           lemmatized_str  \n",
       "116144   of this -PRON- have abundant proof in the ord...  \n",
       "248446   so distinctly and sharply cut be the boundary...  \n",
       "46974    -PRON- be impossible , therefore , for anythi...  \n",
       "285275   this method leave out of account what be alon...  \n",
       "137709   perhaps , even , there may be some justificat...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author</th>\n      <th>school</th>\n      <th>sentence_spacy</th>\n      <th>sentence_str</th>\n      <th>sentence_length</th>\n      <th>sentence_lowered</th>\n      <th>tokenized_txt</th>\n      <th>lemmatized_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>116144</th>\n      <td>Discourse On Method</td>\n      <td>Descartes</td>\n      <td>rationalism</td>\n      <td>Of this we have abundant proof in the ordinary...</td>\n      <td>Of this we have abundant proof in the ordinary...</td>\n      <td>424</td>\n      <td>of this we have abundant proof in the ordinary...</td>\n      <td>['of', 'this', 'we', 'have', 'abundant', 'proo...</td>\n      <td>of this -PRON- have abundant proof in the ord...</td>\n    </tr>\n    <tr>\n      <th>248446</th>\n      <td>Critique Of Practical Reason</td>\n      <td>Kant</td>\n      <td>german_idealism</td>\n      <td>So distinctly and sharply cut are the boundari...</td>\n      <td>So distinctly and sharply cut are the boundari...</td>\n      <td>188</td>\n      <td>so distinctly and sharply cut are the boundari...</td>\n      <td>['so', 'distinctly', 'and', 'sharply', 'cut', ...</td>\n      <td>so distinctly and sharply cut be the boundary...</td>\n    </tr>\n    <tr>\n      <th>46974</th>\n      <td>Aristotle - Complete Works</td>\n      <td>Aristotle</td>\n      <td>aristotle</td>\n      <td>It is impossible, therefore, for anything to b...</td>\n      <td>It is impossible, therefore, for anything to b...</td>\n      <td>67</td>\n      <td>it is impossible, therefore, for anything to b...</td>\n      <td>['it', 'is', 'impossible', 'therefore', 'for',...</td>\n      <td>-PRON- be impossible , therefore , for anythi...</td>\n    </tr>\n    <tr>\n      <th>285275</th>\n      <td>Elements Of The Philosophy Of Right</td>\n      <td>Hegel</td>\n      <td>german_idealism</td>\n      <td>This method leaves out of account what is alon...</td>\n      <td>This method leaves out of account what is alon...</td>\n      <td>118</td>\n      <td>this method leaves out of account what is alon...</td>\n      <td>['this', 'method', 'leaves', 'out', 'of', 'acc...</td>\n      <td>this method leave out of account what be alon...</td>\n    </tr>\n    <tr>\n      <th>137709</th>\n      <td>Philosophical Studies</td>\n      <td>Moore</td>\n      <td>analytic</td>\n      <td>Perhaps, even, there may be some justification...</td>\n      <td>Perhaps, even, there may be some justification...</td>\n      <td>339</td>\n      <td>perhaps, even, there may be some justification...</td>\n      <td>['perhaps', 'even', 'there', 'may', 'be', 'som...</td>\n      <td>perhaps , even , there may be some justificat...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('phil_nlp.csv')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Analytic           0.168647\n",
       "Aristotle          0.148419\n",
       "German Idealism    0.128210\n",
       "Plato              0.116812\n",
       "Continental        0.102785\n",
       "Phenomenology      0.086939\n",
       "Rationalism        0.069830\n",
       "Empiricism         0.060644\n",
       "Capitalism         0.055359\n",
       "Communism          0.054644\n",
       "Stoicism           0.007713\n",
       "Name: school, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df['school'] = df['school'].apply(lambda x: x.replace('_', ' ').title())\n",
    "df['school'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\kcali\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import wordcloud\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import plotly.express as px \n",
    "import pandas as pd\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "classifier_dict = {}\n",
    "for author in df['author'].unique():\n",
    "  classifier_dict[author] = 'author'\n",
    "for title in df['title'].unique():\n",
    "  classifier_dict[title] = 'title'\n",
    "for school in df['school'].unique():\n",
    "  classifier_dict[school] = 'school'\n",
    "\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation) \n",
    "stopwords_list += ['“','”','...',\"''\",'’','``', \"'\", \"‘\"]\n",
    "custom_stopwords = ['–', 'also', 'something', 'cf', 'thus', 'two', 'now', 'would', \n",
    "                    'make', 'eb', 'u', 'well', 'even', 'said', 'eg', 'us',\n",
    "                    'n', 'sein', 'e', 'da', 'therefore', 'however', 'would', \n",
    "                    'thing', 'must', 'merely', 'way', 'since', 'latter', 'first',\n",
    "                    'B', 'mean', 'upon', 'yet', 'cannot', 'c', 'C', 'let', 'may', \n",
    "                    'might', \"'s\", 'b', 'ofthe', 'p.', '_', '-', 'eg', 'e.g.',\n",
    "                    'ie', 'i.e.', 'f', 'l', \"n't\", 'e.g', 'i.e', '—', '--', \n",
    "                    'hyl', 'phil', 'one', 'another', 'could', 'come', 'things', 'thing',\n",
    "                    'else', 'every', 'shall'] + stopwords_list\n",
    "\n",
    "df['gensim_tokenized'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
    "                                                        max_len=500))\n",
    "\n",
    "def get_average_word_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', '[']\n",
    "  num_words = 0\n",
    "  sum_word_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    sentence_list = [re.sub(\"[',]\", '', word) for word in sentence_list]\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    for word in no_punctuation_tokens:\n",
    "      num_words += 1\n",
    "      sum_word_lengths += len(word)\n",
    "  return round((sum_word_lengths / num_words), 2)\n",
    "\n",
    "def get_average_sentence_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  num_sentences = 0\n",
    "  sum_sentence_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_sentences += 1\n",
    "    sum_sentence_lengths += len(no_punctuation_tokens)\n",
    "  return round(sum_sentence_lengths / num_sentences, 2)\n",
    "\n",
    "def make_word_cloud(input, df, classifier, stopwords=stopwords.words('english')):\n",
    "    text = ''\n",
    "    for sentence in df[df[classifier[input]]==input]['sentence_str']:\n",
    "      text += sentence\n",
    "    cloud = wordcloud.WordCloud(width=500, \n",
    "                            height=400, \n",
    "                            background_color='#D1D1D1', \n",
    "                            max_words=30, \n",
    "                            stopwords=stopwords, \n",
    "                            color_func=lambda *args, **kwargs: (95,95,95)).generate(text)\n",
    "    return cloud\n",
    "\n",
    "def get_num_unique_words(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  word_list = []\n",
    "  num_words = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_words += len(no_punctuation_tokens)\n",
    "    for word in no_punctuation_tokens:\n",
    "      word_list.append(word)\n",
    "  num_unique_words = len(set(word_list))\n",
    "  return num_unique_words, num_words\n",
    "\n",
    "def plot_word_frequency(input, df, classifier_dict, stopwords):\n",
    "  word_list = []\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['gensim_tokenized'][:50]:\n",
    "    for word in sentence:\n",
    "      word_list.append(word)\n",
    "  cleaned_words = [x.lower() for x in word_list if x.lower() not in stopwords]\n",
    "  freq_dist = FreqDist(cleaned_words)\n",
    "  freq_dict = {'words': [x[0] for x in freq_dist.most_common(7)], \n",
    "              'frequency': [x[1] for x in freq_dist.most_common(7)]}\n",
    "  freq_df = pd.DataFrame(freq_dict)\n",
    "  fig = px.bar(freq_df,\n",
    "              x='words',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Words')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} Word Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def plot_ngram_frequency(input, df, classifier_dict, stopwords): \n",
    "  word_list = []\n",
    "  for sent in df[df[classifier_dict[input]]==input]['gensim_tokenized']:\n",
    "    for word in sent:\n",
    "      word_list.append(word)\n",
    "  cleaned = [word.lower() for word in word_list if word not in custom_stopwords]\n",
    "  bigram_finder = BigramCollocationFinder.from_words(cleaned, window_size=3)\n",
    "  top_10 = sorted(bigram_finder.ngram_fd.items(), key=lambda t: (-t[1], t[0]))[:7]\n",
    "  bigram_df = pd.DataFrame(top_10, columns=['bigram', 'frequency'])\n",
    "  bigram_df['bigram'] = bigram_df['bigram'].apply(lambda x: ', '.join(x))\n",
    "  fig = px.bar(bigram_df,\n",
    "              x='bigram',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Phrases')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} N-gram Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def get_title_list(input, df, classifier_dict):\n",
    "  title_list = list(df[df[classifier_dict[input]]==input]['title'].unique())\n",
    "  title_list = [title.title() for title in title_list] \n",
    "  return ', '.join(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict_master = {}\n",
    "for option in classifier_dict.keys():\n",
    "    stats_dict = {}\n",
    "    stats_dict['title_list'] = get_title_list(option, df, classifier_dict)\n",
    "    stats_dict['ngram_chart'] = plot_ngram_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['word_freq_chart'] = plot_word_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['num_unique'] = get_num_unique_words(option, df, classifier_dict)\n",
    "    stats_dict['mean_sent_length'] = get_average_sentence_length(option, df, classifier_dict)\n",
    "    stats_dict['mean_word_length'] = get_average_word_length(option, df, classifier_dict)\n",
    "    stats_dict_master[option] = stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'title_list': 'Enchiridion, Meditations',\n",
       " 'ngram_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'bigram=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['unto, thee', 'thou, art', 'thou, shalt', 'thou, hast', 'thee, thou',\n",
       "                           'thou, dost', 'thy, mind'], dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([93, 92, 87, 65, 64, 54, 51], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Stoicism N-gram Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Phrases'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'word_freq_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'words=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['power', 'others', 'within', 'say', 'nature', 'elated', 'desire'],\n",
       "                          dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([13,  9,  8,  8,  7,  6,  5], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Stoicism Word Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Words'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'num_unique': (5999, 62624),\n",
       " 'mean_sent_length': 24.7,\n",
       " 'mean_word_length': 4.47}"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "stats_dict_master['Stoicism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for option in stats_dict_master.keys():\n",
    "    dict_pkl = open(f'../stats_app/stats_pickles/{option.title()}_stats.pkl', 'wb')\n",
    "    pickle.dump(stats_dict_master[option], dict_pkl)\n",
    "    dict_pkl.close()\n"
   ]
  },
  {
   "source": [
    "Now we get the updated dropdown menu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['A General Theory Of Employment, Interest, And Money',\n",
       " 'A Treatise Concerning The Principles Of Human Knowledge',\n",
       " 'A Treatise Of Human Nature',\n",
       " 'Analytic',\n",
       " 'Anti-Oedipus',\n",
       " 'Aristotle',\n",
       " 'Aristotle - Complete Works',\n",
       " 'Being And Time',\n",
       " 'Berkeley',\n",
       " 'Capital',\n",
       " 'Capitalism',\n",
       " 'Communism',\n",
       " 'Continental',\n",
       " 'Critique Of Judgement',\n",
       " 'Critique Of Practical Reason',\n",
       " 'Critique Of Pure Reason',\n",
       " 'Deleuze',\n",
       " 'Derrida',\n",
       " 'Descartes',\n",
       " 'Dialogues Concerning Natural Religion',\n",
       " 'Difference And Repetition',\n",
       " 'Discourse On Method',\n",
       " 'Elements Of The Philosophy Of Right',\n",
       " 'Empiricism',\n",
       " 'Enchiridion',\n",
       " 'Epictetus',\n",
       " 'Essay Concerning Human Understanding',\n",
       " 'Essential Works Of Lenin',\n",
       " 'Ethics',\n",
       " 'Fichte',\n",
       " 'Foucault',\n",
       " 'German Idealism',\n",
       " 'Hegel',\n",
       " 'Heidegger',\n",
       " 'Hume',\n",
       " 'Husserl',\n",
       " 'Kant',\n",
       " 'Keynes',\n",
       " 'Kripke',\n",
       " 'Leibniz',\n",
       " 'Lenin',\n",
       " 'Lewis',\n",
       " 'Lewis - Papers',\n",
       " 'Locke',\n",
       " 'Madness And Civilization',\n",
       " 'Malebranche',\n",
       " 'Marcus Aurelius',\n",
       " 'Marx',\n",
       " 'Meditations',\n",
       " 'Meditations On First Philosophy',\n",
       " 'Merleau-Ponty',\n",
       " 'Moore',\n",
       " 'Naming And Necessity',\n",
       " 'Off The Beaten Track',\n",
       " 'On Certainty',\n",
       " 'On The Improvement Of Understanding',\n",
       " 'On The Principles Of Political Economy And Taxation',\n",
       " 'Phenomenology',\n",
       " 'Philosophical Investigations',\n",
       " 'Philosophical Studies',\n",
       " 'Philosophical Troubles',\n",
       " 'Plato',\n",
       " 'Plato - Complete Works',\n",
       " 'Popper',\n",
       " 'Quine',\n",
       " 'Quintessence',\n",
       " 'Rationalism',\n",
       " 'Ricardo',\n",
       " 'Russell',\n",
       " 'Science Of Logic',\n",
       " 'Second Treatise On Government',\n",
       " 'Smith',\n",
       " 'Spinoza',\n",
       " 'Stoicism',\n",
       " 'The Analysis Of Mind',\n",
       " 'The Birth Of The Clinic',\n",
       " 'The Communist Manifesto',\n",
       " 'The Crisis Of The European Sciences And Phenomenology',\n",
       " 'The Idea Of Phenomenology',\n",
       " 'The Logic Of Scientific Discovery',\n",
       " 'The Order Of Things',\n",
       " 'The Phenomenology Of Perception',\n",
       " 'The Phenomenology Of Spirit',\n",
       " 'The Problems Of Philosophy',\n",
       " 'The Search After Truth',\n",
       " 'The System Of Ethics',\n",
       " 'The Wealth Of Nations',\n",
       " 'Theodicy',\n",
       " 'Three Dialogues',\n",
       " 'Tractatus Logico-Philosophicus',\n",
       " 'Wittgenstein',\n",
       " 'Writing And Difference']"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "all_options = sorted([x.title() for x in list(classifier_dict.keys())])\n",
    "all_options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'A General Theory Of Employment, Interest, And Money',\n",
       "  'value': 'A General Theory Of Employment, Interest, And Money'},\n",
       " {'label': 'A Treatise Concerning The Principles Of Human Knowledge',\n",
       "  'value': 'A Treatise Concerning The Principles Of Human Knowledge'},\n",
       " {'label': 'A Treatise Of Human Nature',\n",
       "  'value': 'A Treatise Of Human Nature'},\n",
       " {'label': 'Analytic', 'value': 'Analytic'},\n",
       " {'label': 'Anti-Oedipus', 'value': 'Anti-Oedipus'},\n",
       " {'label': 'Aristotle', 'value': 'Aristotle'},\n",
       " {'label': 'Aristotle - Complete Works',\n",
       "  'value': 'Aristotle - Complete Works'},\n",
       " {'label': 'Being And Time', 'value': 'Being And Time'},\n",
       " {'label': 'Berkeley', 'value': 'Berkeley'},\n",
       " {'label': 'Capital', 'value': 'Capital'},\n",
       " {'label': 'Capitalism', 'value': 'Capitalism'},\n",
       " {'label': 'Communism', 'value': 'Communism'},\n",
       " {'label': 'Continental', 'value': 'Continental'},\n",
       " {'label': 'Critique Of Judgement', 'value': 'Critique Of Judgement'},\n",
       " {'label': 'Critique Of Practical Reason',\n",
       "  'value': 'Critique Of Practical Reason'},\n",
       " {'label': 'Critique Of Pure Reason', 'value': 'Critique Of Pure Reason'},\n",
       " {'label': 'Deleuze', 'value': 'Deleuze'},\n",
       " {'label': 'Derrida', 'value': 'Derrida'},\n",
       " {'label': 'Descartes', 'value': 'Descartes'},\n",
       " {'label': 'Dialogues Concerning Natural Religion',\n",
       "  'value': 'Dialogues Concerning Natural Religion'},\n",
       " {'label': 'Difference And Repetition', 'value': 'Difference And Repetition'},\n",
       " {'label': 'Discourse On Method', 'value': 'Discourse On Method'},\n",
       " {'label': 'Elements Of The Philosophy Of Right',\n",
       "  'value': 'Elements Of The Philosophy Of Right'},\n",
       " {'label': 'Empiricism', 'value': 'Empiricism'},\n",
       " {'label': 'Enchiridion', 'value': 'Enchiridion'},\n",
       " {'label': 'Epictetus', 'value': 'Epictetus'},\n",
       " {'label': 'Essay Concerning Human Understanding',\n",
       "  'value': 'Essay Concerning Human Understanding'},\n",
       " {'label': 'Essential Works Of Lenin', 'value': 'Essential Works Of Lenin'},\n",
       " {'label': 'Ethics', 'value': 'Ethics'},\n",
       " {'label': 'Fichte', 'value': 'Fichte'},\n",
       " {'label': 'Foucault', 'value': 'Foucault'},\n",
       " {'label': 'German Idealism', 'value': 'German Idealism'},\n",
       " {'label': 'Hegel', 'value': 'Hegel'},\n",
       " {'label': 'Heidegger', 'value': 'Heidegger'},\n",
       " {'label': 'Hume', 'value': 'Hume'},\n",
       " {'label': 'Husserl', 'value': 'Husserl'},\n",
       " {'label': 'Kant', 'value': 'Kant'},\n",
       " {'label': 'Keynes', 'value': 'Keynes'},\n",
       " {'label': 'Kripke', 'value': 'Kripke'},\n",
       " {'label': 'Leibniz', 'value': 'Leibniz'},\n",
       " {'label': 'Lenin', 'value': 'Lenin'},\n",
       " {'label': 'Lewis', 'value': 'Lewis'},\n",
       " {'label': 'Lewis - Papers', 'value': 'Lewis - Papers'},\n",
       " {'label': 'Locke', 'value': 'Locke'},\n",
       " {'label': 'Madness And Civilization', 'value': 'Madness And Civilization'},\n",
       " {'label': 'Malebranche', 'value': 'Malebranche'},\n",
       " {'label': 'Marcus Aurelius', 'value': 'Marcus Aurelius'},\n",
       " {'label': 'Marx', 'value': 'Marx'},\n",
       " {'label': 'Meditations', 'value': 'Meditations'},\n",
       " {'label': 'Meditations On First Philosophy',\n",
       "  'value': 'Meditations On First Philosophy'},\n",
       " {'label': 'Merleau-Ponty', 'value': 'Merleau-Ponty'},\n",
       " {'label': 'Moore', 'value': 'Moore'},\n",
       " {'label': 'Naming And Necessity', 'value': 'Naming And Necessity'},\n",
       " {'label': 'Off The Beaten Track', 'value': 'Off The Beaten Track'},\n",
       " {'label': 'On Certainty', 'value': 'On Certainty'},\n",
       " {'label': 'On The Improvement Of Understanding',\n",
       "  'value': 'On The Improvement Of Understanding'},\n",
       " {'label': 'On The Principles Of Political Economy And Taxation',\n",
       "  'value': 'On The Principles Of Political Economy And Taxation'},\n",
       " {'label': 'Phenomenology', 'value': 'Phenomenology'},\n",
       " {'label': 'Philosophical Investigations',\n",
       "  'value': 'Philosophical Investigations'},\n",
       " {'label': 'Philosophical Studies', 'value': 'Philosophical Studies'},\n",
       " {'label': 'Philosophical Troubles', 'value': 'Philosophical Troubles'},\n",
       " {'label': 'Plato', 'value': 'Plato'},\n",
       " {'label': 'Plato - Complete Works', 'value': 'Plato - Complete Works'},\n",
       " {'label': 'Popper', 'value': 'Popper'},\n",
       " {'label': 'Quine', 'value': 'Quine'},\n",
       " {'label': 'Quintessence', 'value': 'Quintessence'},\n",
       " {'label': 'Rationalism', 'value': 'Rationalism'},\n",
       " {'label': 'Ricardo', 'value': 'Ricardo'},\n",
       " {'label': 'Russell', 'value': 'Russell'},\n",
       " {'label': 'Science Of Logic', 'value': 'Science Of Logic'},\n",
       " {'label': 'Second Treatise On Government',\n",
       "  'value': 'Second Treatise On Government'},\n",
       " {'label': 'Smith', 'value': 'Smith'},\n",
       " {'label': 'Spinoza', 'value': 'Spinoza'},\n",
       " {'label': 'Stoicism', 'value': 'Stoicism'},\n",
       " {'label': 'The Analysis Of Mind', 'value': 'The Analysis Of Mind'},\n",
       " {'label': 'The Birth Of The Clinic', 'value': 'The Birth Of The Clinic'},\n",
       " {'label': 'The Communist Manifesto', 'value': 'The Communist Manifesto'},\n",
       " {'label': 'The Crisis Of The European Sciences And Phenomenology',\n",
       "  'value': 'The Crisis Of The European Sciences And Phenomenology'},\n",
       " {'label': 'The Idea Of Phenomenology', 'value': 'The Idea Of Phenomenology'},\n",
       " {'label': 'The Logic Of Scientific Discovery',\n",
       "  'value': 'The Logic Of Scientific Discovery'},\n",
       " {'label': 'The Order Of Things', 'value': 'The Order Of Things'},\n",
       " {'label': 'The Phenomenology Of Perception',\n",
       "  'value': 'The Phenomenology Of Perception'},\n",
       " {'label': 'The Phenomenology Of Spirit',\n",
       "  'value': 'The Phenomenology Of Spirit'},\n",
       " {'label': 'The Problems Of Philosophy',\n",
       "  'value': 'The Problems Of Philosophy'},\n",
       " {'label': 'The Search After Truth', 'value': 'The Search After Truth'},\n",
       " {'label': 'The System Of Ethics', 'value': 'The System Of Ethics'},\n",
       " {'label': 'The Wealth Of Nations', 'value': 'The Wealth Of Nations'},\n",
       " {'label': 'Theodicy', 'value': 'Theodicy'},\n",
       " {'label': 'Three Dialogues', 'value': 'Three Dialogues'},\n",
       " {'label': 'Tractatus Logico-Philosophicus',\n",
       "  'value': 'Tractatus Logico-Philosophicus'},\n",
       " {'label': 'Wittgenstein', 'value': 'Wittgenstein'},\n",
       " {'label': 'Writing And Difference', 'value': 'Writing And Difference'}]"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "dropdown_menu = []\n",
    "for source in all_options:\n",
    "    dropdown_menu.append({'label': source, 'value': source})\n",
    "\n",
    "dropdown_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}