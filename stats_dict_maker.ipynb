{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "learn-env",
   "display_name": "learn-env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\kcali\\anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3072: DtypeWarning: Columns (8) have mixed types.Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                      title        author           school  \\\n",
       "262034                 The System Of Ethics        Fichte  german_idealism   \n",
       "261349              Critique Of Pure Reason          Kant  german_idealism   \n",
       "319166                The Wealth Of Nations         Smith       capitalism   \n",
       "139015         Philosophical Investigations  Wittgenstein         analytic   \n",
       "288478  Elements Of The Philosophy Of Right         Hegel  german_idealism   \n",
       "\n",
       "                                           sentence_spacy  \\\n",
       "262034          may want to express it in words, for this   \n",
       "261349  Transcendental hypotheses of the speculative u...   \n",
       "319166                    , or a year, for sixteen years.   \n",
       "139015  Of course it is possible to substitute the for...   \n",
       "288478  Translator's note: ist nur das Recht als solch...   \n",
       "\n",
       "                                             sentence_str  \\\n",
       "262034          may want to express it in words, for this   \n",
       "261349  Transcendental hypotheses of the speculative u...   \n",
       "319166                    , or a year, for sixteen years.   \n",
       "139015  Of course it is possible to substitute the for...   \n",
       "288478  Translator's note: ist nur das Recht als solch...   \n",
       "\n",
       "        original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "262034                       1798                 2005               41   \n",
       "261349                       1781                 1998              429   \n",
       "319166                       1776                 2009               31   \n",
       "139015                       1953                 1986              107   \n",
       "288478                       1820                 1991               59   \n",
       "\n",
       "                                         sentence_lowered  \\\n",
       "262034          may want to express it in words, for this   \n",
       "261349  transcendental hypotheses of the speculative u...   \n",
       "319166                    , or a year, for sixteen years.   \n",
       "139015  of course it is possible to substitute the for...   \n",
       "288478  translator's note: ist nur das recht als solch...   \n",
       "\n",
       "                                            tokenized_txt  \\\n",
       "262034  ['may', 'want', 'to', 'express', 'it', 'in', '...   \n",
       "261349  ['transcendental', 'hypotheses', 'of', 'the', ...   \n",
       "319166          ['or', 'year', 'for', 'sixteen', 'years']   \n",
       "139015  ['of', 'course', 'it', 'is', 'possible', 'to',...   \n",
       "288478  ['translator', 'note', 'ist', 'nur', 'das', 'r...   \n",
       "\n",
       "                                           lemmatized_str  \n",
       "262034      may want to express -PRON- in word , for this  \n",
       "261349   transcendental hypothesis of the speculative ...  \n",
       "319166                   , or a year , for sixteen year .  \n",
       "139015   of course -PRON- be possible to substitute th...  \n",
       "288478   translator 's note : ist nur das recht als so...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author</th>\n      <th>school</th>\n      <th>sentence_spacy</th>\n      <th>sentence_str</th>\n      <th>original_publication_date</th>\n      <th>corpus_edition_date</th>\n      <th>sentence_length</th>\n      <th>sentence_lowered</th>\n      <th>tokenized_txt</th>\n      <th>lemmatized_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>262034</th>\n      <td>The System Of Ethics</td>\n      <td>Fichte</td>\n      <td>german_idealism</td>\n      <td>may want to express it in words, for this</td>\n      <td>may want to express it in words, for this</td>\n      <td>1798</td>\n      <td>2005</td>\n      <td>41</td>\n      <td>may want to express it in words, for this</td>\n      <td>['may', 'want', 'to', 'express', 'it', 'in', '...</td>\n      <td>may want to express -PRON- in word , for this</td>\n    </tr>\n    <tr>\n      <th>261349</th>\n      <td>Critique Of Pure Reason</td>\n      <td>Kant</td>\n      <td>german_idealism</td>\n      <td>Transcendental hypotheses of the speculative u...</td>\n      <td>Transcendental hypotheses of the speculative u...</td>\n      <td>1781</td>\n      <td>1998</td>\n      <td>429</td>\n      <td>transcendental hypotheses of the speculative u...</td>\n      <td>['transcendental', 'hypotheses', 'of', 'the', ...</td>\n      <td>transcendental hypothesis of the speculative ...</td>\n    </tr>\n    <tr>\n      <th>319166</th>\n      <td>The Wealth Of Nations</td>\n      <td>Smith</td>\n      <td>capitalism</td>\n      <td>, or a year, for sixteen years.</td>\n      <td>, or a year, for sixteen years.</td>\n      <td>1776</td>\n      <td>2009</td>\n      <td>31</td>\n      <td>, or a year, for sixteen years.</td>\n      <td>['or', 'year', 'for', 'sixteen', 'years']</td>\n      <td>, or a year , for sixteen year .</td>\n    </tr>\n    <tr>\n      <th>139015</th>\n      <td>Philosophical Investigations</td>\n      <td>Wittgenstein</td>\n      <td>analytic</td>\n      <td>Of course it is possible to substitute the for...</td>\n      <td>Of course it is possible to substitute the for...</td>\n      <td>1953</td>\n      <td>1986</td>\n      <td>107</td>\n      <td>of course it is possible to substitute the for...</td>\n      <td>['of', 'course', 'it', 'is', 'possible', 'to',...</td>\n      <td>of course -PRON- be possible to substitute th...</td>\n    </tr>\n    <tr>\n      <th>288478</th>\n      <td>Elements Of The Philosophy Of Right</td>\n      <td>Hegel</td>\n      <td>german_idealism</td>\n      <td>Translator's note: ist nur das Recht als solch...</td>\n      <td>Translator's note: ist nur das Recht als solch...</td>\n      <td>1820</td>\n      <td>1991</td>\n      <td>59</td>\n      <td>translator's note: ist nur das recht als solch...</td>\n      <td>['translator', 'note', 'ist', 'nur', 'das', 'r...</td>\n      <td>translator 's note : ist nur das recht als so...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('phil_nlp.csv')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Analytic           0.139811\n",
       "Aristotle          0.123047\n",
       "German Idealism    0.106279\n",
       "Plato              0.096779\n",
       "Continental        0.085209\n",
       "Phenomenology      0.072076\n",
       "Rationalism        0.057890\n",
       "Empiricism         0.050277\n",
       "Scholasticism      0.047010\n",
       "Capitalism         0.045895\n",
       "Communism          0.045300\n",
       "Existentialism     0.034539\n",
       "Feminism           0.026487\n",
       "Stoicism           0.019055\n",
       "Nietzsche          0.017189\n",
       "Daoism             0.014807\n",
       "Hobbes             0.013902\n",
       "Kierkegaard        0.004450\n",
       "Name: school, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df['school'] = df['school'].apply(lambda x: x.replace('_', ' ').title())\n",
    "df['school'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\kcali\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import wordcloud\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import plotly.express as px \n",
    "import pandas as pd\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "classifier_dict = {}\n",
    "for author in df['author'].unique():\n",
    "  classifier_dict[author] = 'author'\n",
    "for title in df['title'].unique():\n",
    "  classifier_dict[title] = 'title'\n",
    "for school in df['school'].unique():\n",
    "  classifier_dict[school] = 'school'\n",
    "\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation) \n",
    "stopwords_list += ['“','”','...',\"''\",'’','``', \"'\", \"‘\"]\n",
    "custom_stopwords = ['–', 'also', 'something', 'cf', 'thus', 'two', 'now', 'would', \n",
    "                    'make', 'eb', 'u', 'well', 'even', 'said', 'eg', 'us',\n",
    "                    'n', 'sein', 'e', 'da', 'therefore', 'however', 'would', \n",
    "                    'thing', 'must', 'merely', 'way', 'since', 'latter', 'first',\n",
    "                    'B', 'mean', 'upon', 'yet', 'cannot', 'c', 'C', 'let', 'may', \n",
    "                    'might', \"'s\", 'b', 'ofthe', 'p.', '_', '-', 'eg', 'e.g.',\n",
    "                    'ie', 'i.e.', 'f', 'l', \"n't\", 'e.g', 'i.e', '—', '--', \n",
    "                    'hyl', 'phil', 'one', 'another', 'could', 'come', 'things', 'thing',\n",
    "                    'else', 'every', 'shall', 'thee', 'thy', 'thou', 'unto'] + stopwords_list\n",
    "\n",
    "df['gensim_tokenized'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
    "                                                        max_len=500))\n",
    "\n",
    "def get_average_word_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', '[']\n",
    "  num_words = 0\n",
    "  sum_word_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    sentence_list = [re.sub(\"[',]\", '', word) for word in sentence_list]\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    for word in no_punctuation_tokens:\n",
    "      num_words += 1\n",
    "      sum_word_lengths += len(word)\n",
    "  return round((sum_word_lengths / num_words), 2)\n",
    "\n",
    "def get_average_sentence_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  num_sentences = 0\n",
    "  sum_sentence_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_sentences += 1\n",
    "    sum_sentence_lengths += len(no_punctuation_tokens)\n",
    "  return round(sum_sentence_lengths / num_sentences, 2)\n",
    "\n",
    "def make_word_cloud(input, df, classifier, stopwords=stopwords.words('english')):\n",
    "    text = ''\n",
    "    for sentence in df[df[classifier[input]]==input]['sentence_str']:\n",
    "      text += sentence\n",
    "    cloud = wordcloud.WordCloud(width=500, \n",
    "                            height=400, \n",
    "                            background_color='#D1D1D1', \n",
    "                            max_words=30, \n",
    "                            stopwords=stopwords, \n",
    "                            color_func=lambda *args, **kwargs: (95,95,95)).generate(text)\n",
    "    return cloud\n",
    "\n",
    "def get_num_unique_words(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  word_list = []\n",
    "  num_words = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_words += len(no_punctuation_tokens)\n",
    "    for word in no_punctuation_tokens:\n",
    "      word_list.append(word)\n",
    "  num_unique_words = len(set(word_list))\n",
    "  return num_unique_words, num_words\n",
    "\n",
    "def plot_word_frequency(input, df, classifier_dict, stopwords):\n",
    "  word_list = []\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['gensim_tokenized']:\n",
    "    for word in sentence:\n",
    "      word_list.append(word)\n",
    "  cleaned_words = [x.lower() for x in word_list if x.lower() not in stopwords]\n",
    "  freq_dist = FreqDist(cleaned_words)\n",
    "  freq_dict = {'words': [x[0] for x in freq_dist.most_common(7)], \n",
    "              'frequency': [x[1] for x in freq_dist.most_common(7)]}\n",
    "  freq_df = pd.DataFrame(freq_dict)\n",
    "  fig = px.bar(freq_df,\n",
    "              x='words',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Words')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} Word Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def plot_ngram_frequency(input, df, classifier_dict, stopwords): \n",
    "  word_list = []\n",
    "  for sent in df[df[classifier_dict[input]]==input]['gensim_tokenized']:\n",
    "    for word in sent:\n",
    "      word_list.append(word)\n",
    "  cleaned = [word.lower() for word in word_list if word not in custom_stopwords]\n",
    "  bigram_finder = BigramCollocationFinder.from_words(cleaned, window_size=3)\n",
    "  top_10 = sorted(bigram_finder.ngram_fd.items(), key=lambda t: (-t[1], t[0]))[:7]\n",
    "  bigram_df = pd.DataFrame(top_10, columns=['bigram', 'frequency'])\n",
    "  bigram_df['bigram'] = bigram_df['bigram'].apply(lambda x: ', '.join(x))\n",
    "  fig = px.bar(bigram_df,\n",
    "              x='bigram',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Phrases')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} N-gram Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def get_title_list(input, df, classifier_dict):\n",
    "  title_list = list(df[df[classifier_dict[input]]==input]['title'].unique())\n",
    "  title_list = [title.title() for title in title_list] \n",
    "  return ', '.join(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict_master = {}\n",
    "for option in classifier_dict.keys():\n",
    "    stats_dict = {}\n",
    "    stats_dict['title_list'] = get_title_list(option, df, classifier_dict)\n",
    "    stats_dict['ngram_chart'] = plot_ngram_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['word_freq_chart'] = plot_word_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['num_unique'] = get_num_unique_words(option, df, classifier_dict)\n",
    "    stats_dict['mean_sent_length'] = get_average_sentence_length(option, df, classifier_dict)\n",
    "    stats_dict['mean_word_length'] = get_average_word_length(option, df, classifier_dict)\n",
    "    stats_dict_master[option] = stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'title_list': 'The Book Of Zhuangzi ',\n",
       " 'ngram_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'bigram=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['heaven, earth', 'chuang, tzu', 'whole, world', 'lao, tzu',\n",
       "                           'innate, nature', 'benevolence, righteousness', 'forms, life'],\n",
       "                          dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([104,  99,  78,  66,  53,  51,  47], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Daoism N-gram Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Phrases'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'word_freq_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'words=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['heaven', 'people', 'tzu', 'tao', 'like', 'life', 'great'], dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([411, 403, 372, 348, 337, 282, 275], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Daoism Word Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Words'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'num_unique': (8912, 92254),\n",
       " 'mean_sent_length': 15.72,\n",
       " 'mean_word_length': 4.42}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "stats_dict_master['Daoism']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for option in stats_dict_master.keys():\n",
    "    dict_pkl = open(f'../apps/stats_app/stats_pickles/{option.title()}_stats.pkl', 'wb')\n",
    "    pickle.dump(stats_dict_master[option], dict_pkl)\n",
    "    dict_pkl.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_options = sorted([x.title() for x in list(classifier_dict.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'A General Theory Of Employment, Interest, And Money',\n",
       "  'value': 'A General Theory Of Employment, Interest, And Money'},\n",
       " {'label': 'A Treatise Concerning The Principles Of Human Knowledge',\n",
       "  'value': 'A Treatise Concerning The Principles Of Human Knowledge'},\n",
       " {'label': 'A Treatise Of Human Nature',\n",
       "  'value': 'A Treatise Of Human Nature'},\n",
       " {'label': 'Analytic', 'value': 'Analytic'},\n",
       " {'label': 'Anselm', 'value': 'Anselm'},\n",
       " {'label': 'Anti-Oedipus', 'value': 'Anti-Oedipus'},\n",
       " {'label': 'Aristotle', 'value': 'Aristotle'},\n",
       " {'label': 'Aristotle - Complete Works',\n",
       "  'value': 'Aristotle - Complete Works'},\n",
       " {'label': 'Augustine', 'value': 'Augustine'},\n",
       " {'label': 'Beauvoir', 'value': 'Beauvoir'},\n",
       " {'label': 'Being And Nothingness', 'value': 'Being And Nothingness'},\n",
       " {'label': 'Being And Time', 'value': 'Being And Time'},\n",
       " {'label': 'Berkeley', 'value': 'Berkeley'},\n",
       " {'label': 'Beyond Good And Evil', 'value': 'Beyond Good And Evil'},\n",
       " {'label': 'Capital', 'value': 'Capital'},\n",
       " {'label': 'Capitalism', 'value': 'Capitalism'},\n",
       " {'label': 'Communism', 'value': 'Communism'},\n",
       " {'label': 'Confessions', 'value': 'Confessions'},\n",
       " {'label': 'Continental', 'value': 'Continental'},\n",
       " {'label': 'Critique Of Judgement', 'value': 'Critique Of Judgement'},\n",
       " {'label': 'Critique Of Practical Reason',\n",
       "  'value': 'Critique Of Practical Reason'},\n",
       " {'label': 'Critique Of Pure Reason', 'value': 'Critique Of Pure Reason'},\n",
       " {'label': 'Daoism', 'value': 'Daoism'},\n",
       " {'label': 'Davis', 'value': 'Davis'},\n",
       " {'label': 'De Veritate', 'value': 'De Veritate'},\n",
       " {'label': 'Deleuze', 'value': 'Deleuze'},\n",
       " {'label': 'Derrida', 'value': 'Derrida'},\n",
       " {'label': 'Descartes', 'value': 'Descartes'},\n",
       " {'label': 'Dialogues Concerning Natural Religion',\n",
       "  'value': 'Dialogues Concerning Natural Religion'},\n",
       " {'label': 'Difference And Repetition', 'value': 'Difference And Repetition'},\n",
       " {'label': 'Discourse On Method', 'value': 'Discourse On Method'},\n",
       " {'label': 'Ecce Homo', 'value': 'Ecce Homo'},\n",
       " {'label': 'Elements Of The Philosophy Of Right',\n",
       "  'value': 'Elements Of The Philosophy Of Right'},\n",
       " {'label': 'Empiricism', 'value': 'Empiricism'},\n",
       " {'label': 'Enchiridion', 'value': 'Enchiridion'},\n",
       " {'label': 'Epictetus', 'value': 'Epictetus'},\n",
       " {'label': 'Essay Concerning Human Understanding',\n",
       "  'value': 'Essay Concerning Human Understanding'},\n",
       " {'label': 'Essential Works Of Lenin', 'value': 'Essential Works Of Lenin'},\n",
       " {'label': 'Ethics', 'value': 'Ethics'},\n",
       " {'label': 'Existentialism', 'value': 'Existentialism'},\n",
       " {'label': 'Fear And Trembling', 'value': 'Fear And Trembling'},\n",
       " {'label': 'Feminism', 'value': 'Feminism'},\n",
       " {'label': 'Fichte', 'value': 'Fichte'},\n",
       " {'label': 'Foucault', 'value': 'Foucault'},\n",
       " {'label': 'German Idealism', 'value': 'German Idealism'},\n",
       " {'label': 'Hegel', 'value': 'Hegel'},\n",
       " {'label': 'Heidegger', 'value': 'Heidegger'},\n",
       " {'label': 'History Of Madness', 'value': 'History Of Madness'},\n",
       " {'label': 'Hobbes', 'value': 'Hobbes'},\n",
       " {'label': 'Hume', 'value': 'Hume'},\n",
       " {'label': 'Husserl', 'value': 'Husserl'},\n",
       " {'label': 'Kant', 'value': 'Kant'},\n",
       " {'label': 'Keynes', 'value': 'Keynes'},\n",
       " {'label': 'Kierkegaard', 'value': 'Kierkegaard'},\n",
       " {'label': 'Kripke', 'value': 'Kripke'},\n",
       " {'label': 'Leibniz', 'value': 'Leibniz'},\n",
       " {'label': 'Lenin', 'value': 'Lenin'},\n",
       " {'label': 'Leviathan', 'value': 'Leviathan'},\n",
       " {'label': 'Lewis', 'value': 'Lewis'},\n",
       " {'label': 'Lewis - Papers', 'value': 'Lewis - Papers'},\n",
       " {'label': 'Locke', 'value': 'Locke'},\n",
       " {'label': 'Malebranche', 'value': 'Malebranche'},\n",
       " {'label': 'Marcus Aurelius', 'value': 'Marcus Aurelius'},\n",
       " {'label': 'Marx', 'value': 'Marx'},\n",
       " {'label': 'Meditations', 'value': 'Meditations'},\n",
       " {'label': 'Meditations On First Philosophy',\n",
       "  'value': 'Meditations On First Philosophy'},\n",
       " {'label': 'Merleau-Ponty', 'value': 'Merleau-Ponty'},\n",
       " {'label': 'Moore', 'value': 'Moore'},\n",
       " {'label': 'Naming And Necessity', 'value': 'Naming And Necessity'},\n",
       " {'label': 'Nietzsche', 'value': 'Nietzsche'},\n",
       " {'label': 'Off The Beaten Track', 'value': 'Off The Beaten Track'},\n",
       " {'label': 'On Anger', 'value': 'On Anger'},\n",
       " {'label': 'On Benefits', 'value': 'On Benefits'},\n",
       " {'label': 'On Certainty', 'value': 'On Certainty'},\n",
       " {'label': 'On Clemency', 'value': 'On Clemency'},\n",
       " {'label': 'On The Improvement Of Understanding',\n",
       "  'value': 'On The Improvement Of Understanding'},\n",
       " {'label': 'On The Principles Of Political Economy And Taxation',\n",
       "  'value': 'On The Principles Of Political Economy And Taxation'},\n",
       " {'label': 'Phenomenology', 'value': 'Phenomenology'},\n",
       " {'label': 'Philosophical Investigations',\n",
       "  'value': 'Philosophical Investigations'},\n",
       " {'label': 'Philosophical Studies', 'value': 'Philosophical Studies'},\n",
       " {'label': 'Philosophical Troubles', 'value': 'Philosophical Troubles'},\n",
       " {'label': 'Plato', 'value': 'Plato'},\n",
       " {'label': 'Plato - Complete Works', 'value': 'Plato - Complete Works'},\n",
       " {'label': 'Popper', 'value': 'Popper'},\n",
       " {'label': 'Proslogion', 'value': 'Proslogion'},\n",
       " {'label': 'Quine', 'value': 'Quine'},\n",
       " {'label': 'Quintessence', 'value': 'Quintessence'},\n",
       " {'label': 'Rationalism', 'value': 'Rationalism'},\n",
       " {'label': 'Ricardo', 'value': 'Ricardo'},\n",
       " {'label': 'Russell', 'value': 'Russell'},\n",
       " {'label': 'Sartre', 'value': 'Sartre'},\n",
       " {'label': 'Scholasticism', 'value': 'Scholasticism'},\n",
       " {'label': 'Science Of Logic', 'value': 'Science Of Logic'},\n",
       " {'label': 'Second Treatise On Government',\n",
       "  'value': 'Second Treatise On Government'},\n",
       " {'label': 'Seneca', 'value': 'Seneca'},\n",
       " {'label': 'Smith', 'value': 'Smith'},\n",
       " {'label': 'Spinoza', 'value': 'Spinoza'},\n",
       " {'label': 'Stoicism', 'value': 'Stoicism'},\n",
       " {'label': 'The Analysis Of Mind', 'value': 'The Analysis Of Mind'},\n",
       " {'label': 'The Antichrist', 'value': 'The Antichrist'},\n",
       " {'label': 'The Birth Of The Clinic', 'value': 'The Birth Of The Clinic'},\n",
       " {'label': 'The Book Of Zhuangzi ', 'value': 'The Book Of Zhuangzi '},\n",
       " {'label': 'The Communist Manifesto', 'value': 'The Communist Manifesto'},\n",
       " {'label': 'The Crisis Of The European Sciences And Phenomenology',\n",
       "  'value': 'The Crisis Of The European Sciences And Phenomenology'},\n",
       " {'label': 'The Idea Of Phenomenology', 'value': 'The Idea Of Phenomenology'},\n",
       " {'label': 'The Logic Of Scientific Discovery',\n",
       "  'value': 'The Logic Of Scientific Discovery'},\n",
       " {'label': 'The Order Of Things', 'value': 'The Order Of Things'},\n",
       " {'label': 'The Phenomenology Of Perception',\n",
       "  'value': 'The Phenomenology Of Perception'},\n",
       " {'label': 'The Phenomenology Of Spirit',\n",
       "  'value': 'The Phenomenology Of Spirit'},\n",
       " {'label': 'The Problems Of Philosophy',\n",
       "  'value': 'The Problems Of Philosophy'},\n",
       " {'label': 'The Search After Truth', 'value': 'The Search After Truth'},\n",
       " {'label': 'The Second Sex', 'value': 'The Second Sex'},\n",
       " {'label': 'The System Of Ethics', 'value': 'The System Of Ethics'},\n",
       " {'label': 'The Wealth Of Nations', 'value': 'The Wealth Of Nations'},\n",
       " {'label': 'Theodicy', 'value': 'Theodicy'},\n",
       " {'label': 'Three Dialogues', 'value': 'Three Dialogues'},\n",
       " {'label': 'Thus Spake Zarathustra', 'value': 'Thus Spake Zarathustra'},\n",
       " {'label': 'Tractatus Logico-Philosophicus',\n",
       "  'value': 'Tractatus Logico-Philosophicus'},\n",
       " {'label': 'Twilight Of The Idols', 'value': 'Twilight Of The Idols'},\n",
       " {'label': 'Vindication Of The Rights Of Woman',\n",
       "  'value': 'Vindication Of The Rights Of Woman'},\n",
       " {'label': 'Wittgenstein', 'value': 'Wittgenstein'},\n",
       " {'label': 'Wollstonecraft', 'value': 'Wollstonecraft'},\n",
       " {'label': 'Women, Race, And Class', 'value': 'Women, Race, And Class'},\n",
       " {'label': 'Writing And Difference', 'value': 'Writing And Difference'},\n",
       " {'label': 'Zhuangzi', 'value': 'Zhuangzi'}]"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "dropdown_menu = []\n",
    "for source in all_options:\n",
    "    dropdown_menu.append({'label': source, 'value': source})\n",
    "\n",
    "dropdown_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict2 = {}\n",
    "for author in df['author'].unique():\n",
    "  classifier_dict2[author] = 'AUTHOR'\n",
    "for title in df['title'].unique():\n",
    "  classifier_dict2[title] = 'TITLE'\n",
    "for school in df['school'].unique():\n",
    "  classifier_dict2[school] = 'SCHOOL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(stats_dict_master, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "title_list           object\n",
       "ngram_chart          object\n",
       "word_freq_chart      object\n",
       "num_unique           object\n",
       "mean_sent_length    float64\n",
       "mean_word_length    float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'title_list': 'string', 'ngram_chart': 'string', 'word_freq_chart': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Plato', 'Plato - Complete Works', \"Figure({\\n    'data': [{'alignmentgroup': 'True',\\n              'hoverlabel': {'namelength': 0},\\n              'hovertemplate': 'bigram=%{x}<br>fre ... (920 characters truncated) ... 'domain': [0.0, 0.98], 'title': {'text': 'Phrases'}},\\n               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\\n})\", \"Figure({\\n    'data': [{'alignmentgroup': 'True',\\n              'hoverlabel': {'namelength': 0},\\n              'hovertemplate': 'words=%{x}<br>freq ... (862 characters truncated) ... , 'domain': [0.0, 0.98], 'title': {'text': 'Words'}},\\n               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\\n})\", '(25533,795612)', '20.72', '4.46')\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine \n",
    "\n",
    "engine = create_engine('url',  \n",
    "                       echo = False)\n",
    "\n",
    "df.to_sql('stats_database', con = engine, dtype={'ngram_chart': sqlalchemy.types.String(), 'word_freq_chart': sqlalchemy.types.String()}, if_exists='append')\n",
    "\n",
    "print(engine.execute(\"SELECT * FROM stats_database\").fetchone()) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from stats_database where index = 'Plato'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.raw_connection('url')\n",
    "c = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fetchall'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c8a16b1d77ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fetchall'"
     ]
    }
   ],
   "source": [
    "print(c.execute(query).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              title_list  \\\n",
       "0  Plato  Plato - Complete Works   \n",
       "\n",
       "                                         ngram_chart  \\\n",
       "0  Figure({\\n    'data': [{'alignmentgroup': 'Tru...   \n",
       "\n",
       "                                     word_freq_chart      num_unique  \\\n",
       "0  Figure({\\n    'data': [{'alignmentgroup': 'Tru...  (25533,795612)   \n",
       "\n",
       "  mean_sent_length mean_word_length  \n",
       "0            20.72             4.46  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>title_list</th>\n      <th>ngram_chart</th>\n      <th>word_freq_chart</th>\n      <th>num_unique</th>\n      <th>mean_sent_length</th>\n      <th>mean_word_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Plato</td>\n      <td>Plato - Complete Works</td>\n      <td>Figure({\\n    'data': [{'alignmentgroup': 'Tru...</td>\n      <td>Figure({\\n    'data': [{'alignmentgroup': 'Tru...</td>\n      <td>(25533,795612)</td>\n      <td>20.72</td>\n      <td>4.46</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(c.execute(\"\"\"select ngram_chart from stats_database where index = 'Plato'\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'fig'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-df18e9f195d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'fig'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt \n",
    "\n",
    "plt.fig(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = results['ngram_chart'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.controllers'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-2154bd823a1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrollers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mController\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mController\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.controllers'"
     ]
    }
   ],
   "source": [
    "from matplotlib.controllers import Controller\n",
    "\n",
    "c = Controller(chart)\n",
    "\n",
    "fig = c.figure\n",
    "# plt.plot(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Now we get the updated dropdown menu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}