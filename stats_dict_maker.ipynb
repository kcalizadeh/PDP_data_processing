{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "learn-env",
   "display_name": "learn-env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                         title       author       school  \\\n",
       "318854   The Wealth Of Nations        Smith   capitalism   \n",
       "122717  The Search After Truth  Malebranche  rationalism   \n",
       "126619  The Search After Truth  Malebranche  rationalism   \n",
       "172682    Naming And Necessity       Kripke     analytic   \n",
       "331402          The Antichrist    Nietzsche    nietzsche   \n",
       "\n",
       "                                           sentence_spacy  \\\n",
       "318854  Those who live in another country, contribute ...   \n",
       "122717  But I have already written so much about the n...   \n",
       "126619  The word person, according to Saint Augustine,...   \n",
       "172682  The terms 'one meter', degrees Centigrade', ha...   \n",
       "331402  It is not for us to say, 'This is not handsome...   \n",
       "\n",
       "                                             sentence_str  \\\n",
       "318854  Those who live in another country, contribute ...   \n",
       "122717  But I have already written so much about the n...   \n",
       "126619  The word person, according to Saint Augustine,...   \n",
       "172682  The terms 'one meter', degrees Centigrade', ha...   \n",
       "331402  It is not for us to say, 'This is not handsome...   \n",
       "\n",
       "        original_publication_date  corpus_edition_date  sentence_length  \\\n",
       "318854                       1776                 2009              179   \n",
       "122717                       1674                 1997              158   \n",
       "126619                       1674                 1997              215   \n",
       "172682                       1972                 1990              138   \n",
       "331402                       1888                 2006               90   \n",
       "\n",
       "                                         sentence_lowered  \\\n",
       "318854  those who live in another country, contribute ...   \n",
       "122717  but i have already written so much about the n...   \n",
       "126619  the word person, according to saint augustine,...   \n",
       "172682  the terms 'one meter', degrees centigrade', ha...   \n",
       "331402  it is not for us to say, 'this is not handsome...   \n",
       "\n",
       "                                            tokenized_txt  \\\n",
       "318854  ['those', 'who', 'live', 'in', 'another', 'cou...   \n",
       "122717  ['but', 'have', 'already', 'written', 'so', 'm...   \n",
       "126619  ['the', 'word', 'person', 'according', 'to', '...   \n",
       "172682  ['the', 'terms', 'one', 'meter', 'degrees', 'c...   \n",
       "331402  ['it', 'is', 'not', 'for', 'us', 'to', 'say', ...   \n",
       "\n",
       "                                           lemmatized_str  \n",
       "318854   those who live in another country , contribut...  \n",
       "122717   but -PRON- have already write so much about t...  \n",
       "126619   the word person , accord to Saint Augustine ,...  \n",
       "172682   the term ' one meter ' , degree Centigrade ' ...  \n",
       "331402   -PRON- be not for -PRON- to say , ' this be n...  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>title</th>\n      <th>author</th>\n      <th>school</th>\n      <th>sentence_spacy</th>\n      <th>sentence_str</th>\n      <th>original_publication_date</th>\n      <th>corpus_edition_date</th>\n      <th>sentence_length</th>\n      <th>sentence_lowered</th>\n      <th>tokenized_txt</th>\n      <th>lemmatized_str</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>318854</th>\n      <td>The Wealth Of Nations</td>\n      <td>Smith</td>\n      <td>capitalism</td>\n      <td>Those who live in another country, contribute ...</td>\n      <td>Those who live in another country, contribute ...</td>\n      <td>1776</td>\n      <td>2009</td>\n      <td>179</td>\n      <td>those who live in another country, contribute ...</td>\n      <td>['those', 'who', 'live', 'in', 'another', 'cou...</td>\n      <td>those who live in another country , contribut...</td>\n    </tr>\n    <tr>\n      <th>122717</th>\n      <td>The Search After Truth</td>\n      <td>Malebranche</td>\n      <td>rationalism</td>\n      <td>But I have already written so much about the n...</td>\n      <td>But I have already written so much about the n...</td>\n      <td>1674</td>\n      <td>1997</td>\n      <td>158</td>\n      <td>but i have already written so much about the n...</td>\n      <td>['but', 'have', 'already', 'written', 'so', 'm...</td>\n      <td>but -PRON- have already write so much about t...</td>\n    </tr>\n    <tr>\n      <th>126619</th>\n      <td>The Search After Truth</td>\n      <td>Malebranche</td>\n      <td>rationalism</td>\n      <td>The word person, according to Saint Augustine,...</td>\n      <td>The word person, according to Saint Augustine,...</td>\n      <td>1674</td>\n      <td>1997</td>\n      <td>215</td>\n      <td>the word person, according to saint augustine,...</td>\n      <td>['the', 'word', 'person', 'according', 'to', '...</td>\n      <td>the word person , accord to Saint Augustine ,...</td>\n    </tr>\n    <tr>\n      <th>172682</th>\n      <td>Naming And Necessity</td>\n      <td>Kripke</td>\n      <td>analytic</td>\n      <td>The terms 'one meter', degrees Centigrade', ha...</td>\n      <td>The terms 'one meter', degrees Centigrade', ha...</td>\n      <td>1972</td>\n      <td>1990</td>\n      <td>138</td>\n      <td>the terms 'one meter', degrees centigrade', ha...</td>\n      <td>['the', 'terms', 'one', 'meter', 'degrees', 'c...</td>\n      <td>the term ' one meter ' , degree Centigrade ' ...</td>\n    </tr>\n    <tr>\n      <th>331402</th>\n      <td>The Antichrist</td>\n      <td>Nietzsche</td>\n      <td>nietzsche</td>\n      <td>It is not for us to say, 'This is not handsome...</td>\n      <td>It is not for us to say, 'This is not handsome...</td>\n      <td>1888</td>\n      <td>2006</td>\n      <td>90</td>\n      <td>it is not for us to say, 'this is not handsome...</td>\n      <td>['it', 'is', 'not', 'for', 'us', 'to', 'say', ...</td>\n      <td>-PRON- be not for -PRON- to say , ' this be n...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import pandas as pd \n",
    "df = pd.read_csv('phil_nlp.csv')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Analytic           0.147069\n",
       "Aristotle          0.129434\n",
       "German Idealism    0.111796\n",
       "Plato              0.101803\n",
       "Continental        0.089632\n",
       "Phenomenology      0.075818\n",
       "Rationalism        0.060894\n",
       "Empiricism         0.052886\n",
       "Scholasticism      0.049450\n",
       "Capitalism         0.048277\n",
       "Communism          0.047651\n",
       "Feminism           0.027861\n",
       "Stoicism           0.020044\n",
       "Nietzsche          0.018081\n",
       "Hobbes             0.014623\n",
       "Kierkegaard        0.004681\n",
       "Name: school, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "df['school'] = df['school'].apply(lambda x: x.replace('_', ' ').title())\n",
    "df['school'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to\n[nltk_data]     C:\\Users\\kcali\\AppData\\Roaming\\nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import wordcloud\n",
    "import nltk \n",
    "nltk.download('stopwords')\n",
    "from nltk import FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import re\n",
    "import plotly.express as px \n",
    "import pandas as pd\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "classifier_dict = {}\n",
    "for author in df['author'].unique():\n",
    "  classifier_dict[author] = 'author'\n",
    "for title in df['title'].unique():\n",
    "  classifier_dict[title] = 'title'\n",
    "for school in df['school'].unique():\n",
    "  classifier_dict[school] = 'school'\n",
    "\n",
    "stopwords_list = stopwords.words('english') + list(string.punctuation) \n",
    "stopwords_list += ['“','”','...',\"''\",'’','``', \"'\", \"‘\"]\n",
    "custom_stopwords = ['–', 'also', 'something', 'cf', 'thus', 'two', 'now', 'would', \n",
    "                    'make', 'eb', 'u', 'well', 'even', 'said', 'eg', 'us',\n",
    "                    'n', 'sein', 'e', 'da', 'therefore', 'however', 'would', \n",
    "                    'thing', 'must', 'merely', 'way', 'since', 'latter', 'first',\n",
    "                    'B', 'mean', 'upon', 'yet', 'cannot', 'c', 'C', 'let', 'may', \n",
    "                    'might', \"'s\", 'b', 'ofthe', 'p.', '_', '-', 'eg', 'e.g.',\n",
    "                    'ie', 'i.e.', 'f', 'l', \"n't\", 'e.g', 'i.e', '—', '--', \n",
    "                    'hyl', 'phil', 'one', 'another', 'could', 'come', 'things', 'thing',\n",
    "                    'else', 'every', 'shall', 'thee', 'thy', 'thou', 'unto'] + stopwords_list\n",
    "\n",
    "df['gensim_tokenized'] = df['sentence_str'].map(lambda x: simple_preprocess(x.lower(),deacc=True,\n",
    "                                                        max_len=500))\n",
    "\n",
    "def get_average_word_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', '[']\n",
    "  num_words = 0\n",
    "  sum_word_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    sentence_list = [re.sub(\"[',]\", '', word) for word in sentence_list]\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    for word in no_punctuation_tokens:\n",
    "      num_words += 1\n",
    "      sum_word_lengths += len(word)\n",
    "  return round((sum_word_lengths / num_words), 2)\n",
    "\n",
    "def get_average_sentence_length(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  num_sentences = 0\n",
    "  sum_sentence_lengths = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_sentences += 1\n",
    "    sum_sentence_lengths += len(no_punctuation_tokens)\n",
    "  return round(sum_sentence_lengths / num_sentences, 2)\n",
    "\n",
    "def make_word_cloud(input, df, classifier, stopwords=stopwords.words('english')):\n",
    "    text = ''\n",
    "    for sentence in df[df[classifier[input]]==input]['sentence_str']:\n",
    "      text += sentence\n",
    "    cloud = wordcloud.WordCloud(width=500, \n",
    "                            height=400, \n",
    "                            background_color='#D1D1D1', \n",
    "                            max_words=30, \n",
    "                            stopwords=stopwords, \n",
    "                            color_func=lambda *args, **kwargs: (95,95,95)).generate(text)\n",
    "    return cloud\n",
    "\n",
    "def get_num_unique_words(input, df, classifier_dict):\n",
    "  punctuations = list(string.punctuation) + ['“','”','...',\"''\",'’','``', \"'\", \"‘\", '[', ']']\n",
    "  word_list = []\n",
    "  num_words = 0\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['tokenized_txt']:\n",
    "    sentence_list = sentence.split()\n",
    "    no_punctuation_tokens = [word for word in sentence_list if word not in punctuations]\n",
    "    no_punctuation_tokens = [word for word in no_punctuation_tokens if len(word) > 0]\n",
    "    num_words += len(no_punctuation_tokens)\n",
    "    for word in no_punctuation_tokens:\n",
    "      word_list.append(word)\n",
    "  num_unique_words = len(set(word_list))\n",
    "  return num_unique_words, num_words\n",
    "\n",
    "def plot_word_frequency(input, df, classifier_dict, stopwords):\n",
    "  word_list = []\n",
    "  for sentence in df[df[classifier_dict[input]]==input]['gensim_tokenized']:\n",
    "    for word in sentence:\n",
    "      word_list.append(word)\n",
    "  cleaned_words = [x.lower() for x in word_list if x.lower() not in stopwords]\n",
    "  freq_dist = FreqDist(cleaned_words)\n",
    "  freq_dict = {'words': [x[0] for x in freq_dist.most_common(7)], \n",
    "              'frequency': [x[1] for x in freq_dist.most_common(7)]}\n",
    "  freq_df = pd.DataFrame(freq_dict)\n",
    "  fig = px.bar(freq_df,\n",
    "              x='words',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Words')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} Word Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def plot_ngram_frequency(input, df, classifier_dict, stopwords): \n",
    "  word_list = []\n",
    "  for sent in df[df[classifier_dict[input]]==input]['gensim_tokenized']:\n",
    "    for word in sent:\n",
    "      word_list.append(word)\n",
    "  cleaned = [word.lower() for word in word_list if word not in custom_stopwords]\n",
    "  bigram_finder = BigramCollocationFinder.from_words(cleaned, window_size=3)\n",
    "  top_10 = sorted(bigram_finder.ngram_fd.items(), key=lambda t: (-t[1], t[0]))[:7]\n",
    "  bigram_df = pd.DataFrame(top_10, columns=['bigram', 'frequency'])\n",
    "  bigram_df['bigram'] = bigram_df['bigram'].apply(lambda x: ', '.join(x))\n",
    "  fig = px.bar(bigram_df,\n",
    "              x='bigram',\n",
    "              y='frequency')\n",
    "  fig.update_xaxes(title_text='Phrases')\n",
    "  fig.update_yaxes(title_text='Count')\n",
    "  fig.update_layout(title_text=f'{input.title()} N-gram Frequency Chart', title_x=0.5)\n",
    "  return fig\n",
    "\n",
    "def get_title_list(input, df, classifier_dict):\n",
    "  title_list = list(df[df[classifier_dict[input]]==input]['title'].unique())\n",
    "  title_list = [title.title() for title in title_list] \n",
    "  return ', '.join(title_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_dict_master = {}\n",
    "for option in classifier_dict.keys():\n",
    "    stats_dict = {}\n",
    "    stats_dict['title_list'] = get_title_list(option, df, classifier_dict)\n",
    "    stats_dict['ngram_chart'] = plot_ngram_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['word_freq_chart'] = plot_word_frequency(option, df, classifier_dict, custom_stopwords)\n",
    "    stats_dict['num_unique'] = get_num_unique_words(option, df, classifier_dict)\n",
    "    stats_dict['mean_sent_length'] = get_average_sentence_length(option, df, classifier_dict)\n",
    "    stats_dict['mean_word_length'] = get_average_word_length(option, df, classifier_dict)\n",
    "    stats_dict_master[option] = stats_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'title_list': 'Leviathan',\n",
       " 'ngram_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'bigram=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['sovereign, power', 'law, nature', 'kingdom, god', 'st, paul',\n",
       "                           'jesus, christ', 'st, peter', 'civil, sovereign'], dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([125, 109, 106,  74,  70,  62,  55], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Hobbes N-gram Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Phrases'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'word_freq_chart': Figure({\n",
       "     'data': [{'alignmentgroup': 'True',\n",
       "               'hoverlabel': {'namelength': 0},\n",
       "               'hovertemplate': 'words=%{x}<br>frequency=%{y}',\n",
       "               'legendgroup': '',\n",
       "               'marker': {'color': '#636efa'},\n",
       "               'name': '',\n",
       "               'offsetgroup': '',\n",
       "               'orientation': 'v',\n",
       "               'showlegend': False,\n",
       "               'textposition': 'auto',\n",
       "               'type': 'bar',\n",
       "               'x': array(['god', 'man', 'men', 'power', 'law', 'sovereign', 'say'], dtype=object),\n",
       "               'xaxis': 'x',\n",
       "               'y': array([1192, 1135, 1006,  700,  620,  514,  447], dtype=int64),\n",
       "               'yaxis': 'y'}],\n",
       "     'layout': {'barmode': 'relative',\n",
       "                'height': 600,\n",
       "                'legend': {'tracegroupgap': 0},\n",
       "                'margin': {'t': 60},\n",
       "                'template': '...',\n",
       "                'title': {'text': 'Hobbes Word Frequency Chart', 'x': 0.5},\n",
       "                'xaxis': {'anchor': 'y', 'domain': [0.0, 0.98], 'title': {'text': 'Words'}},\n",
       "                'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\n",
       " }),\n",
       " 'num_unique': (10730, 201537),\n",
       " 'mean_sent_length': 36.57,\n",
       " 'mean_word_length': 4.54}"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "stats_dict_master['Hobbes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "for option in stats_dict_master.keys():\n",
    "    dict_pkl = open(f'../apps/stats_app/stats_pickles/{option.title()}_stats.pkl', 'wb')\n",
    "    pickle.dump(stats_dict_master[option], dict_pkl)\n",
    "    dict_pkl.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_options = sorted([x.title() for x in list(classifier_dict.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'label': 'A General Theory Of Employment, Interest, And Money',\n",
       "  'value': 'A General Theory Of Employment, Interest, And Money'},\n",
       " {'label': 'A Treatise Concerning The Principles Of Human Knowledge',\n",
       "  'value': 'A Treatise Concerning The Principles Of Human Knowledge'},\n",
       " {'label': 'A Treatise Of Human Nature',\n",
       "  'value': 'A Treatise Of Human Nature'},\n",
       " {'label': 'Analytic', 'value': 'Analytic'},\n",
       " {'label': 'Anselm', 'value': 'Anselm'},\n",
       " {'label': 'Anti-Oedipus', 'value': 'Anti-Oedipus'},\n",
       " {'label': 'Aristotle', 'value': 'Aristotle'},\n",
       " {'label': 'Aristotle - Complete Works',\n",
       "  'value': 'Aristotle - Complete Works'},\n",
       " {'label': 'Augustine', 'value': 'Augustine'},\n",
       " {'label': 'Beauvoir', 'value': 'Beauvoir'},\n",
       " {'label': 'Being And Time', 'value': 'Being And Time'},\n",
       " {'label': 'Berkeley', 'value': 'Berkeley'},\n",
       " {'label': 'Beyond Good And Evil', 'value': 'Beyond Good And Evil'},\n",
       " {'label': 'Capital', 'value': 'Capital'},\n",
       " {'label': 'Capitalism', 'value': 'Capitalism'},\n",
       " {'label': 'Communism', 'value': 'Communism'},\n",
       " {'label': 'Confessions', 'value': 'Confessions'},\n",
       " {'label': 'Continental', 'value': 'Continental'},\n",
       " {'label': 'Critique Of Judgement', 'value': 'Critique Of Judgement'},\n",
       " {'label': 'Critique Of Practical Reason',\n",
       "  'value': 'Critique Of Practical Reason'},\n",
       " {'label': 'Critique Of Pure Reason', 'value': 'Critique Of Pure Reason'},\n",
       " {'label': 'Davis', 'value': 'Davis'},\n",
       " {'label': 'De Veritate', 'value': 'De Veritate'},\n",
       " {'label': 'Deleuze', 'value': 'Deleuze'},\n",
       " {'label': 'Derrida', 'value': 'Derrida'},\n",
       " {'label': 'Descartes', 'value': 'Descartes'},\n",
       " {'label': 'Dialogues Concerning Natural Religion',\n",
       "  'value': 'Dialogues Concerning Natural Religion'},\n",
       " {'label': 'Difference And Repetition', 'value': 'Difference And Repetition'},\n",
       " {'label': 'Discourse On Method', 'value': 'Discourse On Method'},\n",
       " {'label': 'Ecce Homo', 'value': 'Ecce Homo'},\n",
       " {'label': 'Elements Of The Philosophy Of Right',\n",
       "  'value': 'Elements Of The Philosophy Of Right'},\n",
       " {'label': 'Empiricism', 'value': 'Empiricism'},\n",
       " {'label': 'Enchiridion', 'value': 'Enchiridion'},\n",
       " {'label': 'Epictetus', 'value': 'Epictetus'},\n",
       " {'label': 'Essay Concerning Human Understanding',\n",
       "  'value': 'Essay Concerning Human Understanding'},\n",
       " {'label': 'Essential Works Of Lenin', 'value': 'Essential Works Of Lenin'},\n",
       " {'label': 'Ethics', 'value': 'Ethics'},\n",
       " {'label': 'Fear And Trembling', 'value': 'Fear And Trembling'},\n",
       " {'label': 'Feminism', 'value': 'Feminism'},\n",
       " {'label': 'Fichte', 'value': 'Fichte'},\n",
       " {'label': 'Foucault', 'value': 'Foucault'},\n",
       " {'label': 'German Idealism', 'value': 'German Idealism'},\n",
       " {'label': 'Hegel', 'value': 'Hegel'},\n",
       " {'label': 'Heidegger', 'value': 'Heidegger'},\n",
       " {'label': 'History Of Madness', 'value': 'History Of Madness'},\n",
       " {'label': 'Hobbes', 'value': 'Hobbes'},\n",
       " {'label': 'Hume', 'value': 'Hume'},\n",
       " {'label': 'Husserl', 'value': 'Husserl'},\n",
       " {'label': 'Kant', 'value': 'Kant'},\n",
       " {'label': 'Keynes', 'value': 'Keynes'},\n",
       " {'label': 'Kierkegaard', 'value': 'Kierkegaard'},\n",
       " {'label': 'Kripke', 'value': 'Kripke'},\n",
       " {'label': 'Leibniz', 'value': 'Leibniz'},\n",
       " {'label': 'Lenin', 'value': 'Lenin'},\n",
       " {'label': 'Leviathan', 'value': 'Leviathan'},\n",
       " {'label': 'Lewis', 'value': 'Lewis'},\n",
       " {'label': 'Lewis - Papers', 'value': 'Lewis - Papers'},\n",
       " {'label': 'Locke', 'value': 'Locke'},\n",
       " {'label': 'Malebranche', 'value': 'Malebranche'},\n",
       " {'label': 'Marcus Aurelius', 'value': 'Marcus Aurelius'},\n",
       " {'label': 'Marx', 'value': 'Marx'},\n",
       " {'label': 'Meditations', 'value': 'Meditations'},\n",
       " {'label': 'Meditations On First Philosophy',\n",
       "  'value': 'Meditations On First Philosophy'},\n",
       " {'label': 'Merleau-Ponty', 'value': 'Merleau-Ponty'},\n",
       " {'label': 'Moore', 'value': 'Moore'},\n",
       " {'label': 'Naming And Necessity', 'value': 'Naming And Necessity'},\n",
       " {'label': 'Nietzsche', 'value': 'Nietzsche'},\n",
       " {'label': 'Off The Beaten Track', 'value': 'Off The Beaten Track'},\n",
       " {'label': 'On Anger', 'value': 'On Anger'},\n",
       " {'label': 'On Benefits', 'value': 'On Benefits'},\n",
       " {'label': 'On Certainty', 'value': 'On Certainty'},\n",
       " {'label': 'On Clemency', 'value': 'On Clemency'},\n",
       " {'label': 'On The Improvement Of Understanding',\n",
       "  'value': 'On The Improvement Of Understanding'},\n",
       " {'label': 'On The Principles Of Political Economy And Taxation',\n",
       "  'value': 'On The Principles Of Political Economy And Taxation'},\n",
       " {'label': 'Phenomenology', 'value': 'Phenomenology'},\n",
       " {'label': 'Philosophical Investigations',\n",
       "  'value': 'Philosophical Investigations'},\n",
       " {'label': 'Philosophical Studies', 'value': 'Philosophical Studies'},\n",
       " {'label': 'Philosophical Troubles', 'value': 'Philosophical Troubles'},\n",
       " {'label': 'Plato', 'value': 'Plato'},\n",
       " {'label': 'Plato - Complete Works', 'value': 'Plato - Complete Works'},\n",
       " {'label': 'Popper', 'value': 'Popper'},\n",
       " {'label': 'Proslogion', 'value': 'Proslogion'},\n",
       " {'label': 'Quine', 'value': 'Quine'},\n",
       " {'label': 'Quintessence', 'value': 'Quintessence'},\n",
       " {'label': 'Rationalism', 'value': 'Rationalism'},\n",
       " {'label': 'Ricardo', 'value': 'Ricardo'},\n",
       " {'label': 'Russell', 'value': 'Russell'},\n",
       " {'label': 'Scholasticism', 'value': 'Scholasticism'},\n",
       " {'label': 'Science Of Logic', 'value': 'Science Of Logic'},\n",
       " {'label': 'Second Treatise On Government',\n",
       "  'value': 'Second Treatise On Government'},\n",
       " {'label': 'Seneca', 'value': 'Seneca'},\n",
       " {'label': 'Smith', 'value': 'Smith'},\n",
       " {'label': 'Spinoza', 'value': 'Spinoza'},\n",
       " {'label': 'Stoicism', 'value': 'Stoicism'},\n",
       " {'label': 'The Analysis Of Mind', 'value': 'The Analysis Of Mind'},\n",
       " {'label': 'The Antichrist', 'value': 'The Antichrist'},\n",
       " {'label': 'The Birth Of The Clinic', 'value': 'The Birth Of The Clinic'},\n",
       " {'label': 'The Communist Manifesto', 'value': 'The Communist Manifesto'},\n",
       " {'label': 'The Crisis Of The European Sciences And Phenomenology',\n",
       "  'value': 'The Crisis Of The European Sciences And Phenomenology'},\n",
       " {'label': 'The Idea Of Phenomenology', 'value': 'The Idea Of Phenomenology'},\n",
       " {'label': 'The Logic Of Scientific Discovery',\n",
       "  'value': 'The Logic Of Scientific Discovery'},\n",
       " {'label': 'The Order Of Things', 'value': 'The Order Of Things'},\n",
       " {'label': 'The Phenomenology Of Perception',\n",
       "  'value': 'The Phenomenology Of Perception'},\n",
       " {'label': 'The Phenomenology Of Spirit',\n",
       "  'value': 'The Phenomenology Of Spirit'},\n",
       " {'label': 'The Problems Of Philosophy',\n",
       "  'value': 'The Problems Of Philosophy'},\n",
       " {'label': 'The Search After Truth', 'value': 'The Search After Truth'},\n",
       " {'label': 'The Second Sex', 'value': 'The Second Sex'},\n",
       " {'label': 'The System Of Ethics', 'value': 'The System Of Ethics'},\n",
       " {'label': 'The Wealth Of Nations', 'value': 'The Wealth Of Nations'},\n",
       " {'label': 'Theodicy', 'value': 'Theodicy'},\n",
       " {'label': 'Three Dialogues', 'value': 'Three Dialogues'},\n",
       " {'label': 'Thus Spake Zarathustra', 'value': 'Thus Spake Zarathustra'},\n",
       " {'label': 'Tractatus Logico-Philosophicus',\n",
       "  'value': 'Tractatus Logico-Philosophicus'},\n",
       " {'label': 'Twilight Of The Idols', 'value': 'Twilight Of The Idols'},\n",
       " {'label': 'Vindication Of The Rights Of Woman',\n",
       "  'value': 'Vindication Of The Rights Of Woman'},\n",
       " {'label': 'Wittgenstein', 'value': 'Wittgenstein'},\n",
       " {'label': 'Wollstonecraft', 'value': 'Wollstonecraft'},\n",
       " {'label': 'Women, Race, And Class', 'value': 'Women, Race, And Class'},\n",
       " {'label': 'Writing And Difference', 'value': 'Writing And Difference'}]"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "dropdown_menu = []\n",
    "for source in all_options:\n",
    "    dropdown_menu.append({'label': source, 'value': source})\n",
    "\n",
    "dropdown_menu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict2 = {}\n",
    "for author in df['author'].unique():\n",
    "  classifier_dict2[author] = 'AUTHOR'\n",
    "for title in df['title'].unique():\n",
    "  classifier_dict2[title] = 'TITLE'\n",
    "for school in df['school'].unique():\n",
    "  classifier_dict2[school] = 'SCHOOL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(stats_dict_master, orient='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "title_list           object\n",
       "ngram_chart          object\n",
       "word_freq_chart      object\n",
       "num_unique           object\n",
       "mean_sent_length    float64\n",
       "mean_word_length    float64\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype({'title_list': 'string', 'ngram_chart': 'string', 'word_freq_chart': 'string'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('Plato', 'Plato - Complete Works', \"Figure({\\n    'data': [{'alignmentgroup': 'True',\\n              'hoverlabel': {'namelength': 0},\\n              'hovertemplate': 'bigram=%{x}<br>fre ... (920 characters truncated) ... 'domain': [0.0, 0.98], 'title': {'text': 'Phrases'}},\\n               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\\n})\", \"Figure({\\n    'data': [{'alignmentgroup': 'True',\\n              'hoverlabel': {'namelength': 0},\\n              'hovertemplate': 'words=%{x}<br>freq ... (862 characters truncated) ... , 'domain': [0.0, 0.98], 'title': {'text': 'Words'}},\\n               'yaxis': {'anchor': 'x', 'domain': [0.0, 1.0], 'title': {'text': 'Count'}}}\\n})\", '(25533,795612)', '20.72', '4.46')\n"
     ]
    }
   ],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine \n",
    "\n",
    "engine = create_engine('url',  \n",
    "                       echo = False)\n",
    "\n",
    "df.to_sql('stats_database', con = engine, dtype={'ngram_chart': sqlalchemy.types.String(), 'word_freq_chart': sqlalchemy.types.String()}, if_exists='append')\n",
    "\n",
    "print(engine.execute(\"SELECT * FROM stats_database\").fetchone()) \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"select * from stats_database where index = 'Plato'\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = engine.raw_connection('url')\n",
    "c = connection.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'fetchall'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-c8a16b1d77ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'fetchall'"
     ]
    }
   ],
   "source": [
    "print(c.execute(query).fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   index              title_list  \\\n",
       "0  Plato  Plato - Complete Works   \n",
       "\n",
       "                                         ngram_chart  \\\n",
       "0  Figure({\\n    'data': [{'alignmentgroup': 'Tru...   \n",
       "\n",
       "                                     word_freq_chart      num_unique  \\\n",
       "0  Figure({\\n    'data': [{'alignmentgroup': 'Tru...  (25533,795612)   \n",
       "\n",
       "  mean_sent_length mean_word_length  \n",
       "0            20.72             4.46  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>title_list</th>\n      <th>ngram_chart</th>\n      <th>word_freq_chart</th>\n      <th>num_unique</th>\n      <th>mean_sent_length</th>\n      <th>mean_word_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Plato</td>\n      <td>Plato - Complete Works</td>\n      <td>Figure({\\n    'data': [{'alignmentgroup': 'Tru...</td>\n      <td>Figure({\\n    'data': [{'alignmentgroup': 'Tru...</td>\n      <td>(25533,795612)</td>\n      <td>20.72</td>\n      <td>4.46</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(c.execute(\"\"\"select ngram_chart from stats_database where index = 'Plato'\"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'fig'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-df18e9f195d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'fig'"
     ]
    }
   ],
   "source": [
    "import matplotlib as plt \n",
    "\n",
    "plt.fig(c.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "chart = results['ngram_chart'].astype('object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib.controllers'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-2154bd823a1e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrollers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mController\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mController\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib.controllers'"
     ]
    }
   ],
   "source": [
    "from matplotlib.controllers import Controller\n",
    "\n",
    "c = Controller(chart)\n",
    "\n",
    "fig = c.figure\n",
    "# plt.plot(chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "Now we get the updated dropdown menu"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}