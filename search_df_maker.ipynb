{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "learn-env",
   "display_name": "learn-env",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('phil_nlp.csv')\n",
    "\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_db = df\n",
    "for_db['date'] = for_db['original_publication_date']\n",
    "for_db['date'] = for_db['date'].apply(lambda x: str(x)[1:]+' BC' if x < 0 else str(x))\n",
    "for_db['sentence'] = for_db['sentence_str']\n",
    "for_db['school'] = for_db['school'].apply(lambda x: x.replace('_', ' ').title())\n",
    "for_db = for_db.drop(['sentence_spacy', \n",
    "                      'sentence_length',\n",
    "                      'sentence_lowered', \n",
    "                      'sentence_str', \n",
    "                      'tokenized_txt', \n",
    "                      'lemmatized_str',\n",
    "                      'corpus_edition_date',\n",
    "                      'original_publication_date'], axis=1)\n",
    "for_db.columns = [i.upper() for i in for_db.columns]\n",
    "\n",
    "for_db.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_db.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for_db['SCHOOL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict = {}\n",
    "for author in for_db['AUTHOR'].unique():\n",
    "  classifier_dict[author] = 'AUTHOR'\n",
    "for title in for_db['TITLE'].unique():\n",
    "  classifier_dict[title] = 'TITLE'\n",
    "for school in for_db['SCHOOL'].unique():\n",
    "  classifier_dict[school] = 'SCHOOL'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_dict"
   ]
  },
  {
   "source": [
    "Now get an updated dropdown menu."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_options = sorted([x for x in list(classifier_dict.keys())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_menu = []\n",
    "for source in all_options:\n",
    "    dropdown_menu.append({'label': source, 'value': source})\n",
    "\n",
    "dropdown_menu"
   ]
  },
  {
   "source": [
    "The next cell makes pickles of each relevant slice. Not necessary since we run it all on SQL."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for source in classifier_dict.keys():\n",
    "        source_slice = df[df[classifier_dict[source]]==source]\n",
    "        source = source.title()\n",
    "        source_pkl = open(f'../search_app/slice_pickles/{source}_slice.pkl', 'wb')\n",
    "        pickle.dump(source_slice, source_pkl)\n",
    "        source_pkl.close()\n"
   ]
  }
 ]
}